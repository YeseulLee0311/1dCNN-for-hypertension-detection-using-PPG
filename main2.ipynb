{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhB8-nozfVY"
      },
      "source": [
        "## Mount to Drive"
      ],
      "id": "MfhB8-nozfVY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbICMMTxzhrb",
        "outputId": "70b5f6cf-da20-4626-a67d-36e86cad1536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "nbICMMTxzhrb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ca51692"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from google.colab import files\n",
        "\n",
        "from torchvision import transforms\n",
        "# files.upload()\n",
        "# from modules2 import train_model, test_model\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "# files.upload()\n",
        "# from backbone_models import ResNet18, VGG16\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data"
      ],
      "id": "4ca51692"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e57800d8"
      },
      "outputs": [],
      "source": [
        "ppg_dir = '/content/drive/MyDrive/Data/5459299/Data_File/subject'\n",
        "label_path = '/content/drive/MyDrive/Data/5459299/Data_File/PPG-BP dataset.csv'"
      ],
      "id": "e57800d8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose High Quality Data\n",
        "(From the dataset description, it says every subject has 3 segments of ppg signals, and we need to choose the segment with highest quality for each subject.)\n",
        "(But for now, we just choose all segments as long as the quality is positive, so we can have more data to train.)"
      ],
      "metadata": {
        "id": "w6-rwODsEzQ-"
      },
      "id": "w6-rwODsEzQ-"
    },
    {
      "cell_type": "code",
      "source": [
        "# organized data from https://www.nature.com/articles/sdata201820/tables/2\n",
        "\n",
        "quality_dict = dict()\n",
        "# key: subject number; value[0]: subject ID; value[1]:quality of segment 1; value[2]:quality of segment 2; value[3]:quality of segment 3\n",
        "quality_dict[1] = [2, 0.98, 0.96, 0.92]\n",
        "quality_dict[2] = [3, 0.69, 0.8, 0.81]\n",
        "quality_dict[3] = [6, 0.58, 0.59, 0.64]\n",
        "quality_dict[4] = [8, 0.96, 0.85, 0.87]\n",
        "quality_dict[5] = [9, 0.65, 0.67, 0.87]\n",
        "quality_dict[6] = [10, 0.59, 0.64, 0.34]\n",
        "quality_dict[7] = [11, 0.74, 0.67, -0.16]\n",
        "quality_dict[8] = [12, 0.23, 0.73, 0.41]\n",
        "quality_dict[9] = [13, 0.76, 0.84, 1.06]\n",
        "quality_dict[10] = [14, 0.77, 0.72, 0.15]\n",
        "\n",
        "quality_dict[11] = [15, 1.23, 0.77, 0.3]\n",
        "quality_dict[12] = [16, 0.64, 0.66, 0.83]\n",
        "quality_dict[13] = [17, 0.69, 0.9, 0.9]\n",
        "quality_dict[14] = [18, 0.87, 0.59, 1.05]\n",
        "quality_dict[15] = [19, 0.78, 0.19, 0.16]\n",
        "quality_dict[16] = [21, 0.65, 0.74, 0.75]\n",
        "quality_dict[17] = [22, 0.73, 0.44, 0.39]\n",
        "quality_dict[18] = [23, 0.7, 0.6, 0.74]\n",
        "quality_dict[19] = [24, 0.74, 0.74, 0.75]\n",
        "quality_dict[20] = [25, 1.38, 0.15, 0.78]\n",
        "\n",
        "quality_dict[21] = [26, 1.31, 0.47, 0.83]\n",
        "quality_dict[22] = [27, 1.86, 1.33, 1.26]\n",
        "quality_dict[23] = [29, 0.73, 0.6, -0.05]\n",
        "quality_dict[24] = [30, 0.86, 0.8, 0.76]\n",
        "quality_dict[25] = [31, 0.68, 0.81, 0.7]\n",
        "quality_dict[26] = [32, 1.06, 1.12, 1.23]\n",
        "quality_dict[27] = [34, 0.9, 0.79, 0.74]\n",
        "quality_dict[28] = [35, 0.94, 1.15, 1.18]\n",
        "quality_dict[29] = [38, 0.88, 0.66, 0.94]\n",
        "quality_dict[30] = [40, 0.21, 1.2, 0.9]\n",
        "\n",
        "quality_dict[31] = [41, 0.85, 0.78, 0.73]\n",
        "quality_dict[32] = [43, 0.52, 0.28, 0.53]\n",
        "quality_dict[33] = [45, 0.68, 0.76, 0.67]\n",
        "quality_dict[34] = [47, 0.76, 0.75, 0.73]\n",
        "quality_dict[35] = [48, 0.74, 0.79, 0.63]\n",
        "quality_dict[36] = [50, 0.79, 0.72, 0.73]\n",
        "quality_dict[37] = [51, 0.6, 0.2, 0.49]\n",
        "quality_dict[38] = [52, 0.95, 0.67, 0.93]\n",
        "quality_dict[39] = [53, 0.81, 0.91, 0.9]\n",
        "quality_dict[40] = [54, 1.12, 1.06, 1.11]\n",
        "\n",
        "quality_dict[41] = [55, 0.63, 0.99, 1.1]\n",
        "quality_dict[42] = [56, 0.26, 0.4, 0.47]\n",
        "quality_dict[43] = [57, 0.69, 0.59, 0.65]\n",
        "quality_dict[44] = [58, 0.97, 0.62, 0.75]\n",
        "quality_dict[45] = [60, 0.37, 1.64, 0.51]\n",
        "quality_dict[46] = [61, 0.87, 0.84, 0.93]\n",
        "quality_dict[47] = [62, 0.57, 0.96, 0.69]\n",
        "quality_dict[48] = [63, 1.01, 0.92, 0.92]\n",
        "quality_dict[49] = [64, 0.19, 0.65, 0.39]\n",
        "quality_dict[50] = [65, 0.78, 0.8, 0.72]\n",
        "\n",
        "quality_dict[51] = [66, 0.79, 0.79, 0.94]\n",
        "quality_dict[52] = [67, 0.7, 0.7, 0.99]\n",
        "quality_dict[53] = [83, 0.81, 0.9, 0.79]\n",
        "quality_dict[54] = [84, 0.91, 0.3, 0.65]\n",
        "quality_dict[55] = [85, 0.68, 0.79, 0.63]\n",
        "quality_dict[56] = [86, 0.66, 0.7, 0.72]\n",
        "quality_dict[57] = [87, 0.97, 0.96, 0.95]\n",
        "quality_dict[58] = [88, 0.81, 0.52, 0.65]\n",
        "quality_dict[59] = [89, 0.39, 0.58, 0.14]\n",
        "quality_dict[60] = [90, 0.87, 0.97, 1]\n",
        "\n",
        "quality_dict[61] = [91, 1.05, 0.77, 0.84]\n",
        "quality_dict[62] = [92, 0.9, 1.1, 1.15]\n",
        "quality_dict[63] = [93, 0.97, 0.99, 0.46]\n",
        "quality_dict[64] = [95, 1.31, 0.89, 0.87]\n",
        "quality_dict[65] = [96, 0.75, 0.89, 0.81]\n",
        "quality_dict[66] = [97, 0.56, 0.42, 0.76]\n",
        "quality_dict[67] = [98, 0.88, 0.98, 0.86]\n",
        "quality_dict[68] = [99, 0.88, 0.72, 0.79]\n",
        "quality_dict[69] = [100, 0.58, 0.66, 0.16]\n",
        "quality_dict[70] = [103, 0.37, 0.4, 0.44]\n",
        "\n",
        "quality_dict[71] = [104, 0.88, 0.23, 0.85]\n",
        "quality_dict[72] = [105, 0.54, 0.97, 0.8]\n",
        "quality_dict[73] = [106, 0.82, 0.9, 1.16]\n",
        "quality_dict[74] = [107, 0.89, 0.58, 0.66]\n",
        "quality_dict[75] = [108, 0.71, 0.69, 0.64]\n",
        "quality_dict[76] = [110, 0.9, 0.83, 0.88]\n",
        "quality_dict[77] = [111, 0.9, 0.85, 0.76]\n",
        "quality_dict[78] = [112, 0.61, 0.55, 0.57]\n",
        "quality_dict[79] = [113, 0.35, 0.51, 0.78]\n",
        "quality_dict[80] = [114, 0.5, 0.58, 0.67]\n",
        "\n",
        "quality_dict[81] = [115, 0.74, 0.06, 1.03]\n",
        "quality_dict[82] = [116, 0.78, 0.86, 0.93]\n",
        "quality_dict[83] = [119, 0.55, 0.59, -0.07]\n",
        "quality_dict[84] = [120, 0.79, 0.67, 0.77]\n",
        "quality_dict[85] = [122, 0.93, 0.87, 0.5]\n",
        "quality_dict[86] = [123, 0.89, 0.97, 1.3]\n",
        "quality_dict[87] = [124, 0.93, 1.23, 1.19]\n",
        "quality_dict[88] = [125, 0.84, -0.47, 0.86]\n",
        "quality_dict[89] = [126, 0.44, -0.01, 0.54]\n",
        "quality_dict[90] = [127, 0.53, 0.83, 0.75]\n",
        "\n",
        "quality_dict[91] = [128, 0.87, 0.86, 0.9]\n",
        "quality_dict[92] = [130, 0.91, 0.97, 1]\n",
        "quality_dict[93] = [131, 0.86, 0.85, 0.75]\n",
        "quality_dict[94] = [134, 0.71, 0.21, 0.86]\n",
        "quality_dict[95] = [135, 0.68, 0.72, 0.67]\n",
        "quality_dict[96] = [136, 1.73, 0.56, 0.8]\n",
        "quality_dict[97] = [137, 0.28, 0.58, 0.79]\n",
        "quality_dict[98] = [138, 0.74, 0.48, 0.59]\n",
        "quality_dict[99] = [139, 1.35, 0.69, 0.63]\n",
        "quality_dict[100] = [140, 0.41, 0.85, 0.71]\n",
        "\n",
        "quality_dict[101] = [141, 1.14, 0.96, 0.86]\n",
        "quality_dict[102] = [142, 0.8, 0.82, 0.83]\n",
        "quality_dict[103] = [144, 0.76, 0.66, -0.01]\n",
        "quality_dict[104] = [145, 1.11, 1.1, 1.1]\n",
        "quality_dict[105] = [146, 0.84, 0.84, 1]\n",
        "quality_dict[106] = [148, 1.03, 1.03, 1.06]\n",
        "quality_dict[107] = [149, 0.52, 0.58, 0.49]\n",
        "quality_dict[108] = [150, 0.75, 0.66, 0.49]\n",
        "quality_dict[109] = [151, 0.81, 0.29, 0.85]\n",
        "quality_dict[110] = [152, 1.05, 0.9, 1.22]\n",
        "\n",
        "quality_dict[111] = [153, 0.93, 1.15, 0.79]\n",
        "quality_dict[112] = [154, 0.82, 0.7, 0.75]\n",
        "quality_dict[113] = [155, 0.75, 0.94, 0.71]\n",
        "quality_dict[114] = [156, 0.75, 0.76, 0.7]\n",
        "quality_dict[115] = [157, 0.58, 0.68, 0.44]\n",
        "quality_dict[116] = [158, 0.66, 0.86, 0.05]\n",
        "quality_dict[117] = [160, 0.54, 0.66, 0.59]\n",
        "quality_dict[118] = [161, 0.89, 0.83, 0.86]\n",
        "quality_dict[119] = [162, 1.07, 1, 0.97]\n",
        "quality_dict[120] = [163, 0.79, 0.42, 0.61]\n",
        "\n",
        "quality_dict[121] = [164, 0.94, 0.85, 0.71]\n",
        "quality_dict[122] = [165, 1.07, 0.96, 1.02]\n",
        "quality_dict[123] = [166, 0.71, 0.93, 0.77]\n",
        "quality_dict[124] = [167, 0.57, 0.76, 0.57]\n",
        "quality_dict[125] = [169, 1.11, 0.82, 0.91]\n",
        "quality_dict[126] = [170, 0.77, 0.85, 0.95]\n",
        "quality_dict[127] = [171, 0.69, 0.46, 0.48]\n",
        "quality_dict[128] = [172, 0.45, 0.56, 0.53]\n",
        "quality_dict[129] = [173, 0.89, 0.84, 0.97]\n",
        "quality_dict[130] = [174, 1.14, 1.03, 1.17]\n",
        "\n",
        "quality_dict[131] = [175, 0.69, 0.62, 0.71]\n",
        "quality_dict[132] = [176, 0.75, 0.73, 0.68]\n",
        "quality_dict[133] = [178, 0.38, 0.68, 0.55]\n",
        "quality_dict[134] = [179, 2.34, 0.83, 0.78]\n",
        "quality_dict[135] = [180, 0.8, 0.64, 0.84]\n",
        "quality_dict[136] = [182, 0.72, 0.93, 0.9]\n",
        "quality_dict[137] = [183, 0.35, 0.25, 0.36]\n",
        "quality_dict[138] = [184, 0.49, 0.93, 0.87]\n",
        "quality_dict[139] = [185, 1.03, 1.1, 1.1]\n",
        "quality_dict[140] = [186, 0.73, 0.69, 0.99]\n",
        "\n",
        "quality_dict[141] = [188, 0.85, 1.78, 0.71]\n",
        "quality_dict[142] = [189, 0.9, 0.68, 0.92]\n",
        "quality_dict[143] = [190, 1.13, 0.8, 0.99]\n",
        "quality_dict[144] = [191, 1.23, 1.1, 0.85]\n",
        "quality_dict[145] = [192, 0.85, 0.87, 0.8]\n",
        "quality_dict[146] = [193, 0.76, 0.53, 0.63]\n",
        "quality_dict[147] = [195, 0.91, 1.1, 0.49]\n",
        "quality_dict[148] = [196, 0.88, 0.74, 0.68]\n",
        "quality_dict[149] = [197, 0.9, 1.06, 1.33]\n",
        "quality_dict[150] = [198, 1.12, 1.07, 1.02]\n",
        "\n",
        "quality_dict[151] = [199, 0.81, 0.96, 0.83]\n",
        "quality_dict[152] = [200, 0.3, 0.86, 1.02]\n",
        "quality_dict[153] = [201, 0.68, 0.69, 0.8]\n",
        "quality_dict[154] = [203, 0.92, 1.05, 0.86]\n",
        "quality_dict[155] = [205, 0.91, 0.82, 0.77]\n",
        "quality_dict[156] = [206, 0.69, 0.84, 0.67]\n",
        "quality_dict[157] = [207, 0.75, 0.7, 0.2]\n",
        "quality_dict[158] = [208, 1.47, 0.95, 0.92]\n",
        "quality_dict[159] = [209, 0.76, 0.67, 0.7]\n",
        "quality_dict[160] = [210, 0.72, 0.71, 0.78]\n",
        "\n",
        "quality_dict[161] = [211, 1.4, 0.73, 0.89]\n",
        "quality_dict[162] = [212, 0.74, 0.56, 0.59]\n",
        "quality_dict[163] = [213, 1.16, 0.91, 0.67]\n",
        "quality_dict[164] = [214, 0.46, 0.72, 0.24]\n",
        "quality_dict[165] = [215, 0.62, 0.69, 0.81]\n",
        "quality_dict[166] = [216, 0.33, 0.33, 0.37]\n",
        "quality_dict[167] = [217, 0.69, 1.26, 0.8]\n",
        "quality_dict[168] = [218, 0.82, 0.99, 0.89]\n",
        "quality_dict[169] = [219, 1.02, 1.05, 0.84]\n",
        "quality_dict[170] = [220, 0.63, 0.65, 0.66]\n",
        "\n",
        "quality_dict[171] = [221, 0.43, 0.78, 0.6]\n",
        "quality_dict[172] = [222, 0.92, 0.87, 0.85]\n",
        "quality_dict[173] = [223, 0.81, 0.08, 0.98]\n",
        "quality_dict[174] = [224, 0.85, 1.03, 0.75]\n",
        "quality_dict[175] = [226, 0.84, 1.04, 0.44]\n",
        "quality_dict[176] = [227, 0.99, 0.88, 0.94]\n",
        "quality_dict[177] = [228, 1.06, 1, 0.93]\n",
        "quality_dict[178] = [229, 1, 1.09, 0.98]\n",
        "quality_dict[179] = [230, 0.59, 0.72, 0.81]\n",
        "quality_dict[180] = [231, 1.28, 1.46, 0.98]\n",
        "\n",
        "quality_dict[181] = [232, 0.92, 1.21, 0.87]\n",
        "quality_dict[182] = [233, 0.89, 0.86, 0.67]\n",
        "quality_dict[183] = [234, 0.62, 0.81, 1.02]\n",
        "quality_dict[184] = [235, 0.94, 1.08, 0.97]\n",
        "quality_dict[185] = [237, 0.79, 1.19, 1.42]\n",
        "quality_dict[186] = [239, 0.81, 0.8, 0.7]\n",
        "quality_dict[187] = [240, 0.6, 1.09, 0.93]\n",
        "quality_dict[188] = [241, 0.68, 0.58, 0.52]\n",
        "quality_dict[189] = [242, 0.59, 0.7, 0.69]\n",
        "quality_dict[190] = [243, 1.09, 0.84, 0.91]\n",
        "\n",
        "quality_dict[191] = [244, 0.73, 0.79, 0.68]\n",
        "quality_dict[192] = [245, 0.56, 0.54, 7.13]\n",
        "quality_dict[193] = [246, 1.23, 1.85, 0.63]\n",
        "quality_dict[194] = [247, 0.8, 0.66, 0.54]\n",
        "quality_dict[195] = [248, 0.14, 0.65, 0.69]\n",
        "quality_dict[196] = [250, 0.79, 0.84, 0.77]\n",
        "quality_dict[197] = [251, 0.99, 0.95, 0.99]\n",
        "quality_dict[198] = [252, 0.78, 0.38, 10.22]\n",
        "quality_dict[199] = [253, 0.8, 0.89, 0.92]\n",
        "quality_dict[200] = [254, 0.51, 0.84, 0.75]\n",
        "\n",
        "quality_dict[201] = [256, 0.95, 0.72, 1.25]\n",
        "quality_dict[202] = [257, 0.63, 0.69, 0.87]\n",
        "quality_dict[203] = [259, 0.59, 0.62, 0.67]\n",
        "quality_dict[204] = [403, 0.92, 0.92, 0.92]\n",
        "quality_dict[205] = [404, 1.4, 1, 0.96]\n",
        "quality_dict[206] = [405, 0.72, 0.79, 0.96]\n",
        "quality_dict[207] = [406, 0.28, 0.45, 0.54]\n",
        "quality_dict[208] = [407, 0.84, 0.82, 0.76]\n",
        "quality_dict[209] = [409, 0.84, 1, 0.89]\n",
        "quality_dict[210] = [410, 0.94, 0.91, 0.9]\n",
        "\n",
        "quality_dict[211] = [411, 1.09, 0.92, 1.05]\n",
        "quality_dict[212] = [412, 0.95, 0.7, 0.99]\n",
        "quality_dict[213] = [413, 0.74, 0.67, 0.63]\n",
        "quality_dict[214] = [414, 0.93, 1.34, 1.4]\n",
        "quality_dict[215] = [415, 1.15, 1.38, 1.19]\n",
        "quality_dict[216] = [416, 0.96, 0.94, 1.01]\n",
        "quality_dict[217] = [417, 1.12, 1.32, 1.38]\n",
        "quality_dict[218] = [418, 0.96, 0.87, 1.06]\n",
        "quality_dict[219] = [419, 1.13, 1, 0.81]\n"
      ],
      "metadata": {
        "id": "b1vf3Riexko-"
      },
      "id": "b1vf3Riexko-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select all segments with positive quality."
      ],
      "metadata": {
        "id": "JJ1lmTLUE7Wj"
      },
      "id": "JJ1lmTLUE7Wj"
    },
    {
      "cell_type": "code",
      "source": [
        "# most of data have three segments, only few of them have some negative quality segments\n",
        "# -> just throw away those segments\n",
        "not_choose = []\n",
        "for subject, segment in quality_dict.items():\n",
        "  for seg, quality in enumerate(quality_dict[subject]):\n",
        "    if quality < 0:\n",
        "      not_choose.append((subject, seg))\n",
        "\n",
        "print(not_choose)\n",
        "print(len(not_choose))"
      ],
      "metadata": {
        "id": "NE8mjNfWzl94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f096ce0d-1020-484a-e4e8-d52f2745e085"
      },
      "id": "NE8mjNfWzl94",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(7, 3), (23, 3), (83, 3), (88, 2), (89, 2), (103, 3)]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Dataset"
      ],
      "metadata": {
        "id": "P_udZMLyFAV_"
      },
      "id": "P_udZMLyFAV_"
    },
    {
      "cell_type": "code",
      "source": [
        "class BPDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, ppg_dir, label_path, normalize, choose_class=[0,1,2]):\n",
        "\n",
        "        self.ppg_dir = ppg_dir\n",
        "        self.label_path = label_path\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        self.subjectid = []\n",
        "        self.normalize=normalize\n",
        "        \n",
        "        # read BP labels (Label: 'Stage 1 hypertension' or 'Stage 2 hypertension'-> 2; 'Prehypertension'-> 1; 'Normal'-> 0)\n",
        "        df = pd.read_csv(label_path, skiprows=1)\n",
        "        #print(set(df[\"Hypertension\"]))\n",
        "        # choose class\n",
        "        class_id = [[] for i in range(3)]\n",
        "        for subject in range(219):\n",
        "          if df['Hypertension'][subject] == 'Stage 1 hypertension' or df['Hypertension'][subject] == 'Stage 2 hypertension':\n",
        "            class_id[2].append(subject+1)\n",
        "          elif df['Hypertension'][subject] == 'Prehypertension':\n",
        "            class_id[1].append(subject+1)\n",
        "          elif df['Hypertension'][subject] == 'Normal':\n",
        "            class_id[0].append(subject+1)\n",
        "\n",
        "        for c in choose_class:\n",
        "          # c=0,1,2\n",
        "          for subject in class_id[c]:\n",
        "            subjectid = quality_dict[subject][0]\n",
        "            if subject == 180:\n",
        "              continue\n",
        "            elif subject in [7, 23, 83, 88, 89, 103]:\n",
        "              self.label.extend([c]*2)\n",
        "            else:\n",
        "              self.label.extend([c]*3)\n",
        "            # read ppg data\n",
        "            for segnum in range(1, 4):\n",
        "              if (subject, segnum) not in [(7, 3), (23, 3), (83, 3), (88, 2), (89, 2), (103, 3), (180, 1), (180, 2), (180, 3)]:\n",
        "                ppg_path = os.path.join(ppg_dir, '{}_{}.txt'.format(subjectid, segnum))\n",
        "                if os.path.exists(ppg_path):\n",
        "                  with open(ppg_path) as f:\n",
        "                    lines = f.readlines()[0].split('\\t')[:-1]\n",
        "                    if len(lines) != 2100:\n",
        "                      print(subject, subjectid, segment, len(lines))\n",
        "                      continue\n",
        "                    ppg = torch.Tensor([float(x) for x in lines])\n",
        "                    ppg = ppg.reshape((1,2100))\n",
        "                    self.data.append(ppg)\n",
        "                    self.subjectid.append(subjectid)\n",
        "        self.label = torch.Tensor(self.label)\n",
        "        self.label = self.label.type(torch.long)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        data = (data-self.normalize['mean'])/self.normalize['std'] #normalization\n",
        "        label = self.label[index]\n",
        "        subjectid = self.subjectid[index]\n",
        "        return data, label, subjectid\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "FUt2tVAuxJd-"
      },
      "id": "FUt2tVAuxJd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-Class classification (Sigmoid)\n",
        "\\[\"Normal\", \"Prehypertension\"]: choose_class=\\[0,1]  \n",
        "\n",
        "\\[\"Normal\", \"hypertension\"]: choose_class=\\[0,2]"
      ],
      "metadata": {
        "id": "fRa58ojnoAGR"
      },
      "id": "fRa58ojnoAGR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils (Define lr_decay, calculate accuracy, sensitivity, specificity)"
      ],
      "metadata": {
        "id": "DeN4q5MiFxvK"
      },
      "id": "DeN4q5MiFxvK"
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_decay(optimizer, decay_rate=.9):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * decay_rate\n",
        "\n",
        "class averageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k.mul_(1.0 / batch_size))\n",
        "    return res"
      ],
      "metadata": {
        "id": "eMkEVZmfrn-N"
      },
      "id": "eMkEVZmfrn-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define train, validation functions"
      ],
      "metadata": {
        "id": "K3GjOt9KGYvv"
      },
      "id": "K3GjOt9KGYvv"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, optimizer, epoch, criterion, binary=False):\n",
        "\n",
        "    losses = averageMeter()\n",
        "    ACC = averageMeter()\n",
        "\n",
        "    # setup training mode\n",
        "    model.train()\n",
        "\n",
        "    for (step, value) in enumerate(data_loader):\n",
        "\n",
        "        data = value[0].cuda()\n",
        "        target = value[1].cuda(non_blocking=True)\n",
        "\n",
        "        # forward\n",
        "        output = model(data).squeeze()\n",
        "\n",
        "        # compute loss\n",
        "        if not binary:\n",
        "            loss = criterion(output, target)\n",
        "        else:\n",
        "            loss = criterion(output, target.float())\n",
        "        losses.update(loss.item(), data.size(0))\n",
        "\n",
        "        # compute acc\n",
        "        if not binary:\n",
        "            pred = torch.max(output, dim=1)[1].data.cpu().numpy()\n",
        "            acc = accuracy(output, target, topk=(1,))[0]\n",
        "        else:\n",
        "            pred = torch.gt(output, 0.5).long()\n",
        "            acc = (target == pred).float().mean()\n",
        "        ACC.update(acc.item(), data.size(0))\n",
        "\n",
        "        # compute confusion matrix\n",
        "        # confmat = ConfusionMatrix(task=\"multiclass\", num_classes=2)\n",
        "        # conf = confmat(pred, target)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # logging\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('Epoch: [{}/{}]\\t' \\\n",
        "        'LR: [{:.6g}]\\t' \\\n",
        "        'Loss {loss.avg:.4f}\\t' \\\n",
        "        'Acc {acc.avg:.3f}'.format(\n",
        "            epoch + 1, n_epoch, curr_lr, loss=losses, acc=ACC\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # save last model\n",
        "    state = {\n",
        "        'epoch': epoch + 1,\n",
        "        'acc': acc,\n",
        "        'model_state': model.state_dict(),\n",
        "        'opt_state': optimizer.state_dict()\n",
        "    }\n",
        "    checkpoint = os.path.join('/content/drive/MyDrive/Data/5459299', 'last_checkpoint.pkl')\n",
        "    torch.save(state, checkpoint)\n",
        "    print('[Checkpoint] {} is saved.'.format(checkpoint))\n",
        "    print('Training is done.')\n",
        "\n",
        "    return ACC.avg, losses.avg\n",
        "\n",
        "\n",
        "def val(data_loader, model, criterion, binary=False):\n",
        "\n",
        "    losses = averageMeter()\n",
        "    ACC = averageMeter()\n",
        "\n",
        "    # setup evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for (step, value) in enumerate(data_loader):\n",
        "\n",
        "        data = value[0].cuda()\n",
        "        target = value[1].cuda(non_blocking=True)\n",
        "\n",
        "        # forward\n",
        "        output = model(data).squeeze()\n",
        "\n",
        "        # compute acc\n",
        "        if not binary:\n",
        "            pred = torch.max(output, dim=1)[1].data.cpu().numpy()\n",
        "            acc = accuracy(output, target, topk=(1,))[0]\n",
        "        else:\n",
        "            pred = torch.gt(output, 0.5).long()\n",
        "            acc = (target == pred).float().mean()    \n",
        "        ACC.update(acc.item(), data.size(0))\n",
        "\n",
        "        # compute loss\n",
        "        if not binary:\n",
        "            loss = criterion(output, target)\n",
        "        else:\n",
        "            loss = criterion(output, target.float())\n",
        "        losses.update(loss.item(), data.size(0))\n",
        "\n",
        "    # logging\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('[Val]' \\\n",
        "        'Loss {loss.avg:.4f}\\t' \\\n",
        "        'Acc {acc.avg:.3f}'.format(\n",
        "            loss=losses, acc=ACC\n",
        "        )\n",
        "    )\n",
        "    return ACC.avg, losses.avg"
      ],
      "metadata": {
        "id": "yYT3dsWirhVG"
      },
      "id": "yYT3dsWirhVG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: Our Conv3Net (3-layer convolution neural network) & CNN_LSTM model from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9787648"
      ],
      "metadata": {
        "id": "791Rv7kMGctE"
      },
      "id": "791Rv7kMGctE"
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3Net(nn.Module):\n",
        "    def __init__(self, n_class=2):\n",
        "        super(Conv3Net, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=30, stride=3, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, kernel_size=15, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7),\n",
        "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "IzfsIrvr5QQs"
      },
      "id": "IzfsIrvr5QQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, n_class=2):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=32, batch_first=True)\n",
        "        self.conv1 = nn.Conv1d(1, 8, 16, stride=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(8)\n",
        "        self.lstm2 = nn.LSTM(input_size=7, hidden_size=16, batch_first=True)\n",
        "        self.conv2 = nn.Conv1d(1, 32, 6)\n",
        "        self.mp = nn.MaxPool1d(2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.lstm3 = nn.LSTM(input_size=5, hidden_size=8, batch_first=True)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(8, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.conv1(x[:, -1, :].unsqueeze(1))\n",
        "        x = self.bn1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.conv2(x[:, -1, :].unsqueeze(1))\n",
        "        x = self.bn2(self.mp(x))\n",
        "        x, _ = self.lstm3(x)\n",
        "        x = self.dropout(x[:, -1, :])\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "N8BSTIkp7OFz"
      },
      "id": "N8BSTIkp7OFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Results: \\[\"Normal\", \"Prehypertension\"]"
      ],
      "metadata": {
        "id": "fqL4vZUPoYgR"
      },
      "id": "fqL4vZUPoYgR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd377c1a",
        "outputId": "63f70f4c-ac58-4c3d-db80-1a2e275275e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 487\n",
            "312\n",
            "78\n",
            "97\n"
          ]
        }
      ],
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,1])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [312, 78, 97])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "id": "dd377c1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61d28385",
        "outputId": "c48ca7ee-4469-44df-f22c-18ecf90bcfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "id": "61d28385"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "38b7584d",
        "outputId": "56857762-654a-4895-f1c3-acbca7b574bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "id": "38b7584d"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(2).cuda()\n",
        "#model = CNN_LSTM(2).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.BCELoss()\n",
        "binary = False\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion, binary)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion, binary)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion, binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "2MwjTY-CzFiB",
        "outputId": "a8f04ef4-c802-4708-fa3c-0f2bc6b20743"
      },
      "id": "2MwjTY-CzFiB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-86edd45b09f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-eb06337aa40c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, epoch, criterion, binary)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-0759ee4f102b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Results: \\[\"Normal\", \"hypertension\"]"
      ],
      "metadata": {
        "id": "8MNi0KSX0RgX"
      },
      "id": "8MNi0KSX0RgX"
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,2])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [255, 64, 80])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqHzByty0bCz",
        "outputId": "dd36d010-2ddf-4bd6-cf26-9888f63fd4ce"
      },
      "id": "vqHzByty0bCz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 399\n",
            "255\n",
            "64\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "SzF7jLMORncb",
        "outputId": "0b33b751-ecab-4cc2-fa0a-db59ca5f54d1"
      },
      "id": "SzF7jLMORncb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBhHuDR5lHD",
        "outputId": "2870d330-b543-418a-fbcf-3f0f3c6e838b"
      },
      "id": "crBhHuDR5lHD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(2).cuda()\n",
        "#model = CNN_LSTM(2).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "0-Jvl1g601uz",
        "outputId": "3a7106f8-6e50-422d-9eb5-106786310c6c"
      },
      "id": "0-Jvl1g601uz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7def077c3ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-eb06337aa40c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, epoch, criterion, binary)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0759ee4f102b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our Model: 3-Class classification (Softmax)\n",
        "### Our Results: \\[\"Normal\", \"Prehypertension\", \"hypertension\"]"
      ],
      "metadata": {
        "id": "HTXtwIrl5F3R"
      },
      "id": "HTXtwIrl5F3R"
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3Net(nn.Module):\n",
        "    def __init__(self, n_class=3):\n",
        "        super(Conv3Net, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=30, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, kernel_size=15, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7),\n",
        "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "zcw22eY7lHuH"
      },
      "id": "zcw22eY7lHuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,1,2])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [415, 104, 129])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLY2TjiE5-R7",
        "outputId": "9fb2888d-00d6-4021-e84f-c4f3b9d4cdd3"
      },
      "id": "xLY2TjiE5-R7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 648\n",
            "415\n",
            "104\n",
            "129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PvZSPBw6Dp5",
        "outputId": "9017c6c9-3b5e-466d-c787-90983a92593b"
      },
      "id": "4PvZSPBw6Dp5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "uAiwYbRB6IR4",
        "outputId": "2ab91502-78c6-4e5e-d7d6-44a260e3f7bb"
      },
      "id": "uAiwYbRB6IR4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels, val_labels, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSf9xH5U7B0I",
        "outputId": "607bf88b-9fa7-4a65-e435-54903c2fef35"
      },
      "id": "dSf9xH5U7B0I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[149, 160, 106] [39, 39, 26] [50, 50, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(3).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2w5A784l8Ua",
        "outputId": "2e6a8e90-944b-42d4-bbf5-b6a3774d0f6b"
      },
      "id": "K2w5A784l8Ua",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/180]\tLR: [0.01]\tLoss 1.0831\tAcc 0.378\n",
            "[Val]Loss 1.0601\tAcc 0.442\n",
            "Epoch: [2/180]\tLR: [0.01]\tLoss 1.0596\tAcc 0.410\n",
            "[Val]Loss 1.0136\tAcc 0.404\n",
            "Epoch: [3/180]\tLR: [0.01]\tLoss 1.0526\tAcc 0.427\n",
            "[Val]Loss 1.0060\tAcc 0.452\n",
            "Epoch: [4/180]\tLR: [0.01]\tLoss 1.0265\tAcc 0.441\n",
            "[Val]Loss 1.0091\tAcc 0.442\n",
            "Epoch: [5/180]\tLR: [0.01]\tLoss 1.0400\tAcc 0.419\n",
            "[Val]Loss 1.0052\tAcc 0.442\n",
            "Epoch: [6/180]\tLR: [0.01]\tLoss 1.0386\tAcc 0.441\n",
            "[Val]Loss 1.0312\tAcc 0.442\n",
            "Epoch: [7/180]\tLR: [0.01]\tLoss 1.0166\tAcc 0.446\n",
            "[Val]Loss 1.0648\tAcc 0.413\n",
            "Epoch: [8/180]\tLR: [0.01]\tLoss 1.0137\tAcc 0.436\n",
            "[Val]Loss 1.0203\tAcc 0.433\n",
            "Epoch: [9/180]\tLR: [0.01]\tLoss 1.0072\tAcc 0.446\n",
            "[Val]Loss 1.0246\tAcc 0.404\n",
            "Epoch: [10/180]\tLR: [0.01]\tLoss 1.0124\tAcc 0.441\n",
            "[Val]Loss 1.0128\tAcc 0.404\n",
            "Epoch: [11/180]\tLR: [0.01]\tLoss 1.0004\tAcc 0.441\n",
            "[Val]Loss 1.0285\tAcc 0.394\n",
            "Epoch: [12/180]\tLR: [0.01]\tLoss 0.9875\tAcc 0.484\n",
            "[Val]Loss 1.0941\tAcc 0.394\n",
            "Epoch: [13/180]\tLR: [0.01]\tLoss 1.0153\tAcc 0.453\n",
            "[Val]Loss 1.0946\tAcc 0.279\n",
            "Epoch: [14/180]\tLR: [0.01]\tLoss 1.0004\tAcc 0.427\n",
            "[Val]Loss 1.0349\tAcc 0.423\n",
            "Epoch: [15/180]\tLR: [0.01]\tLoss 0.9856\tAcc 0.480\n",
            "[Val]Loss 1.0459\tAcc 0.317\n",
            "Epoch: [16/180]\tLR: [0.01]\tLoss 0.9742\tAcc 0.475\n",
            "[Val]Loss 1.0292\tAcc 0.433\n",
            "Epoch: [17/180]\tLR: [0.01]\tLoss 0.9796\tAcc 0.496\n",
            "[Val]Loss 1.0282\tAcc 0.394\n",
            "Epoch: [18/180]\tLR: [0.01]\tLoss 0.9908\tAcc 0.492\n",
            "[Val]Loss 1.0217\tAcc 0.423\n",
            "Epoch: [19/180]\tLR: [0.01]\tLoss 0.9694\tAcc 0.504\n",
            "[Val]Loss 1.0423\tAcc 0.375\n",
            "Epoch: [20/180]\tLR: [0.01]\tLoss 0.9767\tAcc 0.489\n",
            "[Val]Loss 1.0350\tAcc 0.433\n",
            "Epoch: [21/180]\tLR: [0.01]\tLoss 0.9524\tAcc 0.487\n",
            "[Val]Loss 1.0948\tAcc 0.423\n",
            "Epoch: [22/180]\tLR: [0.01]\tLoss 0.9671\tAcc 0.492\n",
            "[Val]Loss 1.0408\tAcc 0.375\n",
            "Epoch: [23/180]\tLR: [0.01]\tLoss 0.9675\tAcc 0.504\n",
            "[Val]Loss 1.0215\tAcc 0.404\n",
            "Epoch: [24/180]\tLR: [0.01]\tLoss 0.9697\tAcc 0.508\n",
            "[Val]Loss 1.0054\tAcc 0.433\n",
            "Epoch: [25/180]\tLR: [0.01]\tLoss 0.9682\tAcc 0.489\n",
            "[Val]Loss 1.0665\tAcc 0.442\n",
            "Epoch: [26/180]\tLR: [0.01]\tLoss 0.9490\tAcc 0.528\n",
            "[Val]Loss 1.0410\tAcc 0.404\n",
            "Epoch: [27/180]\tLR: [0.01]\tLoss 0.9361\tAcc 0.520\n",
            "[Val]Loss 1.0607\tAcc 0.413\n",
            "Epoch: [28/180]\tLR: [0.01]\tLoss 0.9454\tAcc 0.533\n",
            "[Val]Loss 1.0499\tAcc 0.433\n",
            "Epoch: [29/180]\tLR: [0.01]\tLoss 0.9362\tAcc 0.535\n",
            "[Val]Loss 1.0558\tAcc 0.413\n",
            "Epoch: [30/180]\tLR: [0.01]\tLoss 0.9281\tAcc 0.535\n",
            "[Val]Loss 1.0965\tAcc 0.385\n",
            "Epoch: [31/180]\tLR: [0.01]\tLoss 0.9483\tAcc 0.513\n",
            "[Val]Loss 1.0063\tAcc 0.452\n",
            "Epoch: [32/180]\tLR: [0.01]\tLoss 0.8876\tAcc 0.552\n",
            "[Val]Loss 1.0413\tAcc 0.519\n",
            "Epoch: [33/180]\tLR: [0.01]\tLoss 0.9172\tAcc 0.559\n",
            "[Val]Loss 1.0623\tAcc 0.433\n",
            "Epoch: [34/180]\tLR: [0.01]\tLoss 0.9277\tAcc 0.525\n",
            "[Val]Loss 1.1161\tAcc 0.433\n",
            "Epoch: [35/180]\tLR: [0.01]\tLoss 0.8951\tAcc 0.547\n",
            "[Val]Loss 1.1198\tAcc 0.404\n",
            "Epoch: [36/180]\tLR: [0.01]\tLoss 0.8685\tAcc 0.549\n",
            "[Val]Loss 1.0923\tAcc 0.423\n",
            "Epoch: [37/180]\tLR: [0.01]\tLoss 0.9112\tAcc 0.564\n",
            "[Val]Loss 1.1527\tAcc 0.394\n",
            "Epoch: [38/180]\tLR: [0.01]\tLoss 0.8986\tAcc 0.537\n",
            "[Val]Loss 1.0108\tAcc 0.462\n",
            "Epoch: [39/180]\tLR: [0.01]\tLoss 0.8658\tAcc 0.578\n",
            "[Val]Loss 1.1763\tAcc 0.442\n",
            "Epoch: [40/180]\tLR: [0.01]\tLoss 0.8362\tAcc 0.595\n",
            "[Val]Loss 1.0478\tAcc 0.481\n",
            "Epoch: [41/180]\tLR: [0.01]\tLoss 0.8575\tAcc 0.588\n",
            "[Val]Loss 0.9994\tAcc 0.529\n",
            "Epoch: [42/180]\tLR: [0.01]\tLoss 0.8497\tAcc 0.571\n",
            "[Val]Loss 1.0837\tAcc 0.471\n",
            "Epoch: [43/180]\tLR: [0.01]\tLoss 0.8703\tAcc 0.588\n",
            "[Val]Loss 1.0762\tAcc 0.481\n",
            "Epoch: [44/180]\tLR: [0.01]\tLoss 0.8336\tAcc 0.598\n",
            "[Val]Loss 1.1173\tAcc 0.500\n",
            "Epoch: [45/180]\tLR: [0.01]\tLoss 0.8385\tAcc 0.619\n",
            "[Val]Loss 1.0852\tAcc 0.462\n",
            "Epoch: [46/180]\tLR: [0.01]\tLoss 0.7993\tAcc 0.602\n",
            "[Val]Loss 1.1265\tAcc 0.471\n",
            "Epoch: [47/180]\tLR: [0.01]\tLoss 0.8275\tAcc 0.602\n",
            "[Val]Loss 1.0316\tAcc 0.500\n",
            "Epoch: [48/180]\tLR: [0.01]\tLoss 0.8170\tAcc 0.581\n",
            "[Val]Loss 1.0547\tAcc 0.548\n",
            "Epoch: [49/180]\tLR: [0.01]\tLoss 0.7887\tAcc 0.624\n",
            "[Val]Loss 1.2032\tAcc 0.462\n",
            "Epoch: [50/180]\tLR: [0.01]\tLoss 0.9000\tAcc 0.610\n",
            "[Val]Loss 1.0319\tAcc 0.481\n",
            "Epoch: [51/180]\tLR: [0.01]\tLoss 0.7817\tAcc 0.612\n",
            "[Val]Loss 1.0831\tAcc 0.558\n",
            "Epoch: [52/180]\tLR: [0.01]\tLoss 0.8544\tAcc 0.600\n",
            "[Val]Loss 1.1357\tAcc 0.442\n",
            "Epoch: [53/180]\tLR: [0.01]\tLoss 0.8791\tAcc 0.561\n",
            "[Val]Loss 1.1528\tAcc 0.471\n",
            "Epoch: [54/180]\tLR: [0.01]\tLoss 0.7976\tAcc 0.634\n",
            "[Val]Loss 1.2217\tAcc 0.510\n",
            "Epoch: [55/180]\tLR: [0.01]\tLoss 0.7731\tAcc 0.658\n",
            "[Val]Loss 1.5524\tAcc 0.442\n",
            "Epoch: [56/180]\tLR: [0.01]\tLoss 0.7241\tAcc 0.665\n",
            "[Val]Loss 1.3547\tAcc 0.519\n",
            "Epoch: [57/180]\tLR: [0.01]\tLoss 0.6819\tAcc 0.689\n",
            "[Val]Loss 1.3752\tAcc 0.500\n",
            "Epoch: [58/180]\tLR: [0.01]\tLoss 0.7373\tAcc 0.672\n",
            "[Val]Loss 1.4396\tAcc 0.452\n",
            "Epoch: [59/180]\tLR: [0.01]\tLoss 0.7585\tAcc 0.629\n",
            "[Val]Loss 1.5500\tAcc 0.442\n",
            "Epoch: [60/180]\tLR: [0.01]\tLoss 0.7637\tAcc 0.643\n",
            "[Val]Loss 1.4451\tAcc 0.510\n",
            "Epoch: [61/180]\tLR: [0.001]\tLoss 0.6396\tAcc 0.708\n",
            "[Val]Loss 1.3391\tAcc 0.471\n",
            "Epoch: [62/180]\tLR: [0.001]\tLoss 0.5766\tAcc 0.754\n",
            "[Val]Loss 1.3929\tAcc 0.500\n",
            "Epoch: [63/180]\tLR: [0.001]\tLoss 0.5500\tAcc 0.778\n",
            "[Val]Loss 1.4503\tAcc 0.490\n",
            "Epoch: [64/180]\tLR: [0.001]\tLoss 0.5284\tAcc 0.773\n",
            "[Val]Loss 1.4853\tAcc 0.500\n",
            "Epoch: [65/180]\tLR: [0.001]\tLoss 0.5100\tAcc 0.771\n",
            "[Val]Loss 1.5311\tAcc 0.500\n",
            "Epoch: [66/180]\tLR: [0.001]\tLoss 0.4966\tAcc 0.778\n",
            "[Val]Loss 1.5922\tAcc 0.500\n",
            "Epoch: [67/180]\tLR: [0.001]\tLoss 0.4802\tAcc 0.788\n",
            "[Val]Loss 1.6208\tAcc 0.500\n",
            "Epoch: [68/180]\tLR: [0.001]\tLoss 0.4602\tAcc 0.812\n",
            "[Val]Loss 1.6646\tAcc 0.500\n",
            "Epoch: [69/180]\tLR: [0.001]\tLoss 0.4536\tAcc 0.798\n",
            "[Val]Loss 1.6649\tAcc 0.519\n",
            "Epoch: [70/180]\tLR: [0.001]\tLoss 0.4372\tAcc 0.812\n",
            "[Val]Loss 1.7067\tAcc 0.529\n",
            "Epoch: [71/180]\tLR: [0.001]\tLoss 0.4276\tAcc 0.822\n",
            "[Val]Loss 1.7510\tAcc 0.500\n",
            "Epoch: [72/180]\tLR: [0.001]\tLoss 0.4163\tAcc 0.827\n",
            "[Val]Loss 1.8744\tAcc 0.490\n",
            "Epoch: [73/180]\tLR: [0.001]\tLoss 0.4078\tAcc 0.829\n",
            "[Val]Loss 1.8422\tAcc 0.500\n",
            "Epoch: [74/180]\tLR: [0.001]\tLoss 0.3939\tAcc 0.841\n",
            "[Val]Loss 1.9038\tAcc 0.510\n",
            "Epoch: [75/180]\tLR: [0.001]\tLoss 0.3846\tAcc 0.851\n",
            "[Val]Loss 1.9588\tAcc 0.500\n",
            "Epoch: [76/180]\tLR: [0.001]\tLoss 0.3750\tAcc 0.843\n",
            "[Val]Loss 1.9771\tAcc 0.510\n",
            "Epoch: [77/180]\tLR: [0.001]\tLoss 0.3632\tAcc 0.855\n",
            "[Val]Loss 2.0311\tAcc 0.519\n",
            "Epoch: [78/180]\tLR: [0.001]\tLoss 0.3507\tAcc 0.853\n",
            "[Val]Loss 2.1386\tAcc 0.510\n",
            "Epoch: [79/180]\tLR: [0.001]\tLoss 0.3389\tAcc 0.872\n",
            "[Val]Loss 2.1084\tAcc 0.510\n",
            "Epoch: [80/180]\tLR: [0.001]\tLoss 0.3373\tAcc 0.865\n",
            "[Val]Loss 2.1173\tAcc 0.519\n",
            "Epoch: [81/180]\tLR: [0.001]\tLoss 0.3312\tAcc 0.880\n",
            "[Val]Loss 2.1658\tAcc 0.519\n",
            "Epoch: [82/180]\tLR: [0.001]\tLoss 0.3268\tAcc 0.870\n",
            "[Val]Loss 2.3439\tAcc 0.519\n",
            "Epoch: [83/180]\tLR: [0.001]\tLoss 0.3217\tAcc 0.872\n",
            "[Val]Loss 2.2822\tAcc 0.500\n",
            "Epoch: [84/180]\tLR: [0.001]\tLoss 0.3076\tAcc 0.892\n",
            "[Val]Loss 2.3379\tAcc 0.529\n",
            "Epoch: [85/180]\tLR: [0.001]\tLoss 0.2944\tAcc 0.892\n",
            "[Val]Loss 2.3902\tAcc 0.490\n",
            "Epoch: [86/180]\tLR: [0.001]\tLoss 0.2866\tAcc 0.894\n",
            "[Val]Loss 2.4643\tAcc 0.519\n",
            "Epoch: [87/180]\tLR: [0.001]\tLoss 0.2826\tAcc 0.896\n",
            "[Val]Loss 2.4917\tAcc 0.519\n",
            "Epoch: [88/180]\tLR: [0.001]\tLoss 0.2740\tAcc 0.901\n",
            "[Val]Loss 2.5860\tAcc 0.500\n",
            "Epoch: [89/180]\tLR: [0.001]\tLoss 0.2690\tAcc 0.901\n",
            "[Val]Loss 2.6238\tAcc 0.519\n",
            "Epoch: [90/180]\tLR: [0.001]\tLoss 0.2731\tAcc 0.892\n",
            "[Val]Loss 2.6826\tAcc 0.500\n",
            "Epoch: [91/180]\tLR: [0.001]\tLoss 0.2552\tAcc 0.904\n",
            "[Val]Loss 2.7363\tAcc 0.510\n",
            "Epoch: [92/180]\tLR: [0.001]\tLoss 0.2436\tAcc 0.911\n",
            "[Val]Loss 2.7983\tAcc 0.490\n",
            "Epoch: [93/180]\tLR: [0.001]\tLoss 0.2378\tAcc 0.920\n",
            "[Val]Loss 2.8010\tAcc 0.519\n",
            "Epoch: [94/180]\tLR: [0.001]\tLoss 0.2293\tAcc 0.916\n",
            "[Val]Loss 2.9292\tAcc 0.519\n",
            "Epoch: [95/180]\tLR: [0.001]\tLoss 0.2383\tAcc 0.908\n",
            "[Val]Loss 2.9977\tAcc 0.510\n",
            "Epoch: [96/180]\tLR: [0.001]\tLoss 0.2225\tAcc 0.920\n",
            "[Val]Loss 2.9596\tAcc 0.519\n",
            "Epoch: [97/180]\tLR: [0.001]\tLoss 0.2156\tAcc 0.913\n",
            "[Val]Loss 3.1511\tAcc 0.510\n",
            "Epoch: [98/180]\tLR: [0.001]\tLoss 0.2139\tAcc 0.920\n",
            "[Val]Loss 3.1434\tAcc 0.538\n",
            "Epoch: [99/180]\tLR: [0.001]\tLoss 0.2187\tAcc 0.918\n",
            "[Val]Loss 3.2234\tAcc 0.510\n",
            "Epoch: [100/180]\tLR: [0.001]\tLoss 0.2003\tAcc 0.930\n",
            "[Val]Loss 3.3266\tAcc 0.548\n",
            "Epoch: [101/180]\tLR: [0.001]\tLoss 0.2066\tAcc 0.916\n",
            "[Val]Loss 3.2290\tAcc 0.529\n",
            "Epoch: [102/180]\tLR: [0.001]\tLoss 0.1881\tAcc 0.933\n",
            "[Val]Loss 3.3707\tAcc 0.500\n",
            "Epoch: [103/180]\tLR: [0.001]\tLoss 0.1772\tAcc 0.942\n",
            "[Val]Loss 3.3378\tAcc 0.510\n",
            "Epoch: [104/180]\tLR: [0.001]\tLoss 0.1731\tAcc 0.935\n",
            "[Val]Loss 3.5726\tAcc 0.529\n",
            "Epoch: [105/180]\tLR: [0.001]\tLoss 0.1812\tAcc 0.942\n",
            "[Val]Loss 3.5106\tAcc 0.519\n",
            "Epoch: [106/180]\tLR: [0.001]\tLoss 0.1801\tAcc 0.942\n",
            "[Val]Loss 3.4542\tAcc 0.538\n",
            "Epoch: [107/180]\tLR: [0.001]\tLoss 0.1645\tAcc 0.947\n",
            "[Val]Loss 3.6942\tAcc 0.519\n",
            "Epoch: [108/180]\tLR: [0.001]\tLoss 0.1605\tAcc 0.952\n",
            "[Val]Loss 3.6171\tAcc 0.529\n",
            "Epoch: [109/180]\tLR: [0.001]\tLoss 0.1984\tAcc 0.928\n",
            "[Val]Loss 3.5296\tAcc 0.538\n",
            "Epoch: [110/180]\tLR: [0.001]\tLoss 0.1553\tAcc 0.957\n",
            "[Val]Loss 3.8703\tAcc 0.490\n",
            "Epoch: [111/180]\tLR: [0.001]\tLoss 0.1804\tAcc 0.942\n",
            "[Val]Loss 3.6954\tAcc 0.519\n",
            "Epoch: [112/180]\tLR: [0.001]\tLoss 0.1892\tAcc 0.925\n",
            "[Val]Loss 3.7814\tAcc 0.529\n",
            "Epoch: [113/180]\tLR: [0.001]\tLoss 0.1510\tAcc 0.952\n",
            "[Val]Loss 3.9329\tAcc 0.481\n",
            "Epoch: [114/180]\tLR: [0.001]\tLoss 0.1451\tAcc 0.945\n",
            "[Val]Loss 3.9052\tAcc 0.529\n",
            "Epoch: [115/180]\tLR: [0.001]\tLoss 0.1292\tAcc 0.957\n",
            "[Val]Loss 4.0132\tAcc 0.510\n",
            "Epoch: [116/180]\tLR: [0.001]\tLoss 0.1238\tAcc 0.964\n",
            "[Val]Loss 4.0159\tAcc 0.481\n",
            "Epoch: [117/180]\tLR: [0.001]\tLoss 0.1226\tAcc 0.969\n",
            "[Val]Loss 4.2020\tAcc 0.529\n",
            "Epoch: [118/180]\tLR: [0.001]\tLoss 0.1868\tAcc 0.920\n",
            "[Val]Loss 3.9409\tAcc 0.519\n",
            "Epoch: [119/180]\tLR: [0.001]\tLoss 0.2242\tAcc 0.908\n",
            "[Val]Loss 3.9644\tAcc 0.481\n",
            "Epoch: [120/180]\tLR: [0.001]\tLoss 0.1434\tAcc 0.945\n",
            "[Val]Loss 4.0404\tAcc 0.529\n",
            "Epoch: [121/180]\tLR: [0.0001]\tLoss 0.1054\tAcc 0.973\n",
            "[Val]Loss 4.0157\tAcc 0.510\n",
            "Epoch: [122/180]\tLR: [0.0001]\tLoss 0.1020\tAcc 0.973\n",
            "[Val]Loss 4.0336\tAcc 0.510\n",
            "Epoch: [123/180]\tLR: [0.0001]\tLoss 0.1004\tAcc 0.973\n",
            "[Val]Loss 4.0607\tAcc 0.510\n",
            "Epoch: [124/180]\tLR: [0.0001]\tLoss 0.0991\tAcc 0.973\n",
            "[Val]Loss 4.0629\tAcc 0.510\n",
            "Epoch: [125/180]\tLR: [0.0001]\tLoss 0.0981\tAcc 0.973\n",
            "[Val]Loss 4.0886\tAcc 0.500\n",
            "Epoch: [126/180]\tLR: [0.0001]\tLoss 0.0969\tAcc 0.973\n",
            "[Val]Loss 4.1103\tAcc 0.500\n",
            "Epoch: [127/180]\tLR: [0.0001]\tLoss 0.0961\tAcc 0.973\n",
            "[Val]Loss 4.1400\tAcc 0.500\n",
            "Epoch: [128/180]\tLR: [0.0001]\tLoss 0.0950\tAcc 0.973\n",
            "[Val]Loss 4.1485\tAcc 0.510\n",
            "Epoch: [129/180]\tLR: [0.0001]\tLoss 0.0939\tAcc 0.973\n",
            "[Val]Loss 4.1631\tAcc 0.510\n",
            "Epoch: [130/180]\tLR: [0.0001]\tLoss 0.0931\tAcc 0.973\n",
            "[Val]Loss 4.1763\tAcc 0.500\n",
            "Epoch: [131/180]\tLR: [0.0001]\tLoss 0.0924\tAcc 0.973\n",
            "[Val]Loss 4.1859\tAcc 0.510\n",
            "Epoch: [132/180]\tLR: [0.0001]\tLoss 0.0921\tAcc 0.973\n",
            "[Val]Loss 4.2050\tAcc 0.510\n",
            "Epoch: [133/180]\tLR: [0.0001]\tLoss 0.0909\tAcc 0.973\n",
            "[Val]Loss 4.2167\tAcc 0.510\n",
            "Epoch: [134/180]\tLR: [0.0001]\tLoss 0.0903\tAcc 0.973\n",
            "[Val]Loss 4.2231\tAcc 0.510\n",
            "Epoch: [135/180]\tLR: [0.0001]\tLoss 0.0895\tAcc 0.973\n",
            "[Val]Loss 4.2450\tAcc 0.510\n",
            "Epoch: [136/180]\tLR: [0.0001]\tLoss 0.0887\tAcc 0.973\n",
            "[Val]Loss 4.2407\tAcc 0.510\n",
            "Epoch: [137/180]\tLR: [0.0001]\tLoss 0.0882\tAcc 0.973\n",
            "[Val]Loss 4.2634\tAcc 0.510\n",
            "Epoch: [138/180]\tLR: [0.0001]\tLoss 0.0878\tAcc 0.973\n",
            "[Val]Loss 4.2677\tAcc 0.510\n",
            "Epoch: [139/180]\tLR: [0.0001]\tLoss 0.0868\tAcc 0.973\n",
            "[Val]Loss 4.2793\tAcc 0.510\n",
            "Epoch: [140/180]\tLR: [0.0001]\tLoss 0.0863\tAcc 0.973\n",
            "[Val]Loss 4.2941\tAcc 0.510\n",
            "Epoch: [141/180]\tLR: [0.0001]\tLoss 0.0862\tAcc 0.976\n",
            "[Val]Loss 4.3157\tAcc 0.510\n",
            "Epoch: [142/180]\tLR: [0.0001]\tLoss 0.0857\tAcc 0.976\n",
            "[Val]Loss 4.3096\tAcc 0.510\n",
            "Epoch: [143/180]\tLR: [0.0001]\tLoss 0.0849\tAcc 0.976\n",
            "[Val]Loss 4.3270\tAcc 0.510\n",
            "Epoch: [144/180]\tLR: [0.0001]\tLoss 0.0840\tAcc 0.976\n",
            "[Val]Loss 4.3305\tAcc 0.510\n",
            "Epoch: [145/180]\tLR: [0.0001]\tLoss 0.0839\tAcc 0.978\n",
            "[Val]Loss 4.3562\tAcc 0.510\n",
            "Epoch: [146/180]\tLR: [0.0001]\tLoss 0.0833\tAcc 0.978\n",
            "[Val]Loss 4.3589\tAcc 0.510\n",
            "Epoch: [147/180]\tLR: [0.0001]\tLoss 0.0827\tAcc 0.978\n",
            "[Val]Loss 4.3673\tAcc 0.510\n",
            "Epoch: [148/180]\tLR: [0.0001]\tLoss 0.0820\tAcc 0.978\n",
            "[Val]Loss 4.3891\tAcc 0.510\n",
            "Epoch: [149/180]\tLR: [0.0001]\tLoss 0.0820\tAcc 0.978\n",
            "[Val]Loss 4.3960\tAcc 0.510\n",
            "Epoch: [150/180]\tLR: [0.0001]\tLoss 0.0809\tAcc 0.978\n",
            "[Val]Loss 4.4011\tAcc 0.510\n",
            "Epoch: [151/180]\tLR: [0.0001]\tLoss 0.0804\tAcc 0.978\n",
            "[Val]Loss 4.4123\tAcc 0.510\n",
            "Epoch: [152/180]\tLR: [0.0001]\tLoss 0.0800\tAcc 0.978\n",
            "[Val]Loss 4.4166\tAcc 0.510\n",
            "Epoch: [153/180]\tLR: [0.0001]\tLoss 0.0792\tAcc 0.978\n",
            "[Val]Loss 4.4331\tAcc 0.510\n",
            "Epoch: [154/180]\tLR: [0.0001]\tLoss 0.0786\tAcc 0.981\n",
            "[Val]Loss 4.4396\tAcc 0.510\n",
            "Epoch: [155/180]\tLR: [0.0001]\tLoss 0.0782\tAcc 0.981\n",
            "[Val]Loss 4.4575\tAcc 0.510\n",
            "Epoch: [156/180]\tLR: [0.0001]\tLoss 0.0775\tAcc 0.981\n",
            "[Val]Loss 4.4667\tAcc 0.510\n",
            "Epoch: [157/180]\tLR: [0.0001]\tLoss 0.0770\tAcc 0.981\n",
            "[Val]Loss 4.4798\tAcc 0.510\n",
            "Epoch: [158/180]\tLR: [0.0001]\tLoss 0.0766\tAcc 0.981\n",
            "[Val]Loss 4.4805\tAcc 0.510\n",
            "Epoch: [159/180]\tLR: [0.0001]\tLoss 0.0766\tAcc 0.981\n",
            "[Val]Loss 4.5009\tAcc 0.510\n",
            "Epoch: [160/180]\tLR: [0.0001]\tLoss 0.0757\tAcc 0.981\n",
            "[Val]Loss 4.5062\tAcc 0.510\n",
            "Epoch: [161/180]\tLR: [0.0001]\tLoss 0.0755\tAcc 0.983\n",
            "[Val]Loss 4.5163\tAcc 0.510\n",
            "Epoch: [162/180]\tLR: [0.0001]\tLoss 0.0750\tAcc 0.981\n",
            "[Val]Loss 4.5315\tAcc 0.510\n",
            "Epoch: [163/180]\tLR: [0.0001]\tLoss 0.0745\tAcc 0.981\n",
            "[Val]Loss 4.5341\tAcc 0.510\n",
            "Epoch: [164/180]\tLR: [0.0001]\tLoss 0.0739\tAcc 0.986\n",
            "[Val]Loss 4.5468\tAcc 0.510\n",
            "Epoch: [165/180]\tLR: [0.0001]\tLoss 0.0736\tAcc 0.981\n",
            "[Val]Loss 4.5499\tAcc 0.510\n",
            "Epoch: [166/180]\tLR: [0.0001]\tLoss 0.0734\tAcc 0.983\n",
            "[Val]Loss 4.5686\tAcc 0.510\n",
            "Epoch: [167/180]\tLR: [0.0001]\tLoss 0.0730\tAcc 0.981\n",
            "[Val]Loss 4.5712\tAcc 0.510\n",
            "Epoch: [168/180]\tLR: [0.0001]\tLoss 0.0725\tAcc 0.986\n",
            "[Val]Loss 4.5851\tAcc 0.510\n",
            "Epoch: [169/180]\tLR: [0.0001]\tLoss 0.0722\tAcc 0.983\n",
            "[Val]Loss 4.5914\tAcc 0.510\n",
            "Epoch: [170/180]\tLR: [0.0001]\tLoss 0.0718\tAcc 0.983\n",
            "[Val]Loss 4.6130\tAcc 0.510\n",
            "Epoch: [171/180]\tLR: [0.0001]\tLoss 0.0717\tAcc 0.988\n",
            "[Val]Loss 4.6143\tAcc 0.510\n",
            "Epoch: [172/180]\tLR: [0.0001]\tLoss 0.0711\tAcc 0.986\n",
            "[Val]Loss 4.6290\tAcc 0.510\n",
            "Epoch: [173/180]\tLR: [0.0001]\tLoss 0.0707\tAcc 0.986\n",
            "[Val]Loss 4.6345\tAcc 0.510\n",
            "Epoch: [174/180]\tLR: [0.0001]\tLoss 0.0700\tAcc 0.986\n",
            "[Val]Loss 4.6548\tAcc 0.510\n",
            "Epoch: [175/180]\tLR: [0.0001]\tLoss 0.0696\tAcc 0.988\n",
            "[Val]Loss 4.6569\tAcc 0.510\n",
            "Epoch: [176/180]\tLR: [0.0001]\tLoss 0.0695\tAcc 0.986\n",
            "[Val]Loss 4.6679\tAcc 0.510\n",
            "Epoch: [177/180]\tLR: [0.0001]\tLoss 0.0688\tAcc 0.988\n",
            "[Val]Loss 4.6685\tAcc 0.510\n",
            "Epoch: [178/180]\tLR: [0.0001]\tLoss 0.0689\tAcc 0.983\n",
            "[Val]Loss 4.6862\tAcc 0.510\n",
            "Epoch: [179/180]\tLR: [0.0001]\tLoss 0.0682\tAcc 0.988\n",
            "[Val]Loss 4.6856\tAcc 0.510\n",
            "Epoch: [180/180]\tLR: [0.0001]\tLoss 0.0678\tAcc 0.986\n",
            "[Val]Loss 4.6916\tAcc 0.510\n",
            "[Val]Loss 4.0447\tAcc 0.442\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}