{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhB8-nozfVY"
      },
      "source": [
        "## Mount to Drive"
      ],
      "id": "MfhB8-nozfVY"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbICMMTxzhrb",
        "outputId": "f00a2d44-fcd3-4b07-94bc-bd7b37bb23d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "nbICMMTxzhrb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "4ca51692",
        "outputId": "7a2d9b2b-30a6-4a39-ca18-691dc5871d58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-611b3369-975b-4650-99dd-832f060178fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-611b3369-975b-4650-99dd-832f060178fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving modules.py to modules.py\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4139fa4b-c47a-4147-95e9-afc790643d95\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4139fa4b-c47a-4147-95e9-afc790643d95\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving backbone_models.py to backbone_models.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from google.colab import files\n",
        "\n",
        "from torchvision import transforms\n",
        "files.upload()\n",
        "from modules import train_model, test_model\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "files.upload()\n",
        "from backbone_models import ResNet18, VGG16\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data"
      ],
      "id": "4ca51692"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e57800d8"
      },
      "outputs": [],
      "source": [
        "ppg_dir = '/content/drive/MyDrive/Data/5459299/Data_File/subject'\n",
        "label_path = '/content/drive/MyDrive/Data/5459299/Data_File/PPG-BP dataset.csv'"
      ],
      "id": "e57800d8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose High Quality Data\n",
        "(From the dataset description, it says every subject has 3 segments of ppg signals, and we need to choose the segment with highest quality for each subject.)\n",
        "(But for now, we just choose all segments as long as the quality is positive, so we can have more data to train.)"
      ],
      "metadata": {
        "id": "w6-rwODsEzQ-"
      },
      "id": "w6-rwODsEzQ-"
    },
    {
      "cell_type": "code",
      "source": [
        "# organized data from https://www.nature.com/articles/sdata201820/tables/2\n",
        "\n",
        "quality_dict = dict()\n",
        "# key: subject number; value[0]: subject ID; value[1]:quality of segment 1; value[2]:quality of segment 2; value[3]:quality of segment 3\n",
        "quality_dict[1] = [2, 0.98, 0.96, 0.92]\n",
        "quality_dict[2] = [3, 0.69, 0.8, 0.81]\n",
        "quality_dict[3] = [6, 0.58, 0.59, 0.64]\n",
        "quality_dict[4] = [8, 0.96, 0.85, 0.87]\n",
        "quality_dict[5] = [9, 0.65, 0.67, 0.87]\n",
        "quality_dict[6] = [10, 0.59, 0.64, 0.34]\n",
        "quality_dict[7] = [11, 0.74, 0.67, -0.16]\n",
        "quality_dict[8] = [12, 0.23, 0.73, 0.41]\n",
        "quality_dict[9] = [13, 0.76, 0.84, 1.06]\n",
        "quality_dict[10] = [14, 0.77, 0.72, 0.15]\n",
        "\n",
        "quality_dict[11] = [15, 1.23, 0.77, 0.3]\n",
        "quality_dict[12] = [16, 0.64, 0.66, 0.83]\n",
        "quality_dict[13] = [17, 0.69, 0.9, 0.9]\n",
        "quality_dict[14] = [18, 0.87, 0.59, 1.05]\n",
        "quality_dict[15] = [19, 0.78, 0.19, 0.16]\n",
        "quality_dict[16] = [21, 0.65, 0.74, 0.75]\n",
        "quality_dict[17] = [22, 0.73, 0.44, 0.39]\n",
        "quality_dict[18] = [23, 0.7, 0.6, 0.74]\n",
        "quality_dict[19] = [24, 0.74, 0.74, 0.75]\n",
        "quality_dict[20] = [25, 1.38, 0.15, 0.78]\n",
        "\n",
        "quality_dict[21] = [26, 1.31, 0.47, 0.83]\n",
        "quality_dict[22] = [27, 1.86, 1.33, 1.26]\n",
        "quality_dict[23] = [29, 0.73, 0.6, -0.05]\n",
        "quality_dict[24] = [30, 0.86, 0.8, 0.76]\n",
        "quality_dict[25] = [31, 0.68, 0.81, 0.7]\n",
        "quality_dict[26] = [32, 1.06, 1.12, 1.23]\n",
        "quality_dict[27] = [34, 0.9, 0.79, 0.74]\n",
        "quality_dict[28] = [35, 0.94, 1.15, 1.18]\n",
        "quality_dict[29] = [38, 0.88, 0.66, 0.94]\n",
        "quality_dict[30] = [40, 0.21, 1.2, 0.9]\n",
        "\n",
        "quality_dict[31] = [41, 0.85, 0.78, 0.73]\n",
        "quality_dict[32] = [43, 0.52, 0.28, 0.53]\n",
        "quality_dict[33] = [45, 0.68, 0.76, 0.67]\n",
        "quality_dict[34] = [47, 0.76, 0.75, 0.73]\n",
        "quality_dict[35] = [48, 0.74, 0.79, 0.63]\n",
        "quality_dict[36] = [50, 0.79, 0.72, 0.73]\n",
        "quality_dict[37] = [51, 0.6, 0.2, 0.49]\n",
        "quality_dict[38] = [52, 0.95, 0.67, 0.93]\n",
        "quality_dict[39] = [53, 0.81, 0.91, 0.9]\n",
        "quality_dict[40] = [54, 1.12, 1.06, 1.11]\n",
        "\n",
        "quality_dict[41] = [55, 0.63, 0.99, 1.1]\n",
        "quality_dict[42] = [56, 0.26, 0.4, 0.47]\n",
        "quality_dict[43] = [57, 0.69, 0.59, 0.65]\n",
        "quality_dict[44] = [58, 0.97, 0.62, 0.75]\n",
        "quality_dict[45] = [60, 0.37, 1.64, 0.51]\n",
        "quality_dict[46] = [61, 0.87, 0.84, 0.93]\n",
        "quality_dict[47] = [62, 0.57, 0.96, 0.69]\n",
        "quality_dict[48] = [63, 1.01, 0.92, 0.92]\n",
        "quality_dict[49] = [64, 0.19, 0.65, 0.39]\n",
        "quality_dict[50] = [65, 0.78, 0.8, 0.72]\n",
        "\n",
        "quality_dict[51] = [66, 0.79, 0.79, 0.94]\n",
        "quality_dict[52] = [67, 0.7, 0.7, 0.99]\n",
        "quality_dict[53] = [83, 0.81, 0.9, 0.79]\n",
        "quality_dict[54] = [84, 0.91, 0.3, 0.65]\n",
        "quality_dict[55] = [85, 0.68, 0.79, 0.63]\n",
        "quality_dict[56] = [86, 0.66, 0.7, 0.72]\n",
        "quality_dict[57] = [87, 0.97, 0.96, 0.95]\n",
        "quality_dict[58] = [88, 0.81, 0.52, 0.65]\n",
        "quality_dict[59] = [89, 0.39, 0.58, 0.14]\n",
        "quality_dict[60] = [90, 0.87, 0.97, 1]\n",
        "\n",
        "quality_dict[61] = [91, 1.05, 0.77, 0.84]\n",
        "quality_dict[62] = [92, 0.9, 1.1, 1.15]\n",
        "quality_dict[63] = [93, 0.97, 0.99, 0.46]\n",
        "quality_dict[64] = [95, 1.31, 0.89, 0.87]\n",
        "quality_dict[65] = [96, 0.75, 0.89, 0.81]\n",
        "quality_dict[66] = [97, 0.56, 0.42, 0.76]\n",
        "quality_dict[67] = [98, 0.88, 0.98, 0.86]\n",
        "quality_dict[68] = [99, 0.88, 0.72, 0.79]\n",
        "quality_dict[69] = [100, 0.58, 0.66, 0.16]\n",
        "quality_dict[70] = [103, 0.37, 0.4, 0.44]\n",
        "\n",
        "quality_dict[71] = [104, 0.88, 0.23, 0.85]\n",
        "quality_dict[72] = [105, 0.54, 0.97, 0.8]\n",
        "quality_dict[73] = [106, 0.82, 0.9, 1.16]\n",
        "quality_dict[74] = [107, 0.89, 0.58, 0.66]\n",
        "quality_dict[75] = [108, 0.71, 0.69, 0.64]\n",
        "quality_dict[76] = [110, 0.9, 0.83, 0.88]\n",
        "quality_dict[77] = [111, 0.9, 0.85, 0.76]\n",
        "quality_dict[78] = [112, 0.61, 0.55, 0.57]\n",
        "quality_dict[79] = [113, 0.35, 0.51, 0.78]\n",
        "quality_dict[80] = [114, 0.5, 0.58, 0.67]\n",
        "\n",
        "quality_dict[81] = [115, 0.74, 0.06, 1.03]\n",
        "quality_dict[82] = [116, 0.78, 0.86, 0.93]\n",
        "quality_dict[83] = [119, 0.55, 0.59, -0.07]\n",
        "quality_dict[84] = [120, 0.79, 0.67, 0.77]\n",
        "quality_dict[85] = [122, 0.93, 0.87, 0.5]\n",
        "quality_dict[86] = [123, 0.89, 0.97, 1.3]\n",
        "quality_dict[87] = [124, 0.93, 1.23, 1.19]\n",
        "quality_dict[88] = [125, 0.84, -0.47, 0.86]\n",
        "quality_dict[89] = [126, 0.44, -0.01, 0.54]\n",
        "quality_dict[90] = [127, 0.53, 0.83, 0.75]\n",
        "\n",
        "quality_dict[91] = [128, 0.87, 0.86, 0.9]\n",
        "quality_dict[92] = [130, 0.91, 0.97, 1]\n",
        "quality_dict[93] = [131, 0.86, 0.85, 0.75]\n",
        "quality_dict[94] = [134, 0.71, 0.21, 0.86]\n",
        "quality_dict[95] = [135, 0.68, 0.72, 0.67]\n",
        "quality_dict[96] = [136, 1.73, 0.56, 0.8]\n",
        "quality_dict[97] = [137, 0.28, 0.58, 0.79]\n",
        "quality_dict[98] = [138, 0.74, 0.48, 0.59]\n",
        "quality_dict[99] = [139, 1.35, 0.69, 0.63]\n",
        "quality_dict[100] = [140, 0.41, 0.85, 0.71]\n",
        "\n",
        "quality_dict[101] = [141, 1.14, 0.96, 0.86]\n",
        "quality_dict[102] = [142, 0.8, 0.82, 0.83]\n",
        "quality_dict[103] = [144, 0.76, 0.66, -0.01]\n",
        "quality_dict[104] = [145, 1.11, 1.1, 1.1]\n",
        "quality_dict[105] = [146, 0.84, 0.84, 1]\n",
        "quality_dict[106] = [148, 1.03, 1.03, 1.06]\n",
        "quality_dict[107] = [149, 0.52, 0.58, 0.49]\n",
        "quality_dict[108] = [150, 0.75, 0.66, 0.49]\n",
        "quality_dict[109] = [151, 0.81, 0.29, 0.85]\n",
        "quality_dict[110] = [152, 1.05, 0.9, 1.22]\n",
        "\n",
        "quality_dict[111] = [153, 0.93, 1.15, 0.79]\n",
        "quality_dict[112] = [154, 0.82, 0.7, 0.75]\n",
        "quality_dict[113] = [155, 0.75, 0.94, 0.71]\n",
        "quality_dict[114] = [156, 0.75, 0.76, 0.7]\n",
        "quality_dict[115] = [157, 0.58, 0.68, 0.44]\n",
        "quality_dict[116] = [158, 0.66, 0.86, 0.05]\n",
        "quality_dict[117] = [160, 0.54, 0.66, 0.59]\n",
        "quality_dict[118] = [161, 0.89, 0.83, 0.86]\n",
        "quality_dict[119] = [162, 1.07, 1, 0.97]\n",
        "quality_dict[120] = [163, 0.79, 0.42, 0.61]\n",
        "\n",
        "quality_dict[121] = [164, 0.94, 0.85, 0.71]\n",
        "quality_dict[122] = [165, 1.07, 0.96, 1.02]\n",
        "quality_dict[123] = [166, 0.71, 0.93, 0.77]\n",
        "quality_dict[124] = [167, 0.57, 0.76, 0.57]\n",
        "quality_dict[125] = [169, 1.11, 0.82, 0.91]\n",
        "quality_dict[126] = [170, 0.77, 0.85, 0.95]\n",
        "quality_dict[127] = [171, 0.69, 0.46, 0.48]\n",
        "quality_dict[128] = [172, 0.45, 0.56, 0.53]\n",
        "quality_dict[129] = [173, 0.89, 0.84, 0.97]\n",
        "quality_dict[130] = [174, 1.14, 1.03, 1.17]\n",
        "\n",
        "quality_dict[131] = [175, 0.69, 0.62, 0.71]\n",
        "quality_dict[132] = [176, 0.75, 0.73, 0.68]\n",
        "quality_dict[133] = [178, 0.38, 0.68, 0.55]\n",
        "quality_dict[134] = [179, 2.34, 0.83, 0.78]\n",
        "quality_dict[135] = [180, 0.8, 0.64, 0.84]\n",
        "quality_dict[136] = [182, 0.72, 0.93, 0.9]\n",
        "quality_dict[137] = [183, 0.35, 0.25, 0.36]\n",
        "quality_dict[138] = [184, 0.49, 0.93, 0.87]\n",
        "quality_dict[139] = [185, 1.03, 1.1, 1.1]\n",
        "quality_dict[140] = [186, 0.73, 0.69, 0.99]\n",
        "\n",
        "quality_dict[141] = [188, 0.85, 1.78, 0.71]\n",
        "quality_dict[142] = [189, 0.9, 0.68, 0.92]\n",
        "quality_dict[143] = [190, 1.13, 0.8, 0.99]\n",
        "quality_dict[144] = [191, 1.23, 1.1, 0.85]\n",
        "quality_dict[145] = [192, 0.85, 0.87, 0.8]\n",
        "quality_dict[146] = [193, 0.76, 0.53, 0.63]\n",
        "quality_dict[147] = [195, 0.91, 1.1, 0.49]\n",
        "quality_dict[148] = [196, 0.88, 0.74, 0.68]\n",
        "quality_dict[149] = [197, 0.9, 1.06, 1.33]\n",
        "quality_dict[150] = [198, 1.12, 1.07, 1.02]\n",
        "\n",
        "quality_dict[151] = [199, 0.81, 0.96, 0.83]\n",
        "quality_dict[152] = [200, 0.3, 0.86, 1.02]\n",
        "quality_dict[153] = [201, 0.68, 0.69, 0.8]\n",
        "quality_dict[154] = [203, 0.92, 1.05, 0.86]\n",
        "quality_dict[155] = [205, 0.91, 0.82, 0.77]\n",
        "quality_dict[156] = [206, 0.69, 0.84, 0.67]\n",
        "quality_dict[157] = [207, 0.75, 0.7, 0.2]\n",
        "quality_dict[158] = [208, 1.47, 0.95, 0.92]\n",
        "quality_dict[159] = [209, 0.76, 0.67, 0.7]\n",
        "quality_dict[160] = [210, 0.72, 0.71, 0.78]\n",
        "\n",
        "quality_dict[161] = [211, 1.4, 0.73, 0.89]\n",
        "quality_dict[162] = [212, 0.74, 0.56, 0.59]\n",
        "quality_dict[163] = [213, 1.16, 0.91, 0.67]\n",
        "quality_dict[164] = [214, 0.46, 0.72, 0.24]\n",
        "quality_dict[165] = [215, 0.62, 0.69, 0.81]\n",
        "quality_dict[166] = [216, 0.33, 0.33, 0.37]\n",
        "quality_dict[167] = [217, 0.69, 1.26, 0.8]\n",
        "quality_dict[168] = [218, 0.82, 0.99, 0.89]\n",
        "quality_dict[169] = [219, 1.02, 1.05, 0.84]\n",
        "quality_dict[170] = [220, 0.63, 0.65, 0.66]\n",
        "\n",
        "quality_dict[171] = [221, 0.43, 0.78, 0.6]\n",
        "quality_dict[172] = [222, 0.92, 0.87, 0.85]\n",
        "quality_dict[173] = [223, 0.81, 0.08, 0.98]\n",
        "quality_dict[174] = [224, 0.85, 1.03, 0.75]\n",
        "quality_dict[175] = [226, 0.84, 1.04, 0.44]\n",
        "quality_dict[176] = [227, 0.99, 0.88, 0.94]\n",
        "quality_dict[177] = [228, 1.06, 1, 0.93]\n",
        "quality_dict[178] = [229, 1, 1.09, 0.98]\n",
        "quality_dict[179] = [230, 0.59, 0.72, 0.81]\n",
        "quality_dict[180] = [231, 1.28, 1.46, 0.98]\n",
        "\n",
        "quality_dict[181] = [232, 0.92, 1.21, 0.87]\n",
        "quality_dict[182] = [233, 0.89, 0.86, 0.67]\n",
        "quality_dict[183] = [234, 0.62, 0.81, 1.02]\n",
        "quality_dict[184] = [235, 0.94, 1.08, 0.97]\n",
        "quality_dict[185] = [237, 0.79, 1.19, 1.42]\n",
        "quality_dict[186] = [239, 0.81, 0.8, 0.7]\n",
        "quality_dict[187] = [240, 0.6, 1.09, 0.93]\n",
        "quality_dict[188] = [241, 0.68, 0.58, 0.52]\n",
        "quality_dict[189] = [242, 0.59, 0.7, 0.69]\n",
        "quality_dict[190] = [243, 1.09, 0.84, 0.91]\n",
        "\n",
        "quality_dict[191] = [244, 0.73, 0.79, 0.68]\n",
        "quality_dict[192] = [245, 0.56, 0.54, 7.13]\n",
        "quality_dict[193] = [246, 1.23, 1.85, 0.63]\n",
        "quality_dict[194] = [247, 0.8, 0.66, 0.54]\n",
        "quality_dict[195] = [248, 0.14, 0.65, 0.69]\n",
        "quality_dict[196] = [250, 0.79, 0.84, 0.77]\n",
        "quality_dict[197] = [251, 0.99, 0.95, 0.99]\n",
        "quality_dict[198] = [252, 0.78, 0.38, 10.22]\n",
        "quality_dict[199] = [253, 0.8, 0.89, 0.92]\n",
        "quality_dict[200] = [254, 0.51, 0.84, 0.75]\n",
        "\n",
        "quality_dict[201] = [256, 0.95, 0.72, 1.25]\n",
        "quality_dict[202] = [257, 0.63, 0.69, 0.87]\n",
        "quality_dict[203] = [259, 0.59, 0.62, 0.67]\n",
        "quality_dict[204] = [403, 0.92, 0.92, 0.92]\n",
        "quality_dict[205] = [404, 1.4, 1, 0.96]\n",
        "quality_dict[206] = [405, 0.72, 0.79, 0.96]\n",
        "quality_dict[207] = [406, 0.28, 0.45, 0.54]\n",
        "quality_dict[208] = [407, 0.84, 0.82, 0.76]\n",
        "quality_dict[209] = [409, 0.84, 1, 0.89]\n",
        "quality_dict[210] = [410, 0.94, 0.91, 0.9]\n",
        "\n",
        "quality_dict[211] = [411, 1.09, 0.92, 1.05]\n",
        "quality_dict[212] = [412, 0.95, 0.7, 0.99]\n",
        "quality_dict[213] = [413, 0.74, 0.67, 0.63]\n",
        "quality_dict[214] = [414, 0.93, 1.34, 1.4]\n",
        "quality_dict[215] = [415, 1.15, 1.38, 1.19]\n",
        "quality_dict[216] = [416, 0.96, 0.94, 1.01]\n",
        "quality_dict[217] = [417, 1.12, 1.32, 1.38]\n",
        "quality_dict[218] = [418, 0.96, 0.87, 1.06]\n",
        "quality_dict[219] = [419, 1.13, 1, 0.81]\n"
      ],
      "metadata": {
        "id": "b1vf3Riexko-"
      },
      "id": "b1vf3Riexko-",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select all segments with positive quality."
      ],
      "metadata": {
        "id": "JJ1lmTLUE7Wj"
      },
      "id": "JJ1lmTLUE7Wj"
    },
    {
      "cell_type": "code",
      "source": [
        "# most of data have three segments, only few of them have some negative quality segments\n",
        "# -> just throw away those segments\n",
        "not_choose = []\n",
        "for subject, segment in quality_dict.items():\n",
        "  for seg, quality in enumerate(quality_dict[subject]):\n",
        "    if quality < 0:\n",
        "      not_choose.append((subject, seg))\n",
        "\n",
        "print(not_choose)\n",
        "print(len(not_choose))"
      ],
      "metadata": {
        "id": "NE8mjNfWzl94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05811a34-0bd4-4e97-b74b-8df408b59a3d"
      },
      "id": "NE8mjNfWzl94",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(7, 3), (23, 3), (83, 3), (88, 2), (89, 2), (103, 3)]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Dataset"
      ],
      "metadata": {
        "id": "P_udZMLyFAV_"
      },
      "id": "P_udZMLyFAV_"
    },
    {
      "cell_type": "code",
      "source": [
        "class BPDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, ppg_dir, label_path, normalize, choose_class=[0,1,2]):\n",
        "\n",
        "        self.ppg_dir = ppg_dir\n",
        "        self.label_path = label_path\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        self.subjectid = []\n",
        "        self.normalize=normalize\n",
        "        \n",
        "        # read BP labels (Label: 'Stage 1 hypertension' or 'Stage 2 hypertension'-> 2; 'Prehypertension'-> 1; 'Normal'-> 0)\n",
        "        df = pd.read_csv(label_path, skiprows=1)\n",
        "        #print(set(df[\"Hypertension\"]))\n",
        "        # choose class\n",
        "        class_id = [[] for i in range(3)]\n",
        "        for subject in range(219):\n",
        "          if df['Hypertension'][subject] == 'Stage 1 hypertension' or df['Hypertension'][subject] == 'Stage 2 hypertension':\n",
        "            class_id[2].append(subject+1)\n",
        "          elif df['Hypertension'][subject] == 'Prehypertension':\n",
        "            class_id[1].append(subject+1)\n",
        "          elif df['Hypertension'][subject] == 'Normal':\n",
        "            class_id[0].append(subject+1)\n",
        "\n",
        "        for c in choose_class:\n",
        "          # c=0,1,2\n",
        "          for subject in class_id[c]:\n",
        "            subjectid = quality_dict[subject][0]\n",
        "            if subject == 180:\n",
        "              continue\n",
        "            elif subject in [7, 23, 83, 88, 89, 103]:\n",
        "              self.label.extend([c]*2)\n",
        "            else:\n",
        "              self.label.extend([c]*3)\n",
        "            # read ppg data\n",
        "            for segnum in range(1, 4):\n",
        "              if (subject, segnum) not in [(7, 3), (23, 3), (83, 3), (88, 2), (89, 2), (103, 3), (180, 1), (180, 2), (180, 3)]:\n",
        "                ppg_path = os.path.join(ppg_dir, '{}_{}.txt'.format(subjectid, segnum))\n",
        "                if os.path.exists(ppg_path):\n",
        "                  with open(ppg_path) as f:\n",
        "                    lines = f.readlines()[0].split('\\t')[:-1]\n",
        "                    if len(lines) != 2100:\n",
        "                      print(subject, subjectid, segment, len(lines))\n",
        "                      continue\n",
        "                    ppg = torch.Tensor([float(x) for x in lines])\n",
        "                    ppg = ppg.reshape((1,2100))\n",
        "                    self.data.append(ppg)\n",
        "                    self.subjectid.append(subjectid)\n",
        "        self.label = torch.Tensor(self.label)\n",
        "        self.label = self.label.type(torch.long)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        data = (data-self.normalize['mean'])/self.normalize['std'] #normalization\n",
        "        label = self.label[index]\n",
        "        subjectid = self.subjectid[index]\n",
        "        return data, label, subjectid\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "FUt2tVAuxJd-"
      },
      "id": "FUt2tVAuxJd-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-Class classification (Sigmoid)\n",
        "\\[\"Normal\", \"Prehypertension\"]: choose_class=\\[0,1]  \n",
        "\n",
        "\\[\"Normal\", \"hypertension\"]: choose_class=\\[0,2]"
      ],
      "metadata": {
        "id": "fRa58ojnoAGR"
      },
      "id": "fRa58ojnoAGR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils (Define lr_decay, calculate accuracy, sensitivity, specificity)"
      ],
      "metadata": {
        "id": "DeN4q5MiFxvK"
      },
      "id": "DeN4q5MiFxvK"
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_decay(optimizer, decay_rate=.9):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * decay_rate\n",
        "\n",
        "class averageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k.mul_(1.0 / batch_size))\n",
        "    return res"
      ],
      "metadata": {
        "id": "eMkEVZmfrn-N"
      },
      "id": "eMkEVZmfrn-N",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGRyvwiRAhmZ",
        "outputId": "6fd2e121-b088-4ec2-d311-d3bd44dba824"
      },
      "id": "lGRyvwiRAhmZ",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.5.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define train, validation functions"
      ],
      "metadata": {
        "id": "K3GjOt9KGYvv"
      },
      "id": "K3GjOt9KGYvv"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "def train(data_loader, model, optimizer, epoch, criterion, binary=False):\n",
        "\n",
        "    losses = averageMeter()\n",
        "    ACC = averageMeter()\n",
        "\n",
        "    # setup training mode\n",
        "    model.train()\n",
        "\n",
        "    for (step, value) in enumerate(data_loader):\n",
        "\n",
        "        data = value[0].cuda()\n",
        "        target = value[1].cuda(non_blocking=True)\n",
        "\n",
        "        # forward\n",
        "        output = model(data).squeeze()\n",
        "\n",
        "        # compute loss\n",
        "        if not binary:\n",
        "            loss = criterion(output, target)\n",
        "        else:\n",
        "            loss = criterion(output, target.float())\n",
        "        losses.update(loss.item(), data.size(0))\n",
        "\n",
        "        # compute acc\n",
        "        if not binary:\n",
        "            pred = torch.max(output, dim=1)[1].data.cpu().numpy()\n",
        "            acc = accuracy(output, target, topk=(1,))[0]\n",
        "        else:\n",
        "            pred = torch.gt(output, 0.5).long()\n",
        "            acc = (target == pred).float().mean()\n",
        "        ACC.update(acc.item(), data.size(0))\n",
        "\n",
        "        # compute confusion matrix\n",
        "        # confmat = ConfusionMatrix(task=\"multiclass\", num_classes=2)\n",
        "        # conf = confmat(pred, target)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # logging\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('Epoch: [{}/{}]\\t' \\\n",
        "        'LR: [{:.6g}]\\t' \\\n",
        "        'Loss {loss.avg:.4f}\\t' \\\n",
        "        'Acc {acc.avg:.3f}'.format(\n",
        "            epoch + 1, n_epoch, curr_lr, loss=losses, acc=ACC\n",
        "        )\n",
        "    )\n",
        "    return ACC.avg, losses.avg#, conf\n",
        "\n",
        "\n",
        "def val(data_loader, model, criterion, binary=False):\n",
        "\n",
        "    losses = averageMeter()\n",
        "    ACC = averageMeter()\n",
        "\n",
        "    # setup evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for (step, value) in enumerate(data_loader):\n",
        "\n",
        "        data = value[0].cuda()\n",
        "        target = value[1].cuda(non_blocking=True)\n",
        "\n",
        "        # forward\n",
        "        output = model(data).squeeze()\n",
        "\n",
        "        # compute acc\n",
        "        if not binary:\n",
        "            pred = torch.max(output, dim=1)[1].data.cpu().numpy()\n",
        "            acc = accuracy(output, target, topk=(1,))[0]\n",
        "        else:\n",
        "            pred = torch.gt(output, 0.5).long()\n",
        "            acc = (target == pred).float().mean()    \n",
        "        ACC.update(acc.item(), data.size(0))\n",
        "\n",
        "        # compute loss\n",
        "        if not binary:\n",
        "            loss = criterion(output, target)\n",
        "        else:\n",
        "            loss = criterion(output, target.float())\n",
        "        losses.update(loss.item(), data.size(0))\n",
        "\n",
        "        # compute confusion matrix\n",
        "        # confmat = ConfusionMatrix(task=\"multiclass\", num_classes=2)\n",
        "        # conf = confmat(pred, target)\n",
        "\n",
        "    # logging\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "    print('[Val]' \\\n",
        "        'Loss {loss.avg:.4f}\\t' \\\n",
        "        'Acc {acc.avg:.3f}'.format(\n",
        "            loss=losses, acc=ACC\n",
        "        )\n",
        "    )\n",
        "    return ACC.avg, losses.avg#, conf"
      ],
      "metadata": {
        "id": "yYT3dsWirhVG"
      },
      "id": "yYT3dsWirhVG",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: Our Conv3Net (3-layer convolution neural network) & CNN_LSTM model from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9787648"
      ],
      "metadata": {
        "id": "791Rv7kMGctE"
      },
      "id": "791Rv7kMGctE"
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3Net(nn.Module):\n",
        "    def __init__(self, n_class=2):\n",
        "        super(Conv3Net, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=30, stride=3, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, kernel_size=15, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7),\n",
        "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "IzfsIrvr5QQs"
      },
      "id": "IzfsIrvr5QQs",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, n_class=2):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=32, batch_first=True)\n",
        "        self.conv1 = nn.Conv1d(1, 8, 16, stride=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(8)\n",
        "        self.lstm2 = nn.LSTM(input_size=7, hidden_size=16, batch_first=True)\n",
        "        self.conv2 = nn.Conv1d(1, 32, 6)\n",
        "        self.mp = nn.MaxPool1d(2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.lstm3 = nn.LSTM(input_size=5, hidden_size=8, batch_first=True)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(8, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.conv1(x[:, -1, :].unsqueeze(1))\n",
        "        x = self.bn1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.conv2(x[:, -1, :].unsqueeze(1))\n",
        "        x = self.bn2(self.mp(x))\n",
        "        x, _ = self.lstm3(x)\n",
        "        x = self.dropout(x[:, -1, :])\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "N8BSTIkp7OFz"
      },
      "id": "N8BSTIkp7OFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Results: \\[\"Normal\", \"Prehypertension\"]"
      ],
      "metadata": {
        "id": "fqL4vZUPoYgR"
      },
      "id": "fqL4vZUPoYgR"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd377c1a",
        "outputId": "dcd3be35-74d4-4918-b312-0c1b48cc9c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 487\n",
            "312\n",
            "78\n",
            "97\n"
          ]
        }
      ],
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,1])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [312, 78, 97])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "id": "dd377c1a"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61d28385",
        "outputId": "0377d983-bd54-49ff-e320-9db25e4958f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "id": "61d28385"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "38b7584d",
        "outputId": "52bb4fa9-a224-43fb-a6ae-5d624090e994"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAADSCAYAAAAxFbcEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVWElEQVR4nO3de7xVZZ3H8c+Xi5kionIiFA0nb5kVFaKmjuSl1C445VhGiqVD9JqsLGucpma0tNGcUstGwyuZeS0DtckMxUspelC8omWKiqKggoopCvzmj+fZsjidw9nnnL05x4fv+/U6r7Ouz/qttfb+7metffbZigjMzErVr7cLMDNrJoecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnDSVprqS9e7uOGklbSFoiqX+D2jtT0nfy8FhJ8xrRbm5vd0kPNqo9SxxyTZafYLWfFZJeroyP70Z7MyQd0aRaOw0oSYMlnSrpsbwPf83jQ5tRUye1HCZpeeV4PiLpPEnb1JaJiMciYlBELK+jrZs722ZETIqI7zWo/pC0VaXtmyJi20a0bSs55JosP8EGRcQg4DHgY5VpF/Z2fV0haR1gOvBOYF9gMLAL8CwwppfKuiUf2w2BvYGXgVmSdmj0hhrVG7Q1LCL8s4Z+gLnA3nm4H3AM8FdSSFwKbJznrQv8Ik9fDNwODANOAJYDrwBLgNM72M7+wP3Ai8ATwNGVeR8FZud2/wS8O0+/AFhBCoklwDfbafcI4GlgUJ37OAa4JW9rPnA6sE6eJ+AUYAHwAnAPsENn9bfZ1mHAze1Mvwq4PA+PBAIYUFnn4dz2I8B44B35mC7P+744L3s+cAbwW+AlUoieDxyf548F5gHfAp7J+z6+UscM4Ij26gVuzHW9lLf5qVp7leXfkdtYDNwHfLwy73zgp8DVeV9mAm/v7cd4X/zp9QLWpp82AfAV4FZgBPAm4GfARXneF4ArgfWA/sD7gcF53ipPnA62Mx/YPQ9vBLwvD783h8pOud0JuaY3ta2vg3YvBqZ0YR/fD+wMDMhhMwf4ap73YWAWMIQUeO8Ahq+u/na29XpotJn+eeDpPDwyh8kAYH1SoG6b5w0H3tlRWzlIngd2Jb0orcvfh9wy4Ef5HO5BCq1a+6ucq7bbyHVtVRkfSw45YCDwEClA1wH2JIXZtpXaaj3oAcCFwMW9/Rjviz++XO09k4D/iIh5EbEUOBY4UNIA4DVgE9ITYHlEzIqIF7rQ9mvA9pIGR8SiiLgjT58I/CwiZuZ2pwBLSUFUj01IAVSXXPetEbEsIuaSgnyPSo0bANsBiog5ETG/Mq+9+uv1JLBxB/NWADtIenNEzI+I+zppa2pE/DEiVkTEKx0s852IWBoRN5B6Vgd1sd727AwMAk6MiFcj4jpSD/XgyjJXRMRtEbGMFHKjGrDd4jjkes/bgCskLZa0mNTLWU66LL0AuAa4WNKTkn4gaWB7jUj6VuXG+5l58idJl3yPSrpB0i6VbX69ts283c2BTeus+VlS76cukraRdJWkpyS9AHwfGAqQn7Snky65FkiaLGlwJ/XXazPgubYTI+Il0mXhJGC+pKslbddJW493Mn9RbrfmUeo/nquzKfB4RKxo0/ZmlfGnKsN/I4WiteGQ6z2PA/tFxJDKz7oR8UREvBYRx0XE9sAHSPfRDs3rrfJvYyLi+7HyjYxJedrtETEOeAvwG9L9vto2T2izzfUi4qL22m7HH4APS1q/zn08A3gA2DoiBpMuvVSp/ccR8X5ge2Ab4Bud1F+vfwJuam9GRFwTEfuQwvoB4KzarA7a6uyYbNTmeGxB6klCunRdrzLvrZ20VfUksLmk6nN0C9I9SusCh1zvORM4QdLbACS1SBqXhz8o6V353bwXSJdvtVf0p4F/6KhRSetIGi9pw4h4La9fW/csYJKknZSsL+kjkjaop21SD/Nx4FeStpPUT9ImuTe5fzvLb5C3vyT3mL5YqXPHXMdAUhi8AqzopP4OSeovaUtJPyHd2zqunWWGSRqXQ2kp6YZ/9biOyO8gd9Vxue7dSS9Il+Xps4FPSFov/6nI4W3WW93xnknqnX1T0kBJY4GPke6LWhc45HrPacA04PeSXiS9CbFTnvdW4HLSE3wOcAMpYGrrHShpkaQfd9D2IcDcfIk4ifQOIhHRCvwL6TJxEenG9mGV9f4b+Ha+lD26baP53uHepB7Qtbm+20iXoDPbqeNo4DOkG+ZnAZdU5g3O0xaRLsOeBU5eXf0d2EXSklzLjNzujhFxTzvL9gO+RuolPUe6P1gL3utI72A+JemZ1WyvrafyPjxJui82KSIeyPNOAV4lhdmUPL/qWGBKPt6r3MeLiFdJobYf6Z3b/wUOrbRtdVKE/2mmmZXLPTkzK5pDzsyK5pAzs6I55MysaA45MyvagDW5saFDh8bIkSPX5CbNbC0wa9asZyKipb15azTkRo4cSWtr65rcpJmtBSQ92tE8X66aWdEccmZWNIecmRXNIWdmRXPImVnR1ui7q9Z3SZ0vs7bz/7J4Y3JPzsyK5pAzs6I55MysaA45MyuaQ87MiuaQM7OiOeTMrGgOOTMrmkPOzIrmkDOzotX1sS5Jc0lfELwcWBYRoyVtTPqy4JHAXOCgiFjUnDLNzLqnKz25D0bEqIgYncePAaZHxNbA9DxuZtan9ORydRwwJQ9PAQ7ocTVmZg1Wb8gF8HtJsyRNzNOGRcT8PPwUMKzh1ZmZ9VC9/2ppt4h4QtJbgGslPVCdGREhqd1/RJNDcSLAFlts0aNizcy6qq6eXEQ8kX8vAK4AxgBPSxoOkH8v6GDdyRExOiJGt7S0+41hZmZN02nISVpf0ga1YeBDwL3ANGBCXmwCMLVZRZqZdVc9l6vDgCuU/nXsAOCXEfE7SbcDl0o6HHgUOKh5ZZqZdU+nIRcRDwPvaWf6s8BezSjKzKxR/IkHMyuaQ87MiuaQM7OiOeTMrGgOOTMrmkPOzIrmkDOzojnkzKxoDjkzK5pDzsyK5pAzs6I55MysaA45MyuaQ87MiuaQM7OiOeTMrGgOOTMrWr3f1tVrdJx6u4Q+Lf6r3S9JM7PMPTkzK1rdISepv6Q7JV2Vx7eUNFPSQ5IukbRO88o0M+uervTkvgLMqYyfBJwSEVsBi4DDG1mYmVkj1BVykkYAHwHOzuMC9gQuz4tMAQ5oQn1mZj1Sb0/uVOCbwIo8vgmwOCKW5fF5wGaNLc3MrOc6DTlJHwUWRMSs7mxA0kRJrZJaFy5c2J0mzMy6rZ6e3K7AxyXNBS4mXaaeBgyRVPsTlBHAE+2tHBGTI2J0RIxuaWlpQMlmZvXrNOQi4t8jYkREjAQ+DVwXEeOB64ED82ITgKlNq9LMrJt68ndy/wZ8TdJDpHt05zSmJDOzxunSJx4iYgYwIw8/DIxpfElmZo3jTzyYWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkVzyJlZ0RxyZlY0h5yZFc0hZ2ZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkWr58ul15V0m6S7JN0n6bg8fUtJMyU9JOkSSes0v1wzs66ppye3FNgzIt4DjAL2lbQzcBJwSkRsBSwCDm9alWZm3VTPl0tHRCzJowPzTwB7Apfn6VOAA5pRoJlZT9R1T05Sf0mzgQXAtcBfgcURsSwvMg/YrIN1J0pqldS6cOHCBpRsZla/ukIuIpZHxChgBOkLpberdwMRMTkiRkfE6JaWlu5VaWbWTV16dzUiFgPXA7sAQyQNyLNGAE80tjQzs56r593VFklD8vCbgX2AOaSwOzAvNgGY2qQazcy6bUDnizAcmCKpPykUL42IqyTdD1ws6XjgTuCcJtZpZtYtnYZcRNwNvLed6Q+T7s+ZmfVZ/sSDmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkVzyJlZ0RxyZlY0h5yZFc0hZ2ZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkVzyJlZ0er5tq7NJV0v6X5J90n6Sp6+saRrJf0l/96o+eWamXVNPT25ZcDXI2J7YGfgXyVtDxwDTI+IrYHpedzMrE/pNOQiYn5E3JGHXyR95+pmwDhgSl5sCnBAk2o0M+u2Lt2TkzSS9PWEM4FhETE/z3oKGNbBOhMltUpqXbhwYU9qNTPrsrpDTtIg4FfAVyPiheq8iAgg2lsvIiZHxOiIGN3S0tKjYs3MuqqukJM0kBRwF0bEr/PkpyUNz/OHAwuaU6KZWffV8+6qgHOAORHxo8qsacCEPDwBmNr48szMemZAHcvsChwC3CNpdp72LeBE4FJJhwOPAgc1pUIzsx7oNOQi4mZAHczeq7HlmJk1lj/xYGZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkVzyJlZ0RxyZlY0h5yZFc0hZ2ZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVrR6vq3rXEkLJN1bmbaxpGsl/SX/3qi5ZZqZdU89PbnzgX3bTDsGmB4RWwPT87iZWZ/TachFxI3Ac20mjwOm5OEpwAGNLcvMrDG6e09uWETMz8NPAcMaVI+ZWUP1+I2HiAggOpovaaKkVkmtCxcu7OnmzMy6pLsh97Sk4QD594KOFoyIyRExOiJGt7S0dHNzZmbd092QmwZMyMMTgKmNKcfMrLHq+ROSi4BbgG0lzZN0OHAisI+kvwB753Ezsz5nQGcLRMTBHczaq8G1mJk1nD/xYGZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVjSHnJkVzSFnZkVzyJlZ0RxyZlY0h5yZFc0hZ2ZFc8iZWdEccmZWNIecmRXNIWdmRXPImVnRHHJmVrQehZykfSU9KOkhScc0qigzs0bpdshJ6g/8FNgP2B44WNL2jSrMzKwRetKTGwM8FBEPR8SrwMXAuMaUZWbWGD0Juc2Axyvj8/I0M7M+o9PvXe0pSROBiXl0iaQHm73NJhsKPNPbRdToWPV2Cc3Sp44zgIo91H3vWHfD2zqa0ZOQewLYvDI+Ik9bRURMBib3YDt9iqTWiBjd23WUzsd5zSn9WPfkcvV2YGtJW0paB/g0MK0xZZmZNUa3e3IRsUzSl4BrgP7AuRFxX8MqMzNrgB7dk4uI3wK/bVAtbxTFXHr3cT7Oa07Rx1oR0ds1mJk1jT/WZWZFW6tCTlJI+mFl/GhJx67hGmZI6hPvZElaLmm2pHslXSZpvS6sO1bSVc2sr4NtfqAJ7Z7dm5/WkbSkzfhhkk5v8jZHSvpME9qdJOnQRrfbE2tVyAFLgU9IGtqdlSU1/e8K17CXI2JUROwAvApMqs7sS/ubaxkLNDzkIuKIiLi/0e32VflYjgQaHnIRcWZE/LzR7fbE2hZyy0g3WY9qOyO/sl0n6W5J0yVtkaefL+lMSTOBH+TxMyTdKunh3Ls4V9IcSedX2jtDUquk+yQdt6Z2sAduArbK+3OTpGnA/ZL6SzpZ0u352Hyhss4gSZdLekDShUr2lPSb2gKS9pF0RR5eIumUfEymS2rJ098u6XeSZuVtb5enV4/9paQQPir3PneX1CLpV7m22yXtmtc7Np+TGfkcfTlPX1/S1ZLuyr3XT+Xpr/euJR0s6Z48/6TKfiyRdEJe91ZJw5p2JlZucwNJj0gamMcH18ZzzadVeuJjKvt4rqTbJN0paVyefpikaZKuA6YDJwK75/WP6ug858fDjLbnOc87UdL9efn/qRz7o/PwqHys7pZ0haSNKsf7pFzjnyXt3tQDGRFrzQ+wBBgMzAU2BI4Gjs3zrgQm5OHPA7/Jw+cDVwH9K+MXAyJ9VvcF4F2kF4xZwKi83Mb5d39gBvDuPD4DGN3bx6J2PPLvAcBU4Iuk3tJLwJZ53kTg23n4TUArsGVe7nnSH4H3A24BdsvH5QGgJa/zS+BjeTiA8Xn4P4HT8/B0YOs8vBNwXQfH/ljg6Er9vwR2y8NbAHMqy/0p1zsUeBYYCHwSOKuy/obVcwJsCjwGtORjch1wQKX22n78oHZMGnQelgOzKz+PVY7NeZUaJgI/rNR8Vh7+R+DePPx94LN5eAjwZ2B94DDSRy9rj8uxwFWVGrp6njcBHmTlm5dD2p4j4G5gjzz8XeDUSu21/dgf+EMzH+drW0+OiHgB+Dnw5TazdiE9aQAuIJ3ImssiYnll/MpIZ+ge4OmIuCciVgD3kS4DAA6SdAdwJ/BO0n9q6WveLGk26QH9GHBOnn5bRDyShz8EHJqXm0l6cG9dWW5e3vfZwMh8XC4APitpCOm4/l9efgVwSR7+BbCbpEGkS9DL8jZ+Bgyv1Nj22FftDZye15sGDM7tAVwdEUsj4hlgATCMdL72yb2I3SPi+Tbt7QjMiIiFEbEMuJAUIJAu52v3IGex8jw3Qu22waiIGEV6Aag5G/hcHv4cKfRqLgKIiBtJ+z6EdL6OycdkBrAu6QUA4NqIeK6DGrp0nknB9wpwjqRPAH+rNiZpQ1Lw3ZAnTWHlsQT4df7d6GP5d/rMPZc17FTgDlZ9wKzOS23Gl+bfKyrDtfEBkrYk9RJ3jIhFSpex63a72uZ5OT+pXpevRKr7K+DIiLimzXJjWXXfl7Py8XQeqWf8CimklnWw/SD1Dha3raOi7bGv6gfsHBGvtLMPf1dbRPxZ0vtIvYfjJU2PiO+upv2q13KAv95enev1SET8UelWylhSj/be6uy2i5PO1ycjYpXPiEvaidUfyy6d50gfBhgD7AUcCHwJ2LPO3aLSZtOP5VrXkwPIr2aXAodXJv+J9NE0gPGke1TdNZj0gHo+37vZrwdt9bZrgC9W7gttI2n91a0QEU8CTwLfZtUXkn6kJwSkm9435571I5L+ObcvSe/poOkXgQ0q478HjqyNSBq1urokbQr8LSJ+AZwMvK/NIrcBe0gaqvT/Eg8GbqD3/Zx0ldH2Rbl2T3E34PncM70GOLJy3+y9HbTZ9lh26TznHvOGkT4QcBSwyjnLtSyq3G87hF46lmtrTw7gh6RXn5ojgfMkfQNYyMpLhC6LiLsk3Um6N/U48MeeFNrLziZdTtyRnzgLgQPqWO9C0n25OZVpLwFjJH2bdAn5qTx9PHBGnj6QdM/zrnbavBK4PN9MP5J0y+Gnku4mPZZvpM07xG28CzhZ0grgNdI9yNdFxHyl/3B9Palnc3VETK1jX5vtQuB48uVpxSv5cTaQdB8Z4HukK5W7JfUDHgE+2k6bdwPLJd1Fuvd5Gl07zxsAUyWtSzpWX2tnmQnAmUp/mvQwPXhO9YQ/8WBNofR3XndGxDmVaUsiYtBqVrN2SDoQGBcRh1SmzSDd4G/ttcLeINbmnpw1iaRZpF7b13u7ljc6ST8h3e7Yv7dreaNyT87MirZWvvFgZmsPh5yZFc0hZ2ZFc8iZWdEccmZWNIecmRXt/wG6d0xvcc/ejgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "id": "38b7584d"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(2).cuda()\n",
        "#model = CNN_LSTM(2).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.BCELoss()\n",
        "binary = False\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion, binary)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion, binary)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion, binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MwjTY-CzFiB",
        "outputId": "be9f9f24-b46b-4fc5-a21d-413060209bf6"
      },
      "id": "2MwjTY-CzFiB",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/180]\tLR: [0.01]\tLoss 0.6914\tAcc 0.551\n",
            "[Val]Loss 0.6428\tAcc 0.577\n",
            "Epoch: [2/180]\tLR: [0.01]\tLoss 0.6626\tAcc 0.558\n",
            "[Val]Loss 0.6258\tAcc 0.590\n",
            "Epoch: [3/180]\tLR: [0.01]\tLoss 0.6637\tAcc 0.593\n",
            "[Val]Loss 0.6353\tAcc 0.590\n",
            "Epoch: [4/180]\tLR: [0.01]\tLoss 0.6469\tAcc 0.545\n",
            "[Val]Loss 0.6588\tAcc 0.590\n",
            "Epoch: [5/180]\tLR: [0.01]\tLoss 0.6547\tAcc 0.622\n",
            "[Val]Loss 0.6862\tAcc 0.551\n",
            "Epoch: [6/180]\tLR: [0.01]\tLoss 0.6505\tAcc 0.580\n",
            "[Val]Loss 0.6124\tAcc 0.500\n",
            "Epoch: [7/180]\tLR: [0.01]\tLoss 0.6436\tAcc 0.593\n",
            "[Val]Loss 0.6925\tAcc 0.564\n",
            "Epoch: [8/180]\tLR: [0.01]\tLoss 0.6635\tAcc 0.535\n",
            "[Val]Loss 0.6299\tAcc 0.603\n",
            "Epoch: [9/180]\tLR: [0.01]\tLoss 0.6531\tAcc 0.583\n",
            "[Val]Loss 0.6149\tAcc 0.590\n",
            "Epoch: [10/180]\tLR: [0.01]\tLoss 0.6369\tAcc 0.574\n",
            "[Val]Loss 0.6387\tAcc 0.590\n",
            "Epoch: [11/180]\tLR: [0.01]\tLoss 0.6383\tAcc 0.590\n",
            "[Val]Loss 0.6118\tAcc 0.577\n",
            "Epoch: [12/180]\tLR: [0.01]\tLoss 0.6455\tAcc 0.577\n",
            "[Val]Loss 0.6109\tAcc 0.590\n",
            "Epoch: [13/180]\tLR: [0.01]\tLoss 0.6366\tAcc 0.590\n",
            "[Val]Loss 0.6295\tAcc 0.590\n",
            "Epoch: [14/180]\tLR: [0.01]\tLoss 0.6468\tAcc 0.599\n",
            "[Val]Loss 0.6190\tAcc 0.628\n",
            "Epoch: [15/180]\tLR: [0.01]\tLoss 0.7037\tAcc 0.551\n",
            "[Val]Loss 0.7054\tAcc 0.462\n",
            "Epoch: [16/180]\tLR: [0.01]\tLoss 0.6820\tAcc 0.564\n",
            "[Val]Loss 0.6377\tAcc 0.615\n",
            "Epoch: [17/180]\tLR: [0.01]\tLoss 0.6614\tAcc 0.558\n",
            "[Val]Loss 0.6236\tAcc 0.538\n",
            "Epoch: [18/180]\tLR: [0.01]\tLoss 0.6781\tAcc 0.519\n",
            "[Val]Loss 0.6180\tAcc 0.590\n",
            "Epoch: [19/180]\tLR: [0.01]\tLoss 0.6491\tAcc 0.596\n",
            "[Val]Loss 0.6714\tAcc 0.577\n",
            "Epoch: [20/180]\tLR: [0.01]\tLoss 0.6529\tAcc 0.577\n",
            "[Val]Loss 0.6145\tAcc 0.577\n",
            "Epoch: [21/180]\tLR: [0.01]\tLoss 0.6476\tAcc 0.580\n",
            "[Val]Loss 0.6104\tAcc 0.590\n",
            "Epoch: [22/180]\tLR: [0.01]\tLoss 0.6484\tAcc 0.571\n",
            "[Val]Loss 0.6251\tAcc 0.615\n",
            "Epoch: [23/180]\tLR: [0.01]\tLoss 0.6358\tAcc 0.593\n",
            "[Val]Loss 0.6133\tAcc 0.603\n",
            "Epoch: [24/180]\tLR: [0.01]\tLoss 0.6438\tAcc 0.542\n",
            "[Val]Loss 0.6195\tAcc 0.577\n",
            "Epoch: [25/180]\tLR: [0.01]\tLoss 0.6371\tAcc 0.619\n",
            "[Val]Loss 0.6115\tAcc 0.603\n",
            "Epoch: [26/180]\tLR: [0.01]\tLoss 0.6809\tAcc 0.516\n",
            "[Val]Loss 0.7084\tAcc 0.513\n",
            "Epoch: [27/180]\tLR: [0.01]\tLoss 0.6935\tAcc 0.577\n",
            "[Val]Loss 0.6868\tAcc 0.474\n",
            "Epoch: [28/180]\tLR: [0.01]\tLoss 0.6789\tAcc 0.551\n",
            "[Val]Loss 0.6513\tAcc 0.603\n",
            "Epoch: [29/180]\tLR: [0.01]\tLoss 0.6523\tAcc 0.548\n",
            "[Val]Loss 0.6352\tAcc 0.641\n",
            "Epoch: [30/180]\tLR: [0.01]\tLoss 0.6470\tAcc 0.593\n",
            "[Val]Loss 0.6231\tAcc 0.577\n",
            "Epoch: [31/180]\tLR: [0.01]\tLoss 0.6375\tAcc 0.593\n",
            "[Val]Loss 0.6262\tAcc 0.590\n",
            "Epoch: [32/180]\tLR: [0.01]\tLoss 0.6331\tAcc 0.580\n",
            "[Val]Loss 0.6321\tAcc 0.590\n",
            "Epoch: [33/180]\tLR: [0.01]\tLoss 0.6433\tAcc 0.599\n",
            "[Val]Loss 0.6689\tAcc 0.590\n",
            "Epoch: [34/180]\tLR: [0.01]\tLoss 0.6544\tAcc 0.587\n",
            "[Val]Loss 0.6430\tAcc 0.590\n",
            "Epoch: [35/180]\tLR: [0.01]\tLoss 0.6594\tAcc 0.580\n",
            "[Val]Loss 0.6443\tAcc 0.577\n",
            "Epoch: [36/180]\tLR: [0.01]\tLoss 0.6218\tAcc 0.599\n",
            "[Val]Loss 0.6298\tAcc 0.590\n",
            "Epoch: [37/180]\tLR: [0.01]\tLoss 0.6369\tAcc 0.580\n",
            "[Val]Loss 0.6308\tAcc 0.577\n",
            "Epoch: [38/180]\tLR: [0.01]\tLoss 0.6451\tAcc 0.564\n",
            "[Val]Loss 0.6170\tAcc 0.590\n",
            "Epoch: [39/180]\tLR: [0.01]\tLoss 0.6353\tAcc 0.612\n",
            "[Val]Loss 0.6358\tAcc 0.577\n",
            "Epoch: [40/180]\tLR: [0.01]\tLoss 0.6382\tAcc 0.599\n",
            "[Val]Loss 0.6246\tAcc 0.590\n",
            "Epoch: [41/180]\tLR: [0.01]\tLoss 0.6201\tAcc 0.615\n",
            "[Val]Loss 0.6199\tAcc 0.628\n",
            "Epoch: [42/180]\tLR: [0.01]\tLoss 0.6295\tAcc 0.599\n",
            "[Val]Loss 0.6215\tAcc 0.615\n",
            "Epoch: [43/180]\tLR: [0.01]\tLoss 0.6151\tAcc 0.599\n",
            "[Val]Loss 0.6451\tAcc 0.577\n",
            "Epoch: [44/180]\tLR: [0.01]\tLoss 0.6224\tAcc 0.583\n",
            "[Val]Loss 0.6160\tAcc 0.641\n",
            "Epoch: [45/180]\tLR: [0.01]\tLoss 0.6424\tAcc 0.580\n",
            "[Val]Loss 0.6208\tAcc 0.590\n",
            "Epoch: [46/180]\tLR: [0.01]\tLoss 0.6419\tAcc 0.558\n",
            "[Val]Loss 0.6292\tAcc 0.526\n",
            "Epoch: [47/180]\tLR: [0.01]\tLoss 0.6173\tAcc 0.599\n",
            "[Val]Loss 0.6204\tAcc 0.654\n",
            "Epoch: [48/180]\tLR: [0.01]\tLoss 0.6058\tAcc 0.651\n",
            "[Val]Loss 0.6480\tAcc 0.564\n",
            "Epoch: [49/180]\tLR: [0.01]\tLoss 0.6485\tAcc 0.551\n",
            "[Val]Loss 0.6383\tAcc 0.513\n",
            "Epoch: [50/180]\tLR: [0.01]\tLoss 0.6324\tAcc 0.561\n",
            "[Val]Loss 0.6184\tAcc 0.513\n",
            "Epoch: [51/180]\tLR: [0.01]\tLoss 0.6104\tAcc 0.590\n",
            "[Val]Loss 0.6180\tAcc 0.654\n",
            "Epoch: [52/180]\tLR: [0.01]\tLoss 0.6124\tAcc 0.644\n",
            "[Val]Loss 0.6391\tAcc 0.538\n",
            "Epoch: [53/180]\tLR: [0.01]\tLoss 0.6401\tAcc 0.609\n",
            "[Val]Loss 0.6454\tAcc 0.551\n",
            "Epoch: [54/180]\tLR: [0.01]\tLoss 0.6661\tAcc 0.593\n",
            "[Val]Loss 0.6025\tAcc 0.615\n",
            "Epoch: [55/180]\tLR: [0.01]\tLoss 0.6306\tAcc 0.551\n",
            "[Val]Loss 0.6148\tAcc 0.654\n",
            "Epoch: [56/180]\tLR: [0.01]\tLoss 0.6315\tAcc 0.564\n",
            "[Val]Loss 0.6048\tAcc 0.590\n",
            "Epoch: [57/180]\tLR: [0.01]\tLoss 0.6373\tAcc 0.590\n",
            "[Val]Loss 0.6172\tAcc 0.628\n",
            "Epoch: [58/180]\tLR: [0.01]\tLoss 0.6267\tAcc 0.603\n",
            "[Val]Loss 0.6262\tAcc 0.603\n",
            "Epoch: [59/180]\tLR: [0.01]\tLoss 0.6108\tAcc 0.609\n",
            "[Val]Loss 0.6161\tAcc 0.718\n",
            "Epoch: [60/180]\tLR: [0.01]\tLoss 0.6161\tAcc 0.638\n",
            "[Val]Loss 0.6125\tAcc 0.615\n",
            "Epoch: [61/180]\tLR: [0.001]\tLoss 0.5890\tAcc 0.631\n",
            "[Val]Loss 0.6216\tAcc 0.718\n",
            "Epoch: [62/180]\tLR: [0.001]\tLoss 0.5782\tAcc 0.667\n",
            "[Val]Loss 0.6150\tAcc 0.641\n",
            "Epoch: [63/180]\tLR: [0.001]\tLoss 0.5698\tAcc 0.638\n",
            "[Val]Loss 0.6247\tAcc 0.731\n",
            "Epoch: [64/180]\tLR: [0.001]\tLoss 0.5702\tAcc 0.641\n",
            "[Val]Loss 0.6145\tAcc 0.705\n",
            "Epoch: [65/180]\tLR: [0.001]\tLoss 0.5657\tAcc 0.647\n",
            "[Val]Loss 0.6140\tAcc 0.654\n",
            "Epoch: [66/180]\tLR: [0.001]\tLoss 0.5578\tAcc 0.673\n",
            "[Val]Loss 0.6214\tAcc 0.654\n",
            "Epoch: [67/180]\tLR: [0.001]\tLoss 0.5570\tAcc 0.696\n",
            "[Val]Loss 0.6229\tAcc 0.692\n",
            "Epoch: [68/180]\tLR: [0.001]\tLoss 0.5631\tAcc 0.660\n",
            "[Val]Loss 0.6182\tAcc 0.667\n",
            "Epoch: [69/180]\tLR: [0.001]\tLoss 0.5366\tAcc 0.679\n",
            "[Val]Loss 0.6267\tAcc 0.731\n",
            "Epoch: [70/180]\tLR: [0.001]\tLoss 0.5475\tAcc 0.657\n",
            "[Val]Loss 0.6258\tAcc 0.603\n",
            "Epoch: [71/180]\tLR: [0.001]\tLoss 0.5269\tAcc 0.702\n",
            "[Val]Loss 0.6375\tAcc 0.769\n",
            "Epoch: [72/180]\tLR: [0.001]\tLoss 0.5250\tAcc 0.699\n",
            "[Val]Loss 0.6377\tAcc 0.679\n",
            "Epoch: [73/180]\tLR: [0.001]\tLoss 0.5256\tAcc 0.708\n",
            "[Val]Loss 0.6500\tAcc 0.705\n",
            "Epoch: [74/180]\tLR: [0.001]\tLoss 0.5443\tAcc 0.644\n",
            "[Val]Loss 0.6401\tAcc 0.590\n",
            "Epoch: [75/180]\tLR: [0.001]\tLoss 0.5367\tAcc 0.679\n",
            "[Val]Loss 0.6458\tAcc 0.667\n",
            "Epoch: [76/180]\tLR: [0.001]\tLoss 0.5252\tAcc 0.670\n",
            "[Val]Loss 0.6514\tAcc 0.615\n",
            "Epoch: [77/180]\tLR: [0.001]\tLoss 0.5215\tAcc 0.699\n",
            "[Val]Loss 0.6481\tAcc 0.654\n",
            "Epoch: [78/180]\tLR: [0.001]\tLoss 0.5235\tAcc 0.705\n",
            "[Val]Loss 0.6561\tAcc 0.692\n",
            "Epoch: [79/180]\tLR: [0.001]\tLoss 0.5011\tAcc 0.708\n",
            "[Val]Loss 0.6568\tAcc 0.641\n",
            "Epoch: [80/180]\tLR: [0.001]\tLoss 0.5200\tAcc 0.692\n",
            "[Val]Loss 0.6691\tAcc 0.654\n",
            "Epoch: [81/180]\tLR: [0.001]\tLoss 0.5191\tAcc 0.708\n",
            "[Val]Loss 0.6595\tAcc 0.615\n",
            "Epoch: [82/180]\tLR: [0.001]\tLoss 0.5342\tAcc 0.712\n",
            "[Val]Loss 0.6741\tAcc 0.667\n",
            "Epoch: [83/180]\tLR: [0.001]\tLoss 0.5071\tAcc 0.689\n",
            "[Val]Loss 0.6707\tAcc 0.679\n",
            "Epoch: [84/180]\tLR: [0.001]\tLoss 0.5042\tAcc 0.721\n",
            "[Val]Loss 0.6873\tAcc 0.641\n",
            "Epoch: [85/180]\tLR: [0.001]\tLoss 0.4911\tAcc 0.731\n",
            "[Val]Loss 0.6861\tAcc 0.705\n",
            "Epoch: [86/180]\tLR: [0.001]\tLoss 0.5034\tAcc 0.702\n",
            "[Val]Loss 0.6986\tAcc 0.679\n",
            "Epoch: [87/180]\tLR: [0.001]\tLoss 0.5083\tAcc 0.715\n",
            "[Val]Loss 0.6653\tAcc 0.667\n",
            "Epoch: [88/180]\tLR: [0.001]\tLoss 0.4890\tAcc 0.737\n",
            "[Val]Loss 0.6888\tAcc 0.615\n",
            "Epoch: [89/180]\tLR: [0.001]\tLoss 0.5011\tAcc 0.705\n",
            "[Val]Loss 0.6533\tAcc 0.641\n",
            "Epoch: [90/180]\tLR: [0.001]\tLoss 0.5036\tAcc 0.734\n",
            "[Val]Loss 0.6838\tAcc 0.654\n",
            "Epoch: [91/180]\tLR: [0.001]\tLoss 0.4962\tAcc 0.737\n",
            "[Val]Loss 0.6888\tAcc 0.603\n",
            "Epoch: [92/180]\tLR: [0.001]\tLoss 0.5096\tAcc 0.692\n",
            "[Val]Loss 0.6807\tAcc 0.667\n",
            "Epoch: [93/180]\tLR: [0.001]\tLoss 0.4886\tAcc 0.718\n",
            "[Val]Loss 0.6905\tAcc 0.679\n",
            "Epoch: [94/180]\tLR: [0.001]\tLoss 0.4766\tAcc 0.763\n",
            "[Val]Loss 0.6879\tAcc 0.628\n",
            "Epoch: [95/180]\tLR: [0.001]\tLoss 0.4848\tAcc 0.750\n",
            "[Val]Loss 0.6779\tAcc 0.603\n",
            "Epoch: [96/180]\tLR: [0.001]\tLoss 0.4932\tAcc 0.721\n",
            "[Val]Loss 0.6854\tAcc 0.628\n",
            "Epoch: [97/180]\tLR: [0.001]\tLoss 0.4868\tAcc 0.753\n",
            "[Val]Loss 0.7064\tAcc 0.654\n",
            "Epoch: [98/180]\tLR: [0.001]\tLoss 0.4745\tAcc 0.740\n",
            "[Val]Loss 0.7086\tAcc 0.641\n",
            "Epoch: [99/180]\tLR: [0.001]\tLoss 0.4907\tAcc 0.737\n",
            "[Val]Loss 0.6771\tAcc 0.603\n",
            "Epoch: [100/180]\tLR: [0.001]\tLoss 0.4846\tAcc 0.737\n",
            "[Val]Loss 0.6956\tAcc 0.615\n",
            "Epoch: [101/180]\tLR: [0.001]\tLoss 0.4714\tAcc 0.785\n",
            "[Val]Loss 0.7064\tAcc 0.590\n",
            "Epoch: [102/180]\tLR: [0.001]\tLoss 0.4646\tAcc 0.753\n",
            "[Val]Loss 0.7268\tAcc 0.577\n",
            "Epoch: [103/180]\tLR: [0.001]\tLoss 0.4707\tAcc 0.747\n",
            "[Val]Loss 0.7125\tAcc 0.590\n",
            "Epoch: [104/180]\tLR: [0.001]\tLoss 0.4701\tAcc 0.734\n",
            "[Val]Loss 0.6994\tAcc 0.641\n",
            "Epoch: [105/180]\tLR: [0.001]\tLoss 0.4593\tAcc 0.753\n",
            "[Val]Loss 0.7112\tAcc 0.679\n",
            "Epoch: [106/180]\tLR: [0.001]\tLoss 0.4629\tAcc 0.760\n",
            "[Val]Loss 0.7377\tAcc 0.628\n",
            "Epoch: [107/180]\tLR: [0.001]\tLoss 0.4472\tAcc 0.744\n",
            "[Val]Loss 0.7584\tAcc 0.615\n",
            "Epoch: [108/180]\tLR: [0.001]\tLoss 0.4848\tAcc 0.753\n",
            "[Val]Loss 0.7324\tAcc 0.577\n",
            "Epoch: [109/180]\tLR: [0.001]\tLoss 0.4692\tAcc 0.750\n",
            "[Val]Loss 0.7672\tAcc 0.603\n",
            "Epoch: [110/180]\tLR: [0.001]\tLoss 0.4855\tAcc 0.756\n",
            "[Val]Loss 0.7167\tAcc 0.615\n",
            "Epoch: [111/180]\tLR: [0.001]\tLoss 0.4459\tAcc 0.782\n",
            "[Val]Loss 0.7490\tAcc 0.654\n",
            "Epoch: [112/180]\tLR: [0.001]\tLoss 0.5295\tAcc 0.708\n",
            "[Val]Loss 0.6902\tAcc 0.628\n",
            "Epoch: [113/180]\tLR: [0.001]\tLoss 0.4794\tAcc 0.737\n",
            "[Val]Loss 0.7111\tAcc 0.615\n",
            "Epoch: [114/180]\tLR: [0.001]\tLoss 0.4431\tAcc 0.808\n",
            "[Val]Loss 0.7726\tAcc 0.641\n",
            "Epoch: [115/180]\tLR: [0.001]\tLoss 0.4281\tAcc 0.772\n",
            "[Val]Loss 0.7195\tAcc 0.641\n",
            "Epoch: [116/180]\tLR: [0.001]\tLoss 0.4300\tAcc 0.808\n",
            "[Val]Loss 0.7584\tAcc 0.577\n",
            "Epoch: [117/180]\tLR: [0.001]\tLoss 0.4090\tAcc 0.785\n",
            "[Val]Loss 0.7391\tAcc 0.667\n",
            "Epoch: [118/180]\tLR: [0.001]\tLoss 0.4152\tAcc 0.814\n",
            "[Val]Loss 0.7970\tAcc 0.641\n",
            "Epoch: [119/180]\tLR: [0.001]\tLoss 0.4339\tAcc 0.756\n",
            "[Val]Loss 0.7707\tAcc 0.641\n",
            "Epoch: [120/180]\tLR: [0.001]\tLoss 0.3999\tAcc 0.808\n",
            "[Val]Loss 0.8246\tAcc 0.564\n",
            "Epoch: [121/180]\tLR: [0.0001]\tLoss 0.3852\tAcc 0.821\n",
            "[Val]Loss 0.7687\tAcc 0.654\n",
            "Epoch: [122/180]\tLR: [0.0001]\tLoss 0.3987\tAcc 0.788\n",
            "[Val]Loss 0.7654\tAcc 0.654\n",
            "Epoch: [123/180]\tLR: [0.0001]\tLoss 0.3547\tAcc 0.824\n",
            "[Val]Loss 0.7950\tAcc 0.577\n",
            "Epoch: [124/180]\tLR: [0.0001]\tLoss 0.3791\tAcc 0.827\n",
            "[Val]Loss 0.7928\tAcc 0.641\n",
            "Epoch: [125/180]\tLR: [0.0001]\tLoss 0.3615\tAcc 0.840\n",
            "[Val]Loss 0.7730\tAcc 0.654\n",
            "Epoch: [126/180]\tLR: [0.0001]\tLoss 0.3654\tAcc 0.856\n",
            "[Val]Loss 0.7820\tAcc 0.641\n",
            "Epoch: [127/180]\tLR: [0.0001]\tLoss 0.3625\tAcc 0.843\n",
            "[Val]Loss 0.7872\tAcc 0.641\n",
            "Epoch: [128/180]\tLR: [0.0001]\tLoss 0.3757\tAcc 0.827\n",
            "[Val]Loss 0.7855\tAcc 0.628\n",
            "Epoch: [129/180]\tLR: [0.0001]\tLoss 0.3645\tAcc 0.830\n",
            "[Val]Loss 0.7659\tAcc 0.641\n",
            "Epoch: [130/180]\tLR: [0.0001]\tLoss 0.3610\tAcc 0.846\n",
            "[Val]Loss 0.7939\tAcc 0.603\n",
            "Epoch: [131/180]\tLR: [0.0001]\tLoss 0.3765\tAcc 0.801\n",
            "[Val]Loss 0.7593\tAcc 0.641\n",
            "Epoch: [132/180]\tLR: [0.0001]\tLoss 0.3641\tAcc 0.837\n",
            "[Val]Loss 0.7928\tAcc 0.654\n",
            "Epoch: [133/180]\tLR: [0.0001]\tLoss 0.3689\tAcc 0.817\n",
            "[Val]Loss 0.7994\tAcc 0.641\n",
            "Epoch: [134/180]\tLR: [0.0001]\tLoss 0.3510\tAcc 0.859\n",
            "[Val]Loss 0.8075\tAcc 0.628\n",
            "Epoch: [135/180]\tLR: [0.0001]\tLoss 0.3631\tAcc 0.824\n",
            "[Val]Loss 0.7725\tAcc 0.628\n",
            "Epoch: [136/180]\tLR: [0.0001]\tLoss 0.3599\tAcc 0.830\n",
            "[Val]Loss 0.7963\tAcc 0.641\n",
            "Epoch: [137/180]\tLR: [0.0001]\tLoss 0.3628\tAcc 0.830\n",
            "[Val]Loss 0.7913\tAcc 0.628\n",
            "Epoch: [138/180]\tLR: [0.0001]\tLoss 0.3355\tAcc 0.859\n",
            "[Val]Loss 0.7911\tAcc 0.615\n",
            "Epoch: [139/180]\tLR: [0.0001]\tLoss 0.3540\tAcc 0.853\n",
            "[Val]Loss 0.7847\tAcc 0.628\n",
            "Epoch: [140/180]\tLR: [0.0001]\tLoss 0.3468\tAcc 0.853\n",
            "[Val]Loss 0.7925\tAcc 0.628\n",
            "Epoch: [141/180]\tLR: [0.0001]\tLoss 0.3667\tAcc 0.833\n",
            "[Val]Loss 0.7866\tAcc 0.615\n",
            "Epoch: [142/180]\tLR: [0.0001]\tLoss 0.3508\tAcc 0.849\n",
            "[Val]Loss 0.7998\tAcc 0.615\n",
            "Epoch: [143/180]\tLR: [0.0001]\tLoss 0.3481\tAcc 0.833\n",
            "[Val]Loss 0.7951\tAcc 0.603\n",
            "Epoch: [144/180]\tLR: [0.0001]\tLoss 0.3423\tAcc 0.856\n",
            "[Val]Loss 0.7991\tAcc 0.615\n",
            "Epoch: [145/180]\tLR: [0.0001]\tLoss 0.3681\tAcc 0.833\n",
            "[Val]Loss 0.7833\tAcc 0.641\n",
            "Epoch: [146/180]\tLR: [0.0001]\tLoss 0.3464\tAcc 0.837\n",
            "[Val]Loss 0.7859\tAcc 0.641\n",
            "Epoch: [147/180]\tLR: [0.0001]\tLoss 0.3414\tAcc 0.843\n",
            "[Val]Loss 0.7862\tAcc 0.628\n",
            "Epoch: [148/180]\tLR: [0.0001]\tLoss 0.3367\tAcc 0.862\n",
            "[Val]Loss 0.8032\tAcc 0.615\n",
            "Epoch: [149/180]\tLR: [0.0001]\tLoss 0.3479\tAcc 0.853\n",
            "[Val]Loss 0.8166\tAcc 0.615\n",
            "Epoch: [150/180]\tLR: [0.0001]\tLoss 0.3444\tAcc 0.859\n",
            "[Val]Loss 0.8088\tAcc 0.654\n",
            "Epoch: [151/180]\tLR: [0.0001]\tLoss 0.3348\tAcc 0.872\n",
            "[Val]Loss 0.7948\tAcc 0.641\n",
            "Epoch: [152/180]\tLR: [0.0001]\tLoss 0.3449\tAcc 0.840\n",
            "[Val]Loss 0.7887\tAcc 0.641\n",
            "Epoch: [153/180]\tLR: [0.0001]\tLoss 0.3281\tAcc 0.885\n",
            "[Val]Loss 0.7887\tAcc 0.628\n",
            "Epoch: [154/180]\tLR: [0.0001]\tLoss 0.3225\tAcc 0.865\n",
            "[Val]Loss 0.7752\tAcc 0.615\n",
            "Epoch: [155/180]\tLR: [0.0001]\tLoss 0.3399\tAcc 0.862\n",
            "[Val]Loss 0.7797\tAcc 0.628\n",
            "Epoch: [156/180]\tLR: [0.0001]\tLoss 0.3273\tAcc 0.856\n",
            "[Val]Loss 0.8090\tAcc 0.615\n",
            "Epoch: [157/180]\tLR: [0.0001]\tLoss 0.3295\tAcc 0.878\n",
            "[Val]Loss 0.7937\tAcc 0.615\n",
            "Epoch: [158/180]\tLR: [0.0001]\tLoss 0.3298\tAcc 0.856\n",
            "[Val]Loss 0.8103\tAcc 0.628\n",
            "Epoch: [159/180]\tLR: [0.0001]\tLoss 0.3325\tAcc 0.846\n",
            "[Val]Loss 0.8119\tAcc 0.628\n",
            "Epoch: [160/180]\tLR: [0.0001]\tLoss 0.3305\tAcc 0.862\n",
            "[Val]Loss 0.7800\tAcc 0.654\n",
            "Epoch: [161/180]\tLR: [0.0001]\tLoss 0.3460\tAcc 0.840\n",
            "[Val]Loss 0.8178\tAcc 0.603\n",
            "Epoch: [162/180]\tLR: [0.0001]\tLoss 0.3609\tAcc 0.830\n",
            "[Val]Loss 0.8105\tAcc 0.615\n",
            "Epoch: [163/180]\tLR: [0.0001]\tLoss 0.3411\tAcc 0.865\n",
            "[Val]Loss 0.8086\tAcc 0.615\n",
            "Epoch: [164/180]\tLR: [0.0001]\tLoss 0.3325\tAcc 0.872\n",
            "[Val]Loss 0.8305\tAcc 0.641\n",
            "Epoch: [165/180]\tLR: [0.0001]\tLoss 0.3442\tAcc 0.837\n",
            "[Val]Loss 0.8418\tAcc 0.615\n",
            "Epoch: [166/180]\tLR: [0.0001]\tLoss 0.3422\tAcc 0.853\n",
            "[Val]Loss 0.8248\tAcc 0.628\n",
            "Epoch: [167/180]\tLR: [0.0001]\tLoss 0.3142\tAcc 0.872\n",
            "[Val]Loss 0.8118\tAcc 0.603\n",
            "Epoch: [168/180]\tLR: [0.0001]\tLoss 0.3178\tAcc 0.878\n",
            "[Val]Loss 0.8174\tAcc 0.603\n",
            "Epoch: [169/180]\tLR: [0.0001]\tLoss 0.3259\tAcc 0.843\n",
            "[Val]Loss 0.7941\tAcc 0.641\n",
            "Epoch: [170/180]\tLR: [0.0001]\tLoss 0.3261\tAcc 0.869\n",
            "[Val]Loss 0.8251\tAcc 0.615\n",
            "Epoch: [171/180]\tLR: [0.0001]\tLoss 0.3413\tAcc 0.837\n",
            "[Val]Loss 0.8121\tAcc 0.628\n",
            "Epoch: [172/180]\tLR: [0.0001]\tLoss 0.3095\tAcc 0.891\n",
            "[Val]Loss 0.8131\tAcc 0.603\n",
            "Epoch: [173/180]\tLR: [0.0001]\tLoss 0.3228\tAcc 0.885\n",
            "[Val]Loss 0.8387\tAcc 0.615\n",
            "Epoch: [174/180]\tLR: [0.0001]\tLoss 0.3190\tAcc 0.869\n",
            "[Val]Loss 0.8366\tAcc 0.615\n",
            "Epoch: [175/180]\tLR: [0.0001]\tLoss 0.3123\tAcc 0.856\n",
            "[Val]Loss 0.8161\tAcc 0.628\n",
            "Epoch: [176/180]\tLR: [0.0001]\tLoss 0.3157\tAcc 0.862\n",
            "[Val]Loss 0.8192\tAcc 0.641\n",
            "Epoch: [177/180]\tLR: [0.0001]\tLoss 0.2979\tAcc 0.901\n",
            "[Val]Loss 0.8252\tAcc 0.628\n",
            "Epoch: [178/180]\tLR: [0.0001]\tLoss 0.3148\tAcc 0.853\n",
            "[Val]Loss 0.8274\tAcc 0.615\n",
            "Epoch: [179/180]\tLR: [0.0001]\tLoss 0.3100\tAcc 0.881\n",
            "[Val]Loss 0.8288\tAcc 0.615\n",
            "Epoch: [180/180]\tLR: [0.0001]\tLoss 0.3004\tAcc 0.894\n",
            "[Val]Loss 0.8125\tAcc 0.641\n",
            "[Val]Loss 0.7192\tAcc 0.639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Results: \\[\"Normal\", \"hypertension\"]"
      ],
      "metadata": {
        "id": "8MNi0KSX0RgX"
      },
      "id": "8MNi0KSX0RgX"
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,2])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [255, 64, 80])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqHzByty0bCz",
        "outputId": "26f6ceb5-bb56-4b3e-b3fc-f78ed7042f94"
      },
      "id": "vqHzByty0bCz",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 399\n",
            "255\n",
            "64\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBhHuDR5lHD",
        "outputId": "1883b12a-7876-4fe9-d4cd-b600b17d2373"
      },
      "id": "crBhHuDR5lHD",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G9GXEts3YwrM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "f5a77638-4d40-4548-8660-d38df4d8d6cc"
      },
      "id": "G9GXEts3YwrM",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sbYOyV7-k0r",
        "outputId": "67da9931-28aa-4fae-b56c-eab5230f3f5d"
      },
      "id": "2sbYOyV7-k0r",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[152, 0, 103]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(2).cuda()\n",
        "#model = CNN_LSTM(2).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Jvl1g601uz",
        "outputId": "7123bc02-0135-4043-be4d-34513f4a3b6e"
      },
      "id": "0-Jvl1g601uz",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/180]\tLR: [0.01]\tLoss 0.9511\tAcc 0.545\n",
            "[Val]Loss 0.6713\tAcc 0.703\n",
            "Epoch: [2/180]\tLR: [0.01]\tLoss 0.7285\tAcc 0.576\n",
            "[Val]Loss 0.6745\tAcc 0.703\n",
            "Epoch: [3/180]\tLR: [0.01]\tLoss 0.6866\tAcc 0.541\n",
            "[Val]Loss 0.6169\tAcc 0.703\n",
            "Epoch: [4/180]\tLR: [0.01]\tLoss 0.6670\tAcc 0.486\n",
            "[Val]Loss 0.6194\tAcc 0.672\n",
            "Epoch: [5/180]\tLR: [0.01]\tLoss 0.7043\tAcc 0.525\n",
            "[Val]Loss 0.7391\tAcc 0.391\n",
            "Epoch: [6/180]\tLR: [0.01]\tLoss 0.7009\tAcc 0.592\n",
            "[Val]Loss 0.6227\tAcc 0.703\n",
            "Epoch: [7/180]\tLR: [0.01]\tLoss 0.6884\tAcc 0.549\n",
            "[Val]Loss 0.6015\tAcc 0.703\n",
            "Epoch: [8/180]\tLR: [0.01]\tLoss 0.6584\tAcc 0.545\n",
            "[Val]Loss 0.6084\tAcc 0.703\n",
            "Epoch: [9/180]\tLR: [0.01]\tLoss 0.6462\tAcc 0.522\n",
            "[Val]Loss 0.6023\tAcc 0.703\n",
            "Epoch: [10/180]\tLR: [0.01]\tLoss 0.6454\tAcc 0.565\n",
            "[Val]Loss 0.6702\tAcc 0.406\n",
            "Epoch: [11/180]\tLR: [0.01]\tLoss 0.6281\tAcc 0.596\n",
            "[Val]Loss 0.5919\tAcc 0.703\n",
            "Epoch: [12/180]\tLR: [0.01]\tLoss 0.6341\tAcc 0.553\n",
            "[Val]Loss 0.5995\tAcc 0.703\n",
            "Epoch: [13/180]\tLR: [0.01]\tLoss 0.6303\tAcc 0.561\n",
            "[Val]Loss 0.5963\tAcc 0.703\n",
            "Epoch: [14/180]\tLR: [0.01]\tLoss 0.6159\tAcc 0.576\n",
            "[Val]Loss 0.6689\tAcc 0.406\n",
            "Epoch: [15/180]\tLR: [0.01]\tLoss 0.6311\tAcc 0.561\n",
            "[Val]Loss 0.6271\tAcc 0.547\n",
            "Epoch: [16/180]\tLR: [0.01]\tLoss 0.6118\tAcc 0.596\n",
            "[Val]Loss 0.6469\tAcc 0.531\n",
            "Epoch: [17/180]\tLR: [0.01]\tLoss 0.6240\tAcc 0.608\n",
            "[Val]Loss 0.6240\tAcc 0.609\n",
            "Epoch: [18/180]\tLR: [0.01]\tLoss 0.6234\tAcc 0.604\n",
            "[Val]Loss 0.6098\tAcc 0.688\n",
            "Epoch: [19/180]\tLR: [0.01]\tLoss 0.6293\tAcc 0.565\n",
            "[Val]Loss 0.6378\tAcc 0.578\n",
            "Epoch: [20/180]\tLR: [0.01]\tLoss 0.6647\tAcc 0.525\n",
            "[Val]Loss 0.6960\tAcc 0.500\n",
            "Epoch: [21/180]\tLR: [0.01]\tLoss 0.6918\tAcc 0.537\n",
            "[Val]Loss 0.6544\tAcc 0.688\n",
            "Epoch: [22/180]\tLR: [0.01]\tLoss 0.6839\tAcc 0.553\n",
            "[Val]Loss 0.6314\tAcc 0.734\n",
            "Epoch: [23/180]\tLR: [0.01]\tLoss 0.6569\tAcc 0.592\n",
            "[Val]Loss 0.6145\tAcc 0.688\n",
            "Epoch: [24/180]\tLR: [0.01]\tLoss 0.6258\tAcc 0.580\n",
            "[Val]Loss 0.6196\tAcc 0.578\n",
            "Epoch: [25/180]\tLR: [0.01]\tLoss 0.6412\tAcc 0.553\n",
            "[Val]Loss 0.6026\tAcc 0.750\n",
            "Epoch: [26/180]\tLR: [0.01]\tLoss 0.6082\tAcc 0.616\n",
            "[Val]Loss 0.7002\tAcc 0.438\n",
            "Epoch: [27/180]\tLR: [0.01]\tLoss 0.6175\tAcc 0.612\n",
            "[Val]Loss 0.5971\tAcc 0.719\n",
            "Epoch: [28/180]\tLR: [0.01]\tLoss 0.6148\tAcc 0.565\n",
            "[Val]Loss 0.6318\tAcc 0.563\n",
            "Epoch: [29/180]\tLR: [0.01]\tLoss 0.6065\tAcc 0.612\n",
            "[Val]Loss 0.6093\tAcc 0.688\n",
            "Epoch: [30/180]\tLR: [0.01]\tLoss 0.6096\tAcc 0.600\n",
            "[Val]Loss 0.7812\tAcc 0.438\n",
            "Epoch: [31/180]\tLR: [0.01]\tLoss 0.6083\tAcc 0.608\n",
            "[Val]Loss 0.6045\tAcc 0.703\n",
            "Epoch: [32/180]\tLR: [0.01]\tLoss 0.5946\tAcc 0.639\n",
            "[Val]Loss 0.6206\tAcc 0.656\n",
            "Epoch: [33/180]\tLR: [0.01]\tLoss 0.6048\tAcc 0.643\n",
            "[Val]Loss 0.6945\tAcc 0.500\n",
            "Epoch: [34/180]\tLR: [0.01]\tLoss 0.6060\tAcc 0.604\n",
            "[Val]Loss 0.5954\tAcc 0.688\n",
            "Epoch: [35/180]\tLR: [0.01]\tLoss 0.6097\tAcc 0.596\n",
            "[Val]Loss 0.6309\tAcc 0.641\n",
            "Epoch: [36/180]\tLR: [0.01]\tLoss 0.5888\tAcc 0.667\n",
            "[Val]Loss 0.7441\tAcc 0.516\n",
            "Epoch: [37/180]\tLR: [0.01]\tLoss 0.6057\tAcc 0.604\n",
            "[Val]Loss 0.6146\tAcc 0.703\n",
            "Epoch: [38/180]\tLR: [0.01]\tLoss 0.6085\tAcc 0.616\n",
            "[Val]Loss 0.6439\tAcc 0.609\n",
            "Epoch: [39/180]\tLR: [0.01]\tLoss 0.6036\tAcc 0.580\n",
            "[Val]Loss 0.6390\tAcc 0.656\n",
            "Epoch: [40/180]\tLR: [0.01]\tLoss 0.5917\tAcc 0.643\n",
            "[Val]Loss 0.6613\tAcc 0.563\n",
            "Epoch: [41/180]\tLR: [0.01]\tLoss 0.6055\tAcc 0.647\n",
            "[Val]Loss 0.5800\tAcc 0.688\n",
            "Epoch: [42/180]\tLR: [0.01]\tLoss 0.5959\tAcc 0.620\n",
            "[Val]Loss 0.5972\tAcc 0.734\n",
            "Epoch: [43/180]\tLR: [0.01]\tLoss 0.5891\tAcc 0.651\n",
            "[Val]Loss 0.6693\tAcc 0.578\n",
            "Epoch: [44/180]\tLR: [0.01]\tLoss 0.5677\tAcc 0.682\n",
            "[Val]Loss 0.7406\tAcc 0.531\n",
            "Epoch: [45/180]\tLR: [0.01]\tLoss 0.5882\tAcc 0.671\n",
            "[Val]Loss 0.6868\tAcc 0.547\n",
            "Epoch: [46/180]\tLR: [0.01]\tLoss 0.5553\tAcc 0.667\n",
            "[Val]Loss 0.7249\tAcc 0.563\n",
            "Epoch: [47/180]\tLR: [0.01]\tLoss 0.5651\tAcc 0.671\n",
            "[Val]Loss 1.0136\tAcc 0.438\n",
            "Epoch: [48/180]\tLR: [0.01]\tLoss 0.6263\tAcc 0.592\n",
            "[Val]Loss 0.6167\tAcc 0.688\n",
            "Epoch: [49/180]\tLR: [0.01]\tLoss 0.5793\tAcc 0.627\n",
            "[Val]Loss 0.6550\tAcc 0.641\n",
            "Epoch: [50/180]\tLR: [0.01]\tLoss 0.5752\tAcc 0.651\n",
            "[Val]Loss 0.6344\tAcc 0.672\n",
            "Epoch: [51/180]\tLR: [0.01]\tLoss 0.5845\tAcc 0.639\n",
            "[Val]Loss 0.5964\tAcc 0.734\n",
            "Epoch: [52/180]\tLR: [0.01]\tLoss 0.5688\tAcc 0.647\n",
            "[Val]Loss 0.6742\tAcc 0.516\n",
            "Epoch: [53/180]\tLR: [0.01]\tLoss 0.5513\tAcc 0.678\n",
            "[Val]Loss 0.6406\tAcc 0.766\n",
            "Epoch: [54/180]\tLR: [0.01]\tLoss 0.5697\tAcc 0.667\n",
            "[Val]Loss 0.6144\tAcc 0.703\n",
            "Epoch: [55/180]\tLR: [0.01]\tLoss 0.5759\tAcc 0.659\n",
            "[Val]Loss 0.6076\tAcc 0.734\n",
            "Epoch: [56/180]\tLR: [0.01]\tLoss 0.5637\tAcc 0.671\n",
            "[Val]Loss 0.6229\tAcc 0.672\n",
            "Epoch: [57/180]\tLR: [0.01]\tLoss 0.5289\tAcc 0.741\n",
            "[Val]Loss 0.6886\tAcc 0.625\n",
            "Epoch: [58/180]\tLR: [0.01]\tLoss 0.5572\tAcc 0.675\n",
            "[Val]Loss 0.5798\tAcc 0.734\n",
            "Epoch: [59/180]\tLR: [0.01]\tLoss 0.5456\tAcc 0.714\n",
            "[Val]Loss 0.6771\tAcc 0.563\n",
            "Epoch: [60/180]\tLR: [0.01]\tLoss 0.5446\tAcc 0.714\n",
            "[Val]Loss 1.0191\tAcc 0.422\n",
            "Epoch: [61/180]\tLR: [0.001]\tLoss 0.5660\tAcc 0.690\n",
            "[Val]Loss 0.5809\tAcc 0.703\n",
            "Epoch: [62/180]\tLR: [0.001]\tLoss 0.4710\tAcc 0.761\n",
            "[Val]Loss 0.6099\tAcc 0.703\n",
            "Epoch: [63/180]\tLR: [0.001]\tLoss 0.4405\tAcc 0.812\n",
            "[Val]Loss 0.5910\tAcc 0.688\n",
            "Epoch: [64/180]\tLR: [0.001]\tLoss 0.4267\tAcc 0.804\n",
            "[Val]Loss 0.5737\tAcc 0.703\n",
            "Epoch: [65/180]\tLR: [0.001]\tLoss 0.4137\tAcc 0.812\n",
            "[Val]Loss 0.6317\tAcc 0.719\n",
            "Epoch: [66/180]\tLR: [0.001]\tLoss 0.4054\tAcc 0.804\n",
            "[Val]Loss 0.5987\tAcc 0.703\n",
            "Epoch: [67/180]\tLR: [0.001]\tLoss 0.3888\tAcc 0.835\n",
            "[Val]Loss 0.5686\tAcc 0.750\n",
            "Epoch: [68/180]\tLR: [0.001]\tLoss 0.3949\tAcc 0.839\n",
            "[Val]Loss 0.5644\tAcc 0.766\n",
            "Epoch: [69/180]\tLR: [0.001]\tLoss 0.3814\tAcc 0.820\n",
            "[Val]Loss 0.6312\tAcc 0.719\n",
            "Epoch: [70/180]\tLR: [0.001]\tLoss 0.3666\tAcc 0.831\n",
            "[Val]Loss 0.5810\tAcc 0.734\n",
            "Epoch: [71/180]\tLR: [0.001]\tLoss 0.3586\tAcc 0.835\n",
            "[Val]Loss 0.5429\tAcc 0.750\n",
            "Epoch: [72/180]\tLR: [0.001]\tLoss 0.4003\tAcc 0.796\n",
            "[Val]Loss 0.5376\tAcc 0.750\n",
            "Epoch: [73/180]\tLR: [0.001]\tLoss 0.3558\tAcc 0.847\n",
            "[Val]Loss 0.5850\tAcc 0.734\n",
            "Epoch: [74/180]\tLR: [0.001]\tLoss 0.3297\tAcc 0.863\n",
            "[Val]Loss 0.6447\tAcc 0.766\n",
            "Epoch: [75/180]\tLR: [0.001]\tLoss 0.3272\tAcc 0.867\n",
            "[Val]Loss 0.7171\tAcc 0.750\n",
            "Epoch: [76/180]\tLR: [0.001]\tLoss 0.3257\tAcc 0.875\n",
            "[Val]Loss 0.5583\tAcc 0.750\n",
            "Epoch: [77/180]\tLR: [0.001]\tLoss 0.3304\tAcc 0.847\n",
            "[Val]Loss 0.5672\tAcc 0.734\n",
            "Epoch: [78/180]\tLR: [0.001]\tLoss 0.2950\tAcc 0.875\n",
            "[Val]Loss 0.6160\tAcc 0.766\n",
            "Epoch: [79/180]\tLR: [0.001]\tLoss 0.2894\tAcc 0.890\n",
            "[Val]Loss 0.7441\tAcc 0.750\n",
            "Epoch: [80/180]\tLR: [0.001]\tLoss 0.2977\tAcc 0.871\n",
            "[Val]Loss 0.6009\tAcc 0.734\n",
            "Epoch: [81/180]\tLR: [0.001]\tLoss 0.3117\tAcc 0.855\n",
            "[Val]Loss 0.5843\tAcc 0.734\n",
            "Epoch: [82/180]\tLR: [0.001]\tLoss 0.3028\tAcc 0.878\n",
            "[Val]Loss 0.7674\tAcc 0.750\n",
            "Epoch: [83/180]\tLR: [0.001]\tLoss 0.2572\tAcc 0.922\n",
            "[Val]Loss 0.5804\tAcc 0.750\n",
            "Epoch: [84/180]\tLR: [0.001]\tLoss 0.2459\tAcc 0.906\n",
            "[Val]Loss 0.7767\tAcc 0.750\n",
            "Epoch: [85/180]\tLR: [0.001]\tLoss 0.2412\tAcc 0.910\n",
            "[Val]Loss 0.7112\tAcc 0.750\n",
            "Epoch: [86/180]\tLR: [0.001]\tLoss 0.2745\tAcc 0.863\n",
            "[Val]Loss 0.9969\tAcc 0.703\n",
            "Epoch: [87/180]\tLR: [0.001]\tLoss 0.2672\tAcc 0.871\n",
            "[Val]Loss 0.9632\tAcc 0.672\n",
            "Epoch: [88/180]\tLR: [0.001]\tLoss 0.2662\tAcc 0.886\n",
            "[Val]Loss 0.9591\tAcc 0.734\n",
            "Epoch: [89/180]\tLR: [0.001]\tLoss 0.2554\tAcc 0.894\n",
            "[Val]Loss 0.9738\tAcc 0.688\n",
            "Epoch: [90/180]\tLR: [0.001]\tLoss 0.2448\tAcc 0.906\n",
            "[Val]Loss 0.7425\tAcc 0.766\n",
            "Epoch: [91/180]\tLR: [0.001]\tLoss 0.2998\tAcc 0.878\n",
            "[Val]Loss 0.8312\tAcc 0.734\n",
            "Epoch: [92/180]\tLR: [0.001]\tLoss 0.2428\tAcc 0.898\n",
            "[Val]Loss 0.7364\tAcc 0.766\n",
            "Epoch: [93/180]\tLR: [0.001]\tLoss 0.2214\tAcc 0.910\n",
            "[Val]Loss 0.8104\tAcc 0.734\n",
            "Epoch: [94/180]\tLR: [0.001]\tLoss 0.2243\tAcc 0.890\n",
            "[Val]Loss 0.8262\tAcc 0.750\n",
            "Epoch: [95/180]\tLR: [0.001]\tLoss 0.2125\tAcc 0.918\n",
            "[Val]Loss 0.8748\tAcc 0.750\n",
            "Epoch: [96/180]\tLR: [0.001]\tLoss 0.1963\tAcc 0.914\n",
            "[Val]Loss 1.0345\tAcc 0.750\n",
            "Epoch: [97/180]\tLR: [0.001]\tLoss 0.1810\tAcc 0.933\n",
            "[Val]Loss 1.0043\tAcc 0.734\n",
            "Epoch: [98/180]\tLR: [0.001]\tLoss 0.1858\tAcc 0.922\n",
            "[Val]Loss 0.8672\tAcc 0.781\n",
            "Epoch: [99/180]\tLR: [0.001]\tLoss 0.1746\tAcc 0.925\n",
            "[Val]Loss 1.3006\tAcc 0.703\n",
            "Epoch: [100/180]\tLR: [0.001]\tLoss 0.1655\tAcc 0.929\n",
            "[Val]Loss 1.0447\tAcc 0.750\n",
            "Epoch: [101/180]\tLR: [0.001]\tLoss 0.1437\tAcc 0.945\n",
            "[Val]Loss 0.8769\tAcc 0.734\n",
            "Epoch: [102/180]\tLR: [0.001]\tLoss 0.1398\tAcc 0.957\n",
            "[Val]Loss 1.3844\tAcc 0.719\n",
            "Epoch: [103/180]\tLR: [0.001]\tLoss 0.1728\tAcc 0.937\n",
            "[Val]Loss 1.5374\tAcc 0.688\n",
            "Epoch: [104/180]\tLR: [0.001]\tLoss 0.1981\tAcc 0.910\n",
            "[Val]Loss 1.4311\tAcc 0.719\n",
            "Epoch: [105/180]\tLR: [0.001]\tLoss 0.2047\tAcc 0.914\n",
            "[Val]Loss 1.7331\tAcc 0.672\n",
            "Epoch: [106/180]\tLR: [0.001]\tLoss 0.3228\tAcc 0.886\n",
            "[Val]Loss 1.6395\tAcc 0.641\n",
            "Epoch: [107/180]\tLR: [0.001]\tLoss 0.3496\tAcc 0.827\n",
            "[Val]Loss 1.1476\tAcc 0.688\n",
            "Epoch: [108/180]\tLR: [0.001]\tLoss 0.2553\tAcc 0.902\n",
            "[Val]Loss 1.2923\tAcc 0.672\n",
            "Epoch: [109/180]\tLR: [0.001]\tLoss 0.2800\tAcc 0.886\n",
            "[Val]Loss 0.7993\tAcc 0.781\n",
            "Epoch: [110/180]\tLR: [0.001]\tLoss 0.2099\tAcc 0.918\n",
            "[Val]Loss 1.3119\tAcc 0.734\n",
            "Epoch: [111/180]\tLR: [0.001]\tLoss 0.2638\tAcc 0.902\n",
            "[Val]Loss 0.8702\tAcc 0.703\n",
            "Epoch: [112/180]\tLR: [0.001]\tLoss 0.1659\tAcc 0.933\n",
            "[Val]Loss 1.1777\tAcc 0.734\n",
            "Epoch: [113/180]\tLR: [0.001]\tLoss 0.1647\tAcc 0.929\n",
            "[Val]Loss 0.9988\tAcc 0.766\n",
            "Epoch: [114/180]\tLR: [0.001]\tLoss 0.1335\tAcc 0.969\n",
            "[Val]Loss 1.1165\tAcc 0.750\n",
            "Epoch: [115/180]\tLR: [0.001]\tLoss 0.1280\tAcc 0.961\n",
            "[Val]Loss 1.1390\tAcc 0.750\n",
            "Epoch: [116/180]\tLR: [0.001]\tLoss 0.1173\tAcc 0.976\n",
            "[Val]Loss 1.0279\tAcc 0.703\n",
            "Epoch: [117/180]\tLR: [0.001]\tLoss 0.1087\tAcc 0.969\n",
            "[Val]Loss 0.9886\tAcc 0.750\n",
            "Epoch: [118/180]\tLR: [0.001]\tLoss 0.0992\tAcc 0.980\n",
            "[Val]Loss 1.2320\tAcc 0.734\n",
            "Epoch: [119/180]\tLR: [0.001]\tLoss 0.1003\tAcc 0.961\n",
            "[Val]Loss 1.5664\tAcc 0.734\n",
            "Epoch: [120/180]\tLR: [0.001]\tLoss 0.1270\tAcc 0.949\n",
            "[Val]Loss 1.6810\tAcc 0.719\n",
            "Epoch: [121/180]\tLR: [0.0001]\tLoss 0.1224\tAcc 0.961\n",
            "[Val]Loss 1.3020\tAcc 0.734\n",
            "Epoch: [122/180]\tLR: [0.0001]\tLoss 0.0842\tAcc 0.973\n",
            "[Val]Loss 1.3621\tAcc 0.734\n",
            "Epoch: [123/180]\tLR: [0.0001]\tLoss 0.0806\tAcc 0.988\n",
            "[Val]Loss 1.3112\tAcc 0.734\n",
            "Epoch: [124/180]\tLR: [0.0001]\tLoss 0.0768\tAcc 0.984\n",
            "[Val]Loss 1.3393\tAcc 0.734\n",
            "Epoch: [125/180]\tLR: [0.0001]\tLoss 0.0762\tAcc 0.984\n",
            "[Val]Loss 1.3746\tAcc 0.750\n",
            "Epoch: [126/180]\tLR: [0.0001]\tLoss 0.0752\tAcc 0.980\n",
            "[Val]Loss 1.2969\tAcc 0.734\n",
            "Epoch: [127/180]\tLR: [0.0001]\tLoss 0.0750\tAcc 0.984\n",
            "[Val]Loss 1.3159\tAcc 0.734\n",
            "Epoch: [128/180]\tLR: [0.0001]\tLoss 0.0737\tAcc 0.984\n",
            "[Val]Loss 1.3384\tAcc 0.750\n",
            "Epoch: [129/180]\tLR: [0.0001]\tLoss 0.0725\tAcc 0.984\n",
            "[Val]Loss 1.3341\tAcc 0.734\n",
            "Epoch: [130/180]\tLR: [0.0001]\tLoss 0.0719\tAcc 0.984\n",
            "[Val]Loss 1.3395\tAcc 0.766\n",
            "Epoch: [131/180]\tLR: [0.0001]\tLoss 0.0724\tAcc 0.984\n",
            "[Val]Loss 1.3320\tAcc 0.750\n",
            "Epoch: [132/180]\tLR: [0.0001]\tLoss 0.0709\tAcc 0.984\n",
            "[Val]Loss 1.3052\tAcc 0.750\n",
            "Epoch: [133/180]\tLR: [0.0001]\tLoss 0.0707\tAcc 0.984\n",
            "[Val]Loss 1.3495\tAcc 0.766\n",
            "Epoch: [134/180]\tLR: [0.0001]\tLoss 0.0695\tAcc 0.984\n",
            "[Val]Loss 1.3265\tAcc 0.750\n",
            "Epoch: [135/180]\tLR: [0.0001]\tLoss 0.0689\tAcc 0.988\n",
            "[Val]Loss 1.3549\tAcc 0.766\n",
            "Epoch: [136/180]\tLR: [0.0001]\tLoss 0.0681\tAcc 0.988\n",
            "[Val]Loss 1.3476\tAcc 0.766\n",
            "Epoch: [137/180]\tLR: [0.0001]\tLoss 0.0679\tAcc 0.992\n",
            "[Val]Loss 1.3600\tAcc 0.766\n",
            "Epoch: [138/180]\tLR: [0.0001]\tLoss 0.0673\tAcc 0.992\n",
            "[Val]Loss 1.3526\tAcc 0.766\n",
            "Epoch: [139/180]\tLR: [0.0001]\tLoss 0.0668\tAcc 0.992\n",
            "[Val]Loss 1.3466\tAcc 0.766\n",
            "Epoch: [140/180]\tLR: [0.0001]\tLoss 0.0662\tAcc 0.988\n",
            "[Val]Loss 1.3571\tAcc 0.766\n",
            "Epoch: [141/180]\tLR: [0.0001]\tLoss 0.0657\tAcc 0.992\n",
            "[Val]Loss 1.3684\tAcc 0.766\n",
            "Epoch: [142/180]\tLR: [0.0001]\tLoss 0.0654\tAcc 0.992\n",
            "[Val]Loss 1.3852\tAcc 0.766\n",
            "Epoch: [143/180]\tLR: [0.0001]\tLoss 0.0643\tAcc 0.992\n",
            "[Val]Loss 1.3763\tAcc 0.766\n",
            "Epoch: [144/180]\tLR: [0.0001]\tLoss 0.0645\tAcc 0.992\n",
            "[Val]Loss 1.3689\tAcc 0.766\n",
            "Epoch: [145/180]\tLR: [0.0001]\tLoss 0.0636\tAcc 0.992\n",
            "[Val]Loss 1.4113\tAcc 0.766\n",
            "Epoch: [146/180]\tLR: [0.0001]\tLoss 0.0652\tAcc 0.992\n",
            "[Val]Loss 1.3601\tAcc 0.766\n",
            "Epoch: [147/180]\tLR: [0.0001]\tLoss 0.0632\tAcc 0.992\n",
            "[Val]Loss 1.3836\tAcc 0.766\n",
            "Epoch: [148/180]\tLR: [0.0001]\tLoss 0.0620\tAcc 0.992\n",
            "[Val]Loss 1.4067\tAcc 0.766\n",
            "Epoch: [149/180]\tLR: [0.0001]\tLoss 0.0622\tAcc 0.992\n",
            "[Val]Loss 1.4273\tAcc 0.766\n",
            "Epoch: [150/180]\tLR: [0.0001]\tLoss 0.0611\tAcc 0.992\n",
            "[Val]Loss 1.4300\tAcc 0.766\n",
            "Epoch: [151/180]\tLR: [0.0001]\tLoss 0.0608\tAcc 0.992\n",
            "[Val]Loss 1.4091\tAcc 0.766\n",
            "Epoch: [152/180]\tLR: [0.0001]\tLoss 0.0605\tAcc 0.992\n",
            "[Val]Loss 1.4513\tAcc 0.766\n",
            "Epoch: [153/180]\tLR: [0.0001]\tLoss 0.0600\tAcc 0.992\n",
            "[Val]Loss 1.4008\tAcc 0.766\n",
            "Epoch: [154/180]\tLR: [0.0001]\tLoss 0.0604\tAcc 0.992\n",
            "[Val]Loss 1.4341\tAcc 0.766\n",
            "Epoch: [155/180]\tLR: [0.0001]\tLoss 0.0616\tAcc 0.992\n",
            "[Val]Loss 1.4562\tAcc 0.766\n",
            "Epoch: [156/180]\tLR: [0.0001]\tLoss 0.0588\tAcc 0.992\n",
            "[Val]Loss 1.4027\tAcc 0.766\n",
            "Epoch: [157/180]\tLR: [0.0001]\tLoss 0.0591\tAcc 0.992\n",
            "[Val]Loss 1.4607\tAcc 0.766\n",
            "Epoch: [158/180]\tLR: [0.0001]\tLoss 0.0592\tAcc 0.992\n",
            "[Val]Loss 1.4218\tAcc 0.766\n",
            "Epoch: [159/180]\tLR: [0.0001]\tLoss 0.0578\tAcc 0.992\n",
            "[Val]Loss 1.4542\tAcc 0.766\n",
            "Epoch: [160/180]\tLR: [0.0001]\tLoss 0.0578\tAcc 0.992\n",
            "[Val]Loss 1.4508\tAcc 0.766\n",
            "Epoch: [161/180]\tLR: [0.0001]\tLoss 0.0576\tAcc 0.992\n",
            "[Val]Loss 1.4632\tAcc 0.766\n",
            "Epoch: [162/180]\tLR: [0.0001]\tLoss 0.0561\tAcc 0.992\n",
            "[Val]Loss 1.4298\tAcc 0.766\n",
            "Epoch: [163/180]\tLR: [0.0001]\tLoss 0.0562\tAcc 0.992\n",
            "[Val]Loss 1.4529\tAcc 0.766\n",
            "Epoch: [164/180]\tLR: [0.0001]\tLoss 0.0554\tAcc 0.992\n",
            "[Val]Loss 1.4761\tAcc 0.766\n",
            "Epoch: [165/180]\tLR: [0.0001]\tLoss 0.0561\tAcc 0.992\n",
            "[Val]Loss 1.4635\tAcc 0.766\n",
            "Epoch: [166/180]\tLR: [0.0001]\tLoss 0.0547\tAcc 0.992\n",
            "[Val]Loss 1.4546\tAcc 0.766\n",
            "Epoch: [167/180]\tLR: [0.0001]\tLoss 0.0541\tAcc 0.992\n",
            "[Val]Loss 1.4832\tAcc 0.766\n",
            "Epoch: [168/180]\tLR: [0.0001]\tLoss 0.0543\tAcc 0.992\n",
            "[Val]Loss 1.4856\tAcc 0.766\n",
            "Epoch: [169/180]\tLR: [0.0001]\tLoss 0.0532\tAcc 0.992\n",
            "[Val]Loss 1.4759\tAcc 0.766\n",
            "Epoch: [170/180]\tLR: [0.0001]\tLoss 0.0530\tAcc 0.992\n",
            "[Val]Loss 1.4930\tAcc 0.766\n",
            "Epoch: [171/180]\tLR: [0.0001]\tLoss 0.0527\tAcc 0.992\n",
            "[Val]Loss 1.4986\tAcc 0.766\n",
            "Epoch: [172/180]\tLR: [0.0001]\tLoss 0.0531\tAcc 0.992\n",
            "[Val]Loss 1.5179\tAcc 0.766\n",
            "Epoch: [173/180]\tLR: [0.0001]\tLoss 0.0527\tAcc 0.992\n",
            "[Val]Loss 1.4978\tAcc 0.766\n",
            "Epoch: [174/180]\tLR: [0.0001]\tLoss 0.0519\tAcc 0.992\n",
            "[Val]Loss 1.5123\tAcc 0.766\n",
            "Epoch: [175/180]\tLR: [0.0001]\tLoss 0.0517\tAcc 0.992\n",
            "[Val]Loss 1.4978\tAcc 0.766\n",
            "Epoch: [176/180]\tLR: [0.0001]\tLoss 0.0510\tAcc 0.992\n",
            "[Val]Loss 1.5309\tAcc 0.766\n",
            "Epoch: [177/180]\tLR: [0.0001]\tLoss 0.0508\tAcc 0.992\n",
            "[Val]Loss 1.5055\tAcc 0.766\n",
            "Epoch: [178/180]\tLR: [0.0001]\tLoss 0.0505\tAcc 0.992\n",
            "[Val]Loss 1.5373\tAcc 0.766\n",
            "Epoch: [179/180]\tLR: [0.0001]\tLoss 0.0501\tAcc 0.992\n",
            "[Val]Loss 1.5070\tAcc 0.766\n",
            "Epoch: [180/180]\tLR: [0.0001]\tLoss 0.0500\tAcc 0.996\n",
            "[Val]Loss 1.5389\tAcc 0.766\n",
            "[Val]Loss 1.1594\tAcc 0.725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our Model: 3-Class classification (Softmax)\n",
        "### Our Results: \\[\"Normal\", \"Prehypertension\", \"hypertension\"]"
      ],
      "metadata": {
        "id": "HTXtwIrl5F3R"
      },
      "id": "HTXtwIrl5F3R"
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv3Net(nn.Module):\n",
        "    def __init__(self, n_class=3):\n",
        "        super(Conv3Net, self).__init__()\n",
        "        self.n_class = n_class\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=30, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, kernel_size=15, stride=3, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7),\n",
        "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "zcw22eY7lHuH"
      },
      "id": "zcw22eY7lHuH",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean=2060.61\n",
        "data_std=285.13\n",
        "data_normalization = {'mean':data_mean,'std':data_std}\n",
        "\n",
        "# setup data loader\n",
        "dataset = BPDataset(ppg_dir, label_path, normalize=data_normalization, choose_class=[0,1,2])\n",
        "print('dataset: {}'.format(dataset.__len__()))\n",
        "\n",
        "# Split training data, validation data, testing data\n",
        "# [0,1] -> [312, 78, 97]\n",
        "# [0,2] -> [255, 64, 80]\n",
        "# [0,1,2]-> [415, 104, 129]\n",
        "data_train, data_val, data_test = torch.utils.data.random_split(dataset, [415, 104, 129])\n",
        "print(data_train.__len__())\n",
        "print(data_val.__len__())\n",
        "print(data_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLY2TjiE5-R7",
        "outputId": "9fb2888d-00d6-4021-e84f-c4f3b9d4cdd3"
      },
      "id": "xLY2TjiE5-R7",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: 648\n",
            "415\n",
            "104\n",
            "129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=10,shuffle=True),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=10,shuffle=True),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=10,shuffle=False)}\n",
        "dataset_sizes = {'train': data_train.__len__(),\n",
        "                    'val':data_val.__len__(),\n",
        "                    'test':data_test.__len__()}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:',device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PvZSPBw6Dp5",
        "outputId": "9017c6c9-3b5e-466d-c787-90983a92593b"
      },
      "id": "4PvZSPBw6Dp5",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataloaders={'train': torch.utils.data.DataLoader(data_train,batch_size=1,shuffle=False),\n",
        "                'val':torch.utils.data.DataLoader(data_val,batch_size=1,shuffle=False),\n",
        "                'test':torch.utils.data.DataLoader(data_test,batch_size=1,shuffle=False)}\n",
        "\n",
        "train_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['train']:\n",
        "    if label.data==0:\n",
        "        train_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        train_labels[1]+=1\n",
        "    else:\n",
        "        train_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),train_labels,color=['g','b','r'],width=0.7)\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Training-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "val_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['val']:\n",
        "    if label.data==0:\n",
        "        val_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        val_labels[1]+=1\n",
        "    else:\n",
        "        val_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),val_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Validation-set Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "test_labels=[0,0,0]\n",
        "for data, label, subject in temp_dataloaders['test']:\n",
        "    if label.data==0:\n",
        "        test_labels[0]+=1\n",
        "    elif label.data==1:\n",
        "        test_labels[1]+=1\n",
        "    else:\n",
        "        test_labels[2]+=1\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(np.arange(3),test_labels,color=['g','b','r'])\n",
        "plt.xticks(np.arange(3),['Normal','Prehypertension','Hypertension'])\n",
        "plt.title('Test-set Class Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "uAiwYbRB6IR4",
        "outputId": "2ab91502-78c6-4e5e-d7d6-44a260e3f7bb"
      },
      "id": "uAiwYbRB6IR4",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels, val_labels, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSf9xH5U7B0I",
        "outputId": "607bf88b-9fa7-4a65-e435-54903c2fef35"
      },
      "id": "dSf9xH5U7B0I",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[149, 160, 106] [39, 39, 26] [50, 50, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv3Net(3).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "n_epoch = 180\n",
        "loss = 0\n",
        "acc = 0\n",
        "best_acc = 0\n",
        "for ep in range(n_epoch):\n",
        "    train_acc, train_loss = train(dataloaders['train'], model, optimizer, ep, criterion)\n",
        "    val_acc, val_loss = val(dataloaders['val'], model, criterion)\n",
        "    if val_acc > best_acc:\n",
        "        state = {\n",
        "            'epoch': ep + 1,\n",
        "            'acc': acc,\n",
        "            'model_state': model.state_dict(),\n",
        "        }\n",
        "        best_acc = val_acc\n",
        "    if (ep + 1) % 60 == 0:\n",
        "        lr_decay(optimizer, decay_rate=0.1)\n",
        "\n",
        "model.load_state_dict(state['model_state'])\n",
        "test_acc, test_loss = val(dataloaders['test'], model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2w5A784l8Ua",
        "outputId": "2e6a8e90-944b-42d4-bbf5-b6a3774d0f6b"
      },
      "id": "K2w5A784l8Ua",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/180]\tLR: [0.01]\tLoss 1.0831\tAcc 0.378\n",
            "[Val]Loss 1.0601\tAcc 0.442\n",
            "Epoch: [2/180]\tLR: [0.01]\tLoss 1.0596\tAcc 0.410\n",
            "[Val]Loss 1.0136\tAcc 0.404\n",
            "Epoch: [3/180]\tLR: [0.01]\tLoss 1.0526\tAcc 0.427\n",
            "[Val]Loss 1.0060\tAcc 0.452\n",
            "Epoch: [4/180]\tLR: [0.01]\tLoss 1.0265\tAcc 0.441\n",
            "[Val]Loss 1.0091\tAcc 0.442\n",
            "Epoch: [5/180]\tLR: [0.01]\tLoss 1.0400\tAcc 0.419\n",
            "[Val]Loss 1.0052\tAcc 0.442\n",
            "Epoch: [6/180]\tLR: [0.01]\tLoss 1.0386\tAcc 0.441\n",
            "[Val]Loss 1.0312\tAcc 0.442\n",
            "Epoch: [7/180]\tLR: [0.01]\tLoss 1.0166\tAcc 0.446\n",
            "[Val]Loss 1.0648\tAcc 0.413\n",
            "Epoch: [8/180]\tLR: [0.01]\tLoss 1.0137\tAcc 0.436\n",
            "[Val]Loss 1.0203\tAcc 0.433\n",
            "Epoch: [9/180]\tLR: [0.01]\tLoss 1.0072\tAcc 0.446\n",
            "[Val]Loss 1.0246\tAcc 0.404\n",
            "Epoch: [10/180]\tLR: [0.01]\tLoss 1.0124\tAcc 0.441\n",
            "[Val]Loss 1.0128\tAcc 0.404\n",
            "Epoch: [11/180]\tLR: [0.01]\tLoss 1.0004\tAcc 0.441\n",
            "[Val]Loss 1.0285\tAcc 0.394\n",
            "Epoch: [12/180]\tLR: [0.01]\tLoss 0.9875\tAcc 0.484\n",
            "[Val]Loss 1.0941\tAcc 0.394\n",
            "Epoch: [13/180]\tLR: [0.01]\tLoss 1.0153\tAcc 0.453\n",
            "[Val]Loss 1.0946\tAcc 0.279\n",
            "Epoch: [14/180]\tLR: [0.01]\tLoss 1.0004\tAcc 0.427\n",
            "[Val]Loss 1.0349\tAcc 0.423\n",
            "Epoch: [15/180]\tLR: [0.01]\tLoss 0.9856\tAcc 0.480\n",
            "[Val]Loss 1.0459\tAcc 0.317\n",
            "Epoch: [16/180]\tLR: [0.01]\tLoss 0.9742\tAcc 0.475\n",
            "[Val]Loss 1.0292\tAcc 0.433\n",
            "Epoch: [17/180]\tLR: [0.01]\tLoss 0.9796\tAcc 0.496\n",
            "[Val]Loss 1.0282\tAcc 0.394\n",
            "Epoch: [18/180]\tLR: [0.01]\tLoss 0.9908\tAcc 0.492\n",
            "[Val]Loss 1.0217\tAcc 0.423\n",
            "Epoch: [19/180]\tLR: [0.01]\tLoss 0.9694\tAcc 0.504\n",
            "[Val]Loss 1.0423\tAcc 0.375\n",
            "Epoch: [20/180]\tLR: [0.01]\tLoss 0.9767\tAcc 0.489\n",
            "[Val]Loss 1.0350\tAcc 0.433\n",
            "Epoch: [21/180]\tLR: [0.01]\tLoss 0.9524\tAcc 0.487\n",
            "[Val]Loss 1.0948\tAcc 0.423\n",
            "Epoch: [22/180]\tLR: [0.01]\tLoss 0.9671\tAcc 0.492\n",
            "[Val]Loss 1.0408\tAcc 0.375\n",
            "Epoch: [23/180]\tLR: [0.01]\tLoss 0.9675\tAcc 0.504\n",
            "[Val]Loss 1.0215\tAcc 0.404\n",
            "Epoch: [24/180]\tLR: [0.01]\tLoss 0.9697\tAcc 0.508\n",
            "[Val]Loss 1.0054\tAcc 0.433\n",
            "Epoch: [25/180]\tLR: [0.01]\tLoss 0.9682\tAcc 0.489\n",
            "[Val]Loss 1.0665\tAcc 0.442\n",
            "Epoch: [26/180]\tLR: [0.01]\tLoss 0.9490\tAcc 0.528\n",
            "[Val]Loss 1.0410\tAcc 0.404\n",
            "Epoch: [27/180]\tLR: [0.01]\tLoss 0.9361\tAcc 0.520\n",
            "[Val]Loss 1.0607\tAcc 0.413\n",
            "Epoch: [28/180]\tLR: [0.01]\tLoss 0.9454\tAcc 0.533\n",
            "[Val]Loss 1.0499\tAcc 0.433\n",
            "Epoch: [29/180]\tLR: [0.01]\tLoss 0.9362\tAcc 0.535\n",
            "[Val]Loss 1.0558\tAcc 0.413\n",
            "Epoch: [30/180]\tLR: [0.01]\tLoss 0.9281\tAcc 0.535\n",
            "[Val]Loss 1.0965\tAcc 0.385\n",
            "Epoch: [31/180]\tLR: [0.01]\tLoss 0.9483\tAcc 0.513\n",
            "[Val]Loss 1.0063\tAcc 0.452\n",
            "Epoch: [32/180]\tLR: [0.01]\tLoss 0.8876\tAcc 0.552\n",
            "[Val]Loss 1.0413\tAcc 0.519\n",
            "Epoch: [33/180]\tLR: [0.01]\tLoss 0.9172\tAcc 0.559\n",
            "[Val]Loss 1.0623\tAcc 0.433\n",
            "Epoch: [34/180]\tLR: [0.01]\tLoss 0.9277\tAcc 0.525\n",
            "[Val]Loss 1.1161\tAcc 0.433\n",
            "Epoch: [35/180]\tLR: [0.01]\tLoss 0.8951\tAcc 0.547\n",
            "[Val]Loss 1.1198\tAcc 0.404\n",
            "Epoch: [36/180]\tLR: [0.01]\tLoss 0.8685\tAcc 0.549\n",
            "[Val]Loss 1.0923\tAcc 0.423\n",
            "Epoch: [37/180]\tLR: [0.01]\tLoss 0.9112\tAcc 0.564\n",
            "[Val]Loss 1.1527\tAcc 0.394\n",
            "Epoch: [38/180]\tLR: [0.01]\tLoss 0.8986\tAcc 0.537\n",
            "[Val]Loss 1.0108\tAcc 0.462\n",
            "Epoch: [39/180]\tLR: [0.01]\tLoss 0.8658\tAcc 0.578\n",
            "[Val]Loss 1.1763\tAcc 0.442\n",
            "Epoch: [40/180]\tLR: [0.01]\tLoss 0.8362\tAcc 0.595\n",
            "[Val]Loss 1.0478\tAcc 0.481\n",
            "Epoch: [41/180]\tLR: [0.01]\tLoss 0.8575\tAcc 0.588\n",
            "[Val]Loss 0.9994\tAcc 0.529\n",
            "Epoch: [42/180]\tLR: [0.01]\tLoss 0.8497\tAcc 0.571\n",
            "[Val]Loss 1.0837\tAcc 0.471\n",
            "Epoch: [43/180]\tLR: [0.01]\tLoss 0.8703\tAcc 0.588\n",
            "[Val]Loss 1.0762\tAcc 0.481\n",
            "Epoch: [44/180]\tLR: [0.01]\tLoss 0.8336\tAcc 0.598\n",
            "[Val]Loss 1.1173\tAcc 0.500\n",
            "Epoch: [45/180]\tLR: [0.01]\tLoss 0.8385\tAcc 0.619\n",
            "[Val]Loss 1.0852\tAcc 0.462\n",
            "Epoch: [46/180]\tLR: [0.01]\tLoss 0.7993\tAcc 0.602\n",
            "[Val]Loss 1.1265\tAcc 0.471\n",
            "Epoch: [47/180]\tLR: [0.01]\tLoss 0.8275\tAcc 0.602\n",
            "[Val]Loss 1.0316\tAcc 0.500\n",
            "Epoch: [48/180]\tLR: [0.01]\tLoss 0.8170\tAcc 0.581\n",
            "[Val]Loss 1.0547\tAcc 0.548\n",
            "Epoch: [49/180]\tLR: [0.01]\tLoss 0.7887\tAcc 0.624\n",
            "[Val]Loss 1.2032\tAcc 0.462\n",
            "Epoch: [50/180]\tLR: [0.01]\tLoss 0.9000\tAcc 0.610\n",
            "[Val]Loss 1.0319\tAcc 0.481\n",
            "Epoch: [51/180]\tLR: [0.01]\tLoss 0.7817\tAcc 0.612\n",
            "[Val]Loss 1.0831\tAcc 0.558\n",
            "Epoch: [52/180]\tLR: [0.01]\tLoss 0.8544\tAcc 0.600\n",
            "[Val]Loss 1.1357\tAcc 0.442\n",
            "Epoch: [53/180]\tLR: [0.01]\tLoss 0.8791\tAcc 0.561\n",
            "[Val]Loss 1.1528\tAcc 0.471\n",
            "Epoch: [54/180]\tLR: [0.01]\tLoss 0.7976\tAcc 0.634\n",
            "[Val]Loss 1.2217\tAcc 0.510\n",
            "Epoch: [55/180]\tLR: [0.01]\tLoss 0.7731\tAcc 0.658\n",
            "[Val]Loss 1.5524\tAcc 0.442\n",
            "Epoch: [56/180]\tLR: [0.01]\tLoss 0.7241\tAcc 0.665\n",
            "[Val]Loss 1.3547\tAcc 0.519\n",
            "Epoch: [57/180]\tLR: [0.01]\tLoss 0.6819\tAcc 0.689\n",
            "[Val]Loss 1.3752\tAcc 0.500\n",
            "Epoch: [58/180]\tLR: [0.01]\tLoss 0.7373\tAcc 0.672\n",
            "[Val]Loss 1.4396\tAcc 0.452\n",
            "Epoch: [59/180]\tLR: [0.01]\tLoss 0.7585\tAcc 0.629\n",
            "[Val]Loss 1.5500\tAcc 0.442\n",
            "Epoch: [60/180]\tLR: [0.01]\tLoss 0.7637\tAcc 0.643\n",
            "[Val]Loss 1.4451\tAcc 0.510\n",
            "Epoch: [61/180]\tLR: [0.001]\tLoss 0.6396\tAcc 0.708\n",
            "[Val]Loss 1.3391\tAcc 0.471\n",
            "Epoch: [62/180]\tLR: [0.001]\tLoss 0.5766\tAcc 0.754\n",
            "[Val]Loss 1.3929\tAcc 0.500\n",
            "Epoch: [63/180]\tLR: [0.001]\tLoss 0.5500\tAcc 0.778\n",
            "[Val]Loss 1.4503\tAcc 0.490\n",
            "Epoch: [64/180]\tLR: [0.001]\tLoss 0.5284\tAcc 0.773\n",
            "[Val]Loss 1.4853\tAcc 0.500\n",
            "Epoch: [65/180]\tLR: [0.001]\tLoss 0.5100\tAcc 0.771\n",
            "[Val]Loss 1.5311\tAcc 0.500\n",
            "Epoch: [66/180]\tLR: [0.001]\tLoss 0.4966\tAcc 0.778\n",
            "[Val]Loss 1.5922\tAcc 0.500\n",
            "Epoch: [67/180]\tLR: [0.001]\tLoss 0.4802\tAcc 0.788\n",
            "[Val]Loss 1.6208\tAcc 0.500\n",
            "Epoch: [68/180]\tLR: [0.001]\tLoss 0.4602\tAcc 0.812\n",
            "[Val]Loss 1.6646\tAcc 0.500\n",
            "Epoch: [69/180]\tLR: [0.001]\tLoss 0.4536\tAcc 0.798\n",
            "[Val]Loss 1.6649\tAcc 0.519\n",
            "Epoch: [70/180]\tLR: [0.001]\tLoss 0.4372\tAcc 0.812\n",
            "[Val]Loss 1.7067\tAcc 0.529\n",
            "Epoch: [71/180]\tLR: [0.001]\tLoss 0.4276\tAcc 0.822\n",
            "[Val]Loss 1.7510\tAcc 0.500\n",
            "Epoch: [72/180]\tLR: [0.001]\tLoss 0.4163\tAcc 0.827\n",
            "[Val]Loss 1.8744\tAcc 0.490\n",
            "Epoch: [73/180]\tLR: [0.001]\tLoss 0.4078\tAcc 0.829\n",
            "[Val]Loss 1.8422\tAcc 0.500\n",
            "Epoch: [74/180]\tLR: [0.001]\tLoss 0.3939\tAcc 0.841\n",
            "[Val]Loss 1.9038\tAcc 0.510\n",
            "Epoch: [75/180]\tLR: [0.001]\tLoss 0.3846\tAcc 0.851\n",
            "[Val]Loss 1.9588\tAcc 0.500\n",
            "Epoch: [76/180]\tLR: [0.001]\tLoss 0.3750\tAcc 0.843\n",
            "[Val]Loss 1.9771\tAcc 0.510\n",
            "Epoch: [77/180]\tLR: [0.001]\tLoss 0.3632\tAcc 0.855\n",
            "[Val]Loss 2.0311\tAcc 0.519\n",
            "Epoch: [78/180]\tLR: [0.001]\tLoss 0.3507\tAcc 0.853\n",
            "[Val]Loss 2.1386\tAcc 0.510\n",
            "Epoch: [79/180]\tLR: [0.001]\tLoss 0.3389\tAcc 0.872\n",
            "[Val]Loss 2.1084\tAcc 0.510\n",
            "Epoch: [80/180]\tLR: [0.001]\tLoss 0.3373\tAcc 0.865\n",
            "[Val]Loss 2.1173\tAcc 0.519\n",
            "Epoch: [81/180]\tLR: [0.001]\tLoss 0.3312\tAcc 0.880\n",
            "[Val]Loss 2.1658\tAcc 0.519\n",
            "Epoch: [82/180]\tLR: [0.001]\tLoss 0.3268\tAcc 0.870\n",
            "[Val]Loss 2.3439\tAcc 0.519\n",
            "Epoch: [83/180]\tLR: [0.001]\tLoss 0.3217\tAcc 0.872\n",
            "[Val]Loss 2.2822\tAcc 0.500\n",
            "Epoch: [84/180]\tLR: [0.001]\tLoss 0.3076\tAcc 0.892\n",
            "[Val]Loss 2.3379\tAcc 0.529\n",
            "Epoch: [85/180]\tLR: [0.001]\tLoss 0.2944\tAcc 0.892\n",
            "[Val]Loss 2.3902\tAcc 0.490\n",
            "Epoch: [86/180]\tLR: [0.001]\tLoss 0.2866\tAcc 0.894\n",
            "[Val]Loss 2.4643\tAcc 0.519\n",
            "Epoch: [87/180]\tLR: [0.001]\tLoss 0.2826\tAcc 0.896\n",
            "[Val]Loss 2.4917\tAcc 0.519\n",
            "Epoch: [88/180]\tLR: [0.001]\tLoss 0.2740\tAcc 0.901\n",
            "[Val]Loss 2.5860\tAcc 0.500\n",
            "Epoch: [89/180]\tLR: [0.001]\tLoss 0.2690\tAcc 0.901\n",
            "[Val]Loss 2.6238\tAcc 0.519\n",
            "Epoch: [90/180]\tLR: [0.001]\tLoss 0.2731\tAcc 0.892\n",
            "[Val]Loss 2.6826\tAcc 0.500\n",
            "Epoch: [91/180]\tLR: [0.001]\tLoss 0.2552\tAcc 0.904\n",
            "[Val]Loss 2.7363\tAcc 0.510\n",
            "Epoch: [92/180]\tLR: [0.001]\tLoss 0.2436\tAcc 0.911\n",
            "[Val]Loss 2.7983\tAcc 0.490\n",
            "Epoch: [93/180]\tLR: [0.001]\tLoss 0.2378\tAcc 0.920\n",
            "[Val]Loss 2.8010\tAcc 0.519\n",
            "Epoch: [94/180]\tLR: [0.001]\tLoss 0.2293\tAcc 0.916\n",
            "[Val]Loss 2.9292\tAcc 0.519\n",
            "Epoch: [95/180]\tLR: [0.001]\tLoss 0.2383\tAcc 0.908\n",
            "[Val]Loss 2.9977\tAcc 0.510\n",
            "Epoch: [96/180]\tLR: [0.001]\tLoss 0.2225\tAcc 0.920\n",
            "[Val]Loss 2.9596\tAcc 0.519\n",
            "Epoch: [97/180]\tLR: [0.001]\tLoss 0.2156\tAcc 0.913\n",
            "[Val]Loss 3.1511\tAcc 0.510\n",
            "Epoch: [98/180]\tLR: [0.001]\tLoss 0.2139\tAcc 0.920\n",
            "[Val]Loss 3.1434\tAcc 0.538\n",
            "Epoch: [99/180]\tLR: [0.001]\tLoss 0.2187\tAcc 0.918\n",
            "[Val]Loss 3.2234\tAcc 0.510\n",
            "Epoch: [100/180]\tLR: [0.001]\tLoss 0.2003\tAcc 0.930\n",
            "[Val]Loss 3.3266\tAcc 0.548\n",
            "Epoch: [101/180]\tLR: [0.001]\tLoss 0.2066\tAcc 0.916\n",
            "[Val]Loss 3.2290\tAcc 0.529\n",
            "Epoch: [102/180]\tLR: [0.001]\tLoss 0.1881\tAcc 0.933\n",
            "[Val]Loss 3.3707\tAcc 0.500\n",
            "Epoch: [103/180]\tLR: [0.001]\tLoss 0.1772\tAcc 0.942\n",
            "[Val]Loss 3.3378\tAcc 0.510\n",
            "Epoch: [104/180]\tLR: [0.001]\tLoss 0.1731\tAcc 0.935\n",
            "[Val]Loss 3.5726\tAcc 0.529\n",
            "Epoch: [105/180]\tLR: [0.001]\tLoss 0.1812\tAcc 0.942\n",
            "[Val]Loss 3.5106\tAcc 0.519\n",
            "Epoch: [106/180]\tLR: [0.001]\tLoss 0.1801\tAcc 0.942\n",
            "[Val]Loss 3.4542\tAcc 0.538\n",
            "Epoch: [107/180]\tLR: [0.001]\tLoss 0.1645\tAcc 0.947\n",
            "[Val]Loss 3.6942\tAcc 0.519\n",
            "Epoch: [108/180]\tLR: [0.001]\tLoss 0.1605\tAcc 0.952\n",
            "[Val]Loss 3.6171\tAcc 0.529\n",
            "Epoch: [109/180]\tLR: [0.001]\tLoss 0.1984\tAcc 0.928\n",
            "[Val]Loss 3.5296\tAcc 0.538\n",
            "Epoch: [110/180]\tLR: [0.001]\tLoss 0.1553\tAcc 0.957\n",
            "[Val]Loss 3.8703\tAcc 0.490\n",
            "Epoch: [111/180]\tLR: [0.001]\tLoss 0.1804\tAcc 0.942\n",
            "[Val]Loss 3.6954\tAcc 0.519\n",
            "Epoch: [112/180]\tLR: [0.001]\tLoss 0.1892\tAcc 0.925\n",
            "[Val]Loss 3.7814\tAcc 0.529\n",
            "Epoch: [113/180]\tLR: [0.001]\tLoss 0.1510\tAcc 0.952\n",
            "[Val]Loss 3.9329\tAcc 0.481\n",
            "Epoch: [114/180]\tLR: [0.001]\tLoss 0.1451\tAcc 0.945\n",
            "[Val]Loss 3.9052\tAcc 0.529\n",
            "Epoch: [115/180]\tLR: [0.001]\tLoss 0.1292\tAcc 0.957\n",
            "[Val]Loss 4.0132\tAcc 0.510\n",
            "Epoch: [116/180]\tLR: [0.001]\tLoss 0.1238\tAcc 0.964\n",
            "[Val]Loss 4.0159\tAcc 0.481\n",
            "Epoch: [117/180]\tLR: [0.001]\tLoss 0.1226\tAcc 0.969\n",
            "[Val]Loss 4.2020\tAcc 0.529\n",
            "Epoch: [118/180]\tLR: [0.001]\tLoss 0.1868\tAcc 0.920\n",
            "[Val]Loss 3.9409\tAcc 0.519\n",
            "Epoch: [119/180]\tLR: [0.001]\tLoss 0.2242\tAcc 0.908\n",
            "[Val]Loss 3.9644\tAcc 0.481\n",
            "Epoch: [120/180]\tLR: [0.001]\tLoss 0.1434\tAcc 0.945\n",
            "[Val]Loss 4.0404\tAcc 0.529\n",
            "Epoch: [121/180]\tLR: [0.0001]\tLoss 0.1054\tAcc 0.973\n",
            "[Val]Loss 4.0157\tAcc 0.510\n",
            "Epoch: [122/180]\tLR: [0.0001]\tLoss 0.1020\tAcc 0.973\n",
            "[Val]Loss 4.0336\tAcc 0.510\n",
            "Epoch: [123/180]\tLR: [0.0001]\tLoss 0.1004\tAcc 0.973\n",
            "[Val]Loss 4.0607\tAcc 0.510\n",
            "Epoch: [124/180]\tLR: [0.0001]\tLoss 0.0991\tAcc 0.973\n",
            "[Val]Loss 4.0629\tAcc 0.510\n",
            "Epoch: [125/180]\tLR: [0.0001]\tLoss 0.0981\tAcc 0.973\n",
            "[Val]Loss 4.0886\tAcc 0.500\n",
            "Epoch: [126/180]\tLR: [0.0001]\tLoss 0.0969\tAcc 0.973\n",
            "[Val]Loss 4.1103\tAcc 0.500\n",
            "Epoch: [127/180]\tLR: [0.0001]\tLoss 0.0961\tAcc 0.973\n",
            "[Val]Loss 4.1400\tAcc 0.500\n",
            "Epoch: [128/180]\tLR: [0.0001]\tLoss 0.0950\tAcc 0.973\n",
            "[Val]Loss 4.1485\tAcc 0.510\n",
            "Epoch: [129/180]\tLR: [0.0001]\tLoss 0.0939\tAcc 0.973\n",
            "[Val]Loss 4.1631\tAcc 0.510\n",
            "Epoch: [130/180]\tLR: [0.0001]\tLoss 0.0931\tAcc 0.973\n",
            "[Val]Loss 4.1763\tAcc 0.500\n",
            "Epoch: [131/180]\tLR: [0.0001]\tLoss 0.0924\tAcc 0.973\n",
            "[Val]Loss 4.1859\tAcc 0.510\n",
            "Epoch: [132/180]\tLR: [0.0001]\tLoss 0.0921\tAcc 0.973\n",
            "[Val]Loss 4.2050\tAcc 0.510\n",
            "Epoch: [133/180]\tLR: [0.0001]\tLoss 0.0909\tAcc 0.973\n",
            "[Val]Loss 4.2167\tAcc 0.510\n",
            "Epoch: [134/180]\tLR: [0.0001]\tLoss 0.0903\tAcc 0.973\n",
            "[Val]Loss 4.2231\tAcc 0.510\n",
            "Epoch: [135/180]\tLR: [0.0001]\tLoss 0.0895\tAcc 0.973\n",
            "[Val]Loss 4.2450\tAcc 0.510\n",
            "Epoch: [136/180]\tLR: [0.0001]\tLoss 0.0887\tAcc 0.973\n",
            "[Val]Loss 4.2407\tAcc 0.510\n",
            "Epoch: [137/180]\tLR: [0.0001]\tLoss 0.0882\tAcc 0.973\n",
            "[Val]Loss 4.2634\tAcc 0.510\n",
            "Epoch: [138/180]\tLR: [0.0001]\tLoss 0.0878\tAcc 0.973\n",
            "[Val]Loss 4.2677\tAcc 0.510\n",
            "Epoch: [139/180]\tLR: [0.0001]\tLoss 0.0868\tAcc 0.973\n",
            "[Val]Loss 4.2793\tAcc 0.510\n",
            "Epoch: [140/180]\tLR: [0.0001]\tLoss 0.0863\tAcc 0.973\n",
            "[Val]Loss 4.2941\tAcc 0.510\n",
            "Epoch: [141/180]\tLR: [0.0001]\tLoss 0.0862\tAcc 0.976\n",
            "[Val]Loss 4.3157\tAcc 0.510\n",
            "Epoch: [142/180]\tLR: [0.0001]\tLoss 0.0857\tAcc 0.976\n",
            "[Val]Loss 4.3096\tAcc 0.510\n",
            "Epoch: [143/180]\tLR: [0.0001]\tLoss 0.0849\tAcc 0.976\n",
            "[Val]Loss 4.3270\tAcc 0.510\n",
            "Epoch: [144/180]\tLR: [0.0001]\tLoss 0.0840\tAcc 0.976\n",
            "[Val]Loss 4.3305\tAcc 0.510\n",
            "Epoch: [145/180]\tLR: [0.0001]\tLoss 0.0839\tAcc 0.978\n",
            "[Val]Loss 4.3562\tAcc 0.510\n",
            "Epoch: [146/180]\tLR: [0.0001]\tLoss 0.0833\tAcc 0.978\n",
            "[Val]Loss 4.3589\tAcc 0.510\n",
            "Epoch: [147/180]\tLR: [0.0001]\tLoss 0.0827\tAcc 0.978\n",
            "[Val]Loss 4.3673\tAcc 0.510\n",
            "Epoch: [148/180]\tLR: [0.0001]\tLoss 0.0820\tAcc 0.978\n",
            "[Val]Loss 4.3891\tAcc 0.510\n",
            "Epoch: [149/180]\tLR: [0.0001]\tLoss 0.0820\tAcc 0.978\n",
            "[Val]Loss 4.3960\tAcc 0.510\n",
            "Epoch: [150/180]\tLR: [0.0001]\tLoss 0.0809\tAcc 0.978\n",
            "[Val]Loss 4.4011\tAcc 0.510\n",
            "Epoch: [151/180]\tLR: [0.0001]\tLoss 0.0804\tAcc 0.978\n",
            "[Val]Loss 4.4123\tAcc 0.510\n",
            "Epoch: [152/180]\tLR: [0.0001]\tLoss 0.0800\tAcc 0.978\n",
            "[Val]Loss 4.4166\tAcc 0.510\n",
            "Epoch: [153/180]\tLR: [0.0001]\tLoss 0.0792\tAcc 0.978\n",
            "[Val]Loss 4.4331\tAcc 0.510\n",
            "Epoch: [154/180]\tLR: [0.0001]\tLoss 0.0786\tAcc 0.981\n",
            "[Val]Loss 4.4396\tAcc 0.510\n",
            "Epoch: [155/180]\tLR: [0.0001]\tLoss 0.0782\tAcc 0.981\n",
            "[Val]Loss 4.4575\tAcc 0.510\n",
            "Epoch: [156/180]\tLR: [0.0001]\tLoss 0.0775\tAcc 0.981\n",
            "[Val]Loss 4.4667\tAcc 0.510\n",
            "Epoch: [157/180]\tLR: [0.0001]\tLoss 0.0770\tAcc 0.981\n",
            "[Val]Loss 4.4798\tAcc 0.510\n",
            "Epoch: [158/180]\tLR: [0.0001]\tLoss 0.0766\tAcc 0.981\n",
            "[Val]Loss 4.4805\tAcc 0.510\n",
            "Epoch: [159/180]\tLR: [0.0001]\tLoss 0.0766\tAcc 0.981\n",
            "[Val]Loss 4.5009\tAcc 0.510\n",
            "Epoch: [160/180]\tLR: [0.0001]\tLoss 0.0757\tAcc 0.981\n",
            "[Val]Loss 4.5062\tAcc 0.510\n",
            "Epoch: [161/180]\tLR: [0.0001]\tLoss 0.0755\tAcc 0.983\n",
            "[Val]Loss 4.5163\tAcc 0.510\n",
            "Epoch: [162/180]\tLR: [0.0001]\tLoss 0.0750\tAcc 0.981\n",
            "[Val]Loss 4.5315\tAcc 0.510\n",
            "Epoch: [163/180]\tLR: [0.0001]\tLoss 0.0745\tAcc 0.981\n",
            "[Val]Loss 4.5341\tAcc 0.510\n",
            "Epoch: [164/180]\tLR: [0.0001]\tLoss 0.0739\tAcc 0.986\n",
            "[Val]Loss 4.5468\tAcc 0.510\n",
            "Epoch: [165/180]\tLR: [0.0001]\tLoss 0.0736\tAcc 0.981\n",
            "[Val]Loss 4.5499\tAcc 0.510\n",
            "Epoch: [166/180]\tLR: [0.0001]\tLoss 0.0734\tAcc 0.983\n",
            "[Val]Loss 4.5686\tAcc 0.510\n",
            "Epoch: [167/180]\tLR: [0.0001]\tLoss 0.0730\tAcc 0.981\n",
            "[Val]Loss 4.5712\tAcc 0.510\n",
            "Epoch: [168/180]\tLR: [0.0001]\tLoss 0.0725\tAcc 0.986\n",
            "[Val]Loss 4.5851\tAcc 0.510\n",
            "Epoch: [169/180]\tLR: [0.0001]\tLoss 0.0722\tAcc 0.983\n",
            "[Val]Loss 4.5914\tAcc 0.510\n",
            "Epoch: [170/180]\tLR: [0.0001]\tLoss 0.0718\tAcc 0.983\n",
            "[Val]Loss 4.6130\tAcc 0.510\n",
            "Epoch: [171/180]\tLR: [0.0001]\tLoss 0.0717\tAcc 0.988\n",
            "[Val]Loss 4.6143\tAcc 0.510\n",
            "Epoch: [172/180]\tLR: [0.0001]\tLoss 0.0711\tAcc 0.986\n",
            "[Val]Loss 4.6290\tAcc 0.510\n",
            "Epoch: [173/180]\tLR: [0.0001]\tLoss 0.0707\tAcc 0.986\n",
            "[Val]Loss 4.6345\tAcc 0.510\n",
            "Epoch: [174/180]\tLR: [0.0001]\tLoss 0.0700\tAcc 0.986\n",
            "[Val]Loss 4.6548\tAcc 0.510\n",
            "Epoch: [175/180]\tLR: [0.0001]\tLoss 0.0696\tAcc 0.988\n",
            "[Val]Loss 4.6569\tAcc 0.510\n",
            "Epoch: [176/180]\tLR: [0.0001]\tLoss 0.0695\tAcc 0.986\n",
            "[Val]Loss 4.6679\tAcc 0.510\n",
            "Epoch: [177/180]\tLR: [0.0001]\tLoss 0.0688\tAcc 0.988\n",
            "[Val]Loss 4.6685\tAcc 0.510\n",
            "Epoch: [178/180]\tLR: [0.0001]\tLoss 0.0689\tAcc 0.983\n",
            "[Val]Loss 4.6862\tAcc 0.510\n",
            "Epoch: [179/180]\tLR: [0.0001]\tLoss 0.0682\tAcc 0.988\n",
            "[Val]Loss 4.6856\tAcc 0.510\n",
            "Epoch: [180/180]\tLR: [0.0001]\tLoss 0.0678\tAcc 0.986\n",
            "[Val]Loss 4.6916\tAcc 0.510\n",
            "[Val]Loss 4.0447\tAcc 0.442\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}