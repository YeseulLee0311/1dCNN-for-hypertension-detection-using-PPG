{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cebe00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path=['/Users/yeseullee/Documents/ECE271B/MIMICii/part1',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part2',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part3',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part4']\n",
    "\n",
    "label_path=['/Users/yeseullee/Documents/ECE271B/MIMICii/part1/label1.csv',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part2/label2.csv',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part3/label3.csv',\n",
    "'/Users/yeseullee/Documents/ECE271B/MIMICii/part4/label4.csv']\n",
    "\n",
    "\n",
    "class MIMICDataset(data.Dataset):\n",
    "    def __init__(self, data_path, label_path, normalize=None, preprocessing=False, choose_class=[0,1,2]):\n",
    "        self.data_path=data_path\n",
    "        self.label_path=label_path\n",
    "        self.normalize=normalize\n",
    "        self.preprocessing=preprocessing\n",
    "        self.choose_class=choose_class\n",
    "        \n",
    "        self.data = []\n",
    "        self.label = []\n",
    "        self.subjectid = []\n",
    "        \n",
    "        #read BP labels\n",
    "        label_df1=pd.read_csv(label_path[0])\n",
    "        label_df2=pd.read_csv(label_path[1])\n",
    "        label_df3=pd.read_csv(label_path[2])\n",
    "        label_df4=pd.read_csv(label_path[3])\n",
    "        label_dfs=[label_df1,label_df2,label_df3,label_df4]\n",
    "        \n",
    "        class_id = [[] for i in range(3)]\n",
    "        for i in range(0,4):\n",
    "            for n in range(0,len(label_dfs[i])):\n",
    "                if label_dfs[i]['hypertension_level'][n]=='Hypertension':\n",
    "                    class_id[2].append(str(i+1)+'_'+(label_dfs[i]['subject_id'][n]))\n",
    "                elif label_dfs[i]['hypertension_level'][n]=='Prehypertension':\n",
    "                    class_id[1].append(str(i+1)+'_'+(label_dfs[i]['subject_id'][n]))\n",
    "                elif label_dfs[i]['hypertension_level'][n]=='Normal':\n",
    "                    class_id[0].append(str(i+1)+'_'+(label_dfs[i]['subject_id'][n]))    \n",
    "                \n",
    "        freq=125\n",
    "        sec=5\n",
    "        for c in choose_class:\n",
    "            for sub in class_id[c]:\n",
    "                seg_path = os.path.join(self.data_path[int(sub[0])-1], '{}.txt'.format(sub[2:]))\n",
    "                if os.path.exists(seg_path):\n",
    "                    with open(seg_path) as f:\n",
    "                        lines = f.readlines()[0].split('\\t')[:-1]\n",
    "                if len(lines) != freq*sec:\n",
    "                    print(subject, subjectid, segment, len(lines))\n",
    "                    continue\n",
    "\n",
    "                seg = torch.Tensor([float(x) for x in lines])\n",
    "                seg = seg.reshape((1,freq*sec))\n",
    "                self.data.append(seg)\n",
    "                self.label.append(c)\n",
    "                self.subjectid.append(sub)\n",
    "        \n",
    "        self.label = torch.Tensor(self.label)\n",
    "        self.label = self.label.type(torch.long)\n",
    "        \n",
    "        with open(r'./subjectid_NT_PHT_HT.txt', 'w') as fp:\n",
    "            for item in self.subjectid:\n",
    "                # write each item on a new line\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "        \n",
    "        torch.save(self.data,'dataset_NT_PHT_HT.pt')\n",
    "        torch.save(self.label,'label_NT_PHT_HT.pt')\n",
    "        \n",
    "    def median_filter(tensor_data):\n",
    "        x,y = tensor_data.size()\n",
    "        new_data = torch.zeros(x,y)\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                if j == 0:\n",
    "                    new_data[i][j] = tensor_data[i][j]\n",
    "                elif j < 11:\n",
    "                    new_data[i][j] = tensor_data[i][0: 2 * j + 1].median()\n",
    "                elif 11 <= j < y - 11:\n",
    "                    new_data[i][j] = tensor_data[i][j - 11: j + 12].median()\n",
    "                elif y - 11 <= j < y - 1:\n",
    "                    new_data[i][j] = tensor_data[i][2*j - y : y].median()\n",
    "                elif j == y - 1:\n",
    "                    new_data[i][j] = tensor_data[i][j]\n",
    "        return new_data\n",
    "\n",
    "    def roll_filter(tensor_data):\n",
    "        x,y = tensor_data.size()\n",
    "        new_data = torch.zeros(x,y)\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                if j == 0:\n",
    "                    new_data[i][j] = tensor_data[i][j]\n",
    "                elif j < 11:\n",
    "                    new_data[i][j] = tensor_data[i][0: 2 * j + 1].mean()\n",
    "                elif 11 <= j < y - 11:\n",
    "                    new_data[i][j] = tensor_data[i][j - 11: j + 12].mean()\n",
    "                elif y - 11 <= j < y - 1:\n",
    "                    new_data[i][j] = tensor_data[i][2*j - y : y].mean()\n",
    "                elif j == y - 1:\n",
    "                    new_data[i][j] = tensor_data[i][j]\n",
    "        return new_data            \n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        if self.preprocessing:\n",
    "            data = roll_filter(median_filter(data))\n",
    "        if self.normalize:\n",
    "            data = (data-self.normalize['mean'])/self.normalize['std'] #normalization\n",
    "        label = self.label[index]\n",
    "        subjectid = self.subjectid[index]\n",
    "\n",
    "        if self.choose_class==[0,2] and label==2:\n",
    "            label=torch.tensor(1)\n",
    "\n",
    "        return data, label, subjectid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1804e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean=1.59\n",
    "data_std=0.73\n",
    "data_normalization = {'mean':data_mean,'std':data_std}\n",
    "dataset=MIMICDataset(data_path, label_path, normalize=data_normalization, preprocessing=False, choose_class=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d458f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean=1.59\n",
    "data_std=0.73\n",
    "data_normalization = {'mean':data_mean,'std':data_std}\n",
    "dataset=MIMICDataset(data_path, label_path, normalize=data_normalization, preprocessing=False, choose_class=[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854e0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean=1.59\n",
    "data_std=0.73\n",
    "data_normalization = {'mean':data_mean,'std':data_std}\n",
    "dataset=MIMICDataset(data_path, label_path, normalize=data_normalization, preprocessing=False, choose_class=[0,1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
